{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "ppg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg4pPcCWcJR",
        "outputId": "1f69c92b-1423-4de0-c8e0-31f62235d45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=ea3c2976808d12a04861efdc316e704075bf3d0403f841270d357e4a49f7d2e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Unix-like\n",
            "Mounted at /content/drive\n",
            "Cloning into 'HeartRateRegression'...\n",
            "Warning: Permanently added 'github.com,192.30.255.113' (RSA) to the list of known hosts.\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 835 (delta 71), reused 60 (delta 29), pack-reused 719\u001b[K\n",
            "Receiving objects: 100% (835/835), 88.09 MiB | 31.77 MiB/s, done.\n",
            "Resolving deltas: 100% (527/527), done.\n",
            "Already up to date.\n",
            "Warning: Permanently added the RSA host key for IP address '192.30.255.112' to the list of known hosts.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFiZv0xM1pa",
        "outputId": "2dc6d5df-eb31-4882-d549-e9cf7c3426c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = {\n",
        "    'epoch_num': 250,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 0,     # Number of workers on data loader.\n",
        "    'batch_size': 128,     # Mini-batch size. 128\n",
        "    'batch_test': 248,     # size of test batch\n",
        "    'window': 15,\n",
        "    'initial_window':5,\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seeds()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V97F8pWmvK",
        "outputId": "0066b072-3b12-42af-b7e3-5addeafef1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data_utils import (PpgDaliaExtractor, FormatPPGDalia)\n",
        "\n",
        "extractor = PpgDaliaExtractor(DATA_DIR)\n",
        "ppg_dalia_formatter = FormatPPGDalia()\n",
        "dfs_train = [ppg_dalia_formatter.transform(extractor.extract_subject(i)) for i in range(1,16)]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDUK1vToJWo",
        "outputId": "1c064ce6-98f9-455c-b898-abe1b77dc15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "\n",
        "from PPG import FullTrainer\n",
        "\n",
        "importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "importlib.reload(PPG.NoHrPceLstmModel)\n",
        "importlib.reload(PPG.TrainerXY)\n",
        "importlib.reload(PPG.TrainerIS)\n",
        "importlib.reload(PPG.FullTrainer)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'PPG.FullTrainer' from '/tmp/HeartRateRegression/PPG/FullTrainer.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7zop0WGrHb",
        "outputId": "4100ebf3-6d97-4cf4-9398-a4bfc4e5061c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "  # ensembler = SimpleEnsemble()\n",
        "\n",
        "def compute_ensemble(results):\n",
        "  ps = [v[\"predictions\"][1].reshape(-1).numpy() for v in results]\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  return np.mean(np.abs(a - y))\n",
        "\n",
        "\n",
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0,\n",
        "  'lr': 0.0001,\n",
        "  'lin_dropout': 0,\n",
        "  'lin_size': 16,\n",
        "  'nlin_layers': 2,\n",
        "  'feedforward_expansion': 1,\n",
        "  'nhead': 4,\n",
        "  'ndec_layers': 2,\n",
        "  'nenc_layers': 2,\n",
        "  'conv_dropout': 0,\n",
        "  'nconv_layers': 2,\n",
        "  'conv_filters': 128,\n",
        "  'nfeatures': 4\n",
        "}\n",
        "\n",
        "\n",
        "from PPG import UtilitiesDataXY\n",
        "aresults = list()\n",
        "for ts_sub in [4,5,6,7,8,9,10,11,12,13,14]:\n",
        "  dresults = list()\n",
        "  for i in range(7):\n",
        "    filename = f\"attention_output_ts_{ts_sub}_{i}.pkl\"\n",
        "    save_path = os.path.join(STORE_DIR, filename)\n",
        "    try:\n",
        "      with open(save_path , \"rb\") as f:\n",
        "        out = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "      full_trainer = FullTrainer.JointValAttentionFullTrainer(dfs_train, args[\"device\"])\n",
        "    else:\n",
        "      dresults.append(out)\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      fchoice[\"ts_sub\"] = ts_sub\n",
        "      out = full_trainer.train(**fchoice)\n",
        "      print(out[\"args\"], out[\"metric\"])\n",
        "      dresults.append(out)\n",
        "      \n",
        "      \n",
        "      with open(save_path, \"wb\") as f:\n",
        "        results = pickle.dump(out, f)\n",
        "\n",
        "    except RuntimeError as e:\n",
        "      if isinstance(e, KeyboardInterrupt):\n",
        "        raise e\n",
        "      else:\n",
        "        print(\"####\")\n",
        "        print(f\"Failed: {fchoice}\")\n",
        "        print(\"###\")\n",
        "  print(f\"TS:{compute_ensemble(dresults)}\")\n",
        "  aresults.append(dresults)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TS:6.431684970855713\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 9.625 loss_val 9.277 loss_ts 7.971\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.790 loss_val 8.535 loss_ts 7.107\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.530 loss_val 6.589 loss_ts 7.706\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.426 loss_val 6.532 loss_ts 6.095\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 5.977 loss_val 6.128 loss_ts 5.840\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 5.499 loss_val 5.770 loss_ts 6.805\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.205 loss_val 5.495 loss_ts 4.997\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 4.839 loss_val 5.197 loss_ts 6.084\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.188 loss_val 4.657 loss_ts 5.739\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 3.752 loss_val 4.236 loss_ts 5.551\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 3.503 loss_val 4.230 loss_ts 6.562\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 3.455 loss_val 4.119 loss_ts 5.225\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 3.292 loss_val 4.072 loss_ts 5.361\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 3.212 loss_val 4.029 loss_ts 5.274\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 3.241 loss_val 3.975 loss_ts 3.976\n",
            "best val epoch: 23\n",
            "[23/30]: loss_train: 2.737 loss_val 3.606 loss_ts 5.015\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 2.558 loss_val 3.569 loss_ts 4.651\n",
            "Final: 4.6508097648620605\n",
            "{'val_sub': 4, 'ts_sub': 5, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 4.65081\n",
            "TS:3.7522900104522705\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 8.800 loss_val 8.926 loss_ts 6.962\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.697 loss_val 7.740 loss_ts 6.849\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.525 loss_val 6.808 loss_ts 5.606\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 5.999 loss_val 6.457 loss_ts 5.101\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 5.888 loss_val 6.249 loss_ts 4.890\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 5.414 loss_val 5.964 loss_ts 4.691\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 5.237 loss_val 5.745 loss_ts 5.120\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 4.462 loss_val 5.171 loss_ts 4.509\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 4.543 loss_val 5.170 loss_ts 4.285\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 3.794 loss_val 4.605 loss_ts 3.831\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 3.472 loss_val 4.453 loss_ts 3.370\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 3.608 loss_val 4.412 loss_ts 3.710\n",
            "best val epoch: 27\n",
            "[27/30]: loss_train: 3.258 loss_val 4.339 loss_ts 3.416\n",
            "best val epoch: 28\n",
            "[28/30]: loss_train: 3.152 loss_val 4.224 loss_ts 3.550\n",
            "best val epoch: 29\n",
            "[29/30]: loss_train: 2.589 loss_val 3.888 loss_ts 2.808\n",
            "Final: 2.808425188064575\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 2.8084252\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 7.842 loss_val 8.092 loss_ts 5.979\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.634 loss_val 7.863 loss_ts 6.521\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.591 loss_val 6.877 loss_ts 5.507\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 6.006 loss_val 6.409 loss_ts 5.315\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.205 loss_val 5.681 loss_ts 4.698\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 4.971 loss_val 5.534 loss_ts 4.397\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.706 loss_val 5.309 loss_ts 4.239\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 4.075 loss_val 4.750 loss_ts 3.674\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 3.897 loss_val 4.701 loss_ts 3.411\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 3.763 loss_val 4.598 loss_ts 3.334\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 3.338 loss_val 4.167 loss_ts 3.225\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 3.017 loss_val 3.983 loss_ts 2.935\n",
            "best val epoch: 29\n",
            "[29/30]: loss_train: 2.674 loss_val 3.877 loss_ts 2.683\n",
            "Final: 2.6834115982055664\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 2.6834116\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 7.976 loss_val 8.245 loss_ts 6.528\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.387 loss_val 7.633 loss_ts 6.082\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.025 loss_val 6.564 loss_ts 4.854\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.473 loss_val 6.069 loss_ts 4.638\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.195 loss_val 5.858 loss_ts 4.564\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 4.929 loss_val 5.668 loss_ts 4.577\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.797 loss_val 5.510 loss_ts 4.377\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 4.505 loss_val 5.255 loss_ts 4.667\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 4.343 loss_val 5.047 loss_ts 3.970\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 3.763 loss_val 4.612 loss_ts 3.646\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 3.643 loss_val 4.475 loss_ts 3.860\n",
            "best val epoch: 22\n",
            "[22/30]: loss_train: 3.566 loss_val 4.447 loss_ts 3.837\n",
            "best val epoch: 23\n",
            "[23/30]: loss_train: 3.121 loss_val 4.035 loss_ts 3.165\n",
            "best val epoch: 25\n",
            "[25/30]: loss_train: 2.752 loss_val 3.807 loss_ts 2.917\n",
            "best val epoch: 27\n",
            "[27/30]: loss_train: 2.667 loss_val 3.702 loss_ts 2.800\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 2.535 loss_val 3.670 loss_ts 2.827\n",
            "Final: 2.826552152633667\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 2.8265522\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 9.214 loss_val 9.503 loss_ts 8.169\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.633 loss_val 7.920 loss_ts 7.805\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.550 loss_val 6.799 loss_ts 5.436\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 6.157 loss_val 6.538 loss_ts 4.996\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 5.885 loss_val 6.208 loss_ts 5.078\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 5.661 loss_val 6.061 loss_ts 4.928\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.616 loss_val 6.017 loss_ts 5.303\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.086 loss_val 5.493 loss_ts 4.736\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 4.800 loss_val 5.245 loss_ts 4.588\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.504 loss_val 5.089 loss_ts 4.249\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 4.428 loss_val 4.934 loss_ts 4.154\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 4.387 loss_val 4.905 loss_ts 3.960\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 4.112 loss_val 4.673 loss_ts 4.120\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 3.635 loss_val 4.198 loss_ts 3.253\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 3.362 loss_val 3.994 loss_ts 3.101\n",
            "best val epoch: 22\n",
            "[22/30]: loss_train: 3.256 loss_val 3.859 loss_ts 3.021\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 2.903 loss_val 3.731 loss_ts 2.593\n",
            "Final: 2.593188762664795\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 2.5931888\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 8.116 loss_val 8.410 loss_ts 6.070\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.947 loss_val 7.121 loss_ts 5.756\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.373 loss_val 6.674 loss_ts 5.485\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 5.929 loss_val 6.235 loss_ts 5.074\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 5.758 loss_val 6.189 loss_ts 5.144\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.407 loss_val 5.868 loss_ts 5.006\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 4.754 loss_val 5.177 loss_ts 4.401\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.558 loss_val 5.065 loss_ts 4.226\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 4.387 loss_val 4.899 loss_ts 4.275\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 4.198 loss_val 4.671 loss_ts 4.227\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 3.975 loss_val 4.527 loss_ts 3.691\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 3.756 loss_val 4.305 loss_ts 3.414\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 3.065 loss_val 3.786 loss_ts 2.881\n",
            "best val epoch: 27\n",
            "[27/30]: loss_train: 2.717 loss_val 3.676 loss_ts 2.954\n",
            "best val epoch: 28\n",
            "[28/30]: loss_train: 2.590 loss_val 3.574 loss_ts 2.876\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 2.562 loss_val 3.493 loss_ts 2.766\n",
            "Final: 2.766361713409424\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 2.7663617\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 9.216 loss_val 9.356 loss_ts 7.700\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.051 loss_val 8.004 loss_ts 7.075\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.596 loss_val 6.617 loss_ts 5.662\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 5.849 loss_val 5.993 loss_ts 5.123\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 5.666 loss_val 5.927 loss_ts 4.912\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.041 loss_val 5.428 loss_ts 4.698\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 4.506 loss_val 4.955 loss_ts 4.178\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.063 loss_val 4.588 loss_ts 3.809\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 3.930 loss_val 4.475 loss_ts 3.847\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 3.723 loss_val 4.466 loss_ts 3.517\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 3.562 loss_val 4.331 loss_ts 3.520\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 3.509 loss_val 4.210 loss_ts 3.227\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 3.066 loss_val 3.858 loss_ts 2.826\n",
            "best val epoch: 25\n",
            "[25/30]: loss_train: 2.724 loss_val 3.755 loss_ts 2.834\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 2.545 loss_val 3.681 loss_ts 2.777\n",
            "best val epoch: 29\n",
            "[29/30]: loss_train: 2.492 loss_val 3.570 loss_ts 2.964\n",
            "Final: 2.9635367393493652\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 2.9635367\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 8.874 loss_val 8.967 loss_ts 7.123\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 6.871 loss_val 6.961 loss_ts 5.996\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.301 loss_val 6.367 loss_ts 5.249\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 5.995 loss_val 6.155 loss_ts 5.120\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.661 loss_val 5.792 loss_ts 4.763\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.161 loss_val 5.351 loss_ts 4.396\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 4.556 loss_val 4.863 loss_ts 4.189\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 4.366 loss_val 4.781 loss_ts 3.894\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 4.249 loss_val 4.552 loss_ts 3.989\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 3.912 loss_val 4.334 loss_ts 3.577\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 3.639 loss_val 4.117 loss_ts 3.310\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 3.381 loss_val 3.939 loss_ts 3.135\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 3.229 loss_val 3.863 loss_ts 2.886\n",
            "best val epoch: 23\n",
            "[23/30]: loss_train: 3.075 loss_val 3.799 loss_ts 3.047\n",
            "best val epoch: 24\n",
            "[24/30]: loss_train: 3.062 loss_val 3.775 loss_ts 3.169\n",
            "best val epoch: 28\n",
            "[28/30]: loss_train: 2.876 loss_val 3.706 loss_ts 3.119\n",
            "Final: 3.119199514389038\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 3.1191995\n",
            "TS:2.3120176792144775\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 8.266 loss_val 8.252 loss_ts 8.467\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 6.767 loss_val 6.880 loss_ts 9.493\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.226 loss_val 6.446 loss_ts 8.662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjYv8BlUKYnM"
      },
      "source": [
        "\n",
        "def compute_ensemble(results):\n",
        "  ps = [v[\"predictions\"][1].reshape(-1).numpy() for v in results]\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  np.mean(np.abs(a - y))\n",
        "\n",
        "compute_ensemble(dresults)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# p = p.reshape(-1)\n",
        "\n",
        "# plt.plot(y)\n",
        "# plt.plot(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdPECC3jYpjp"
      },
      "source": [
        "import random \n",
        "options = {\n",
        "  \"ts_h_size\": [64, 128],\n",
        "  \"lstm_size\": [64, 64, 128],\n",
        "  \"lstm_input\": [64, 128, 256],\n",
        "  \"dropout_rate\": [0.25],\n",
        "  \"bvp_count\": [8,16],\n",
        "  \"nattrs\": [5],\n",
        "  'lr': [0.001],\n",
        "  'weight_decay': [0, 0.0001],\n",
        "  'batch_size': [64, 128, 256],\n",
        "  'ts_sub': [0],\n",
        "  'val_sub': [4]\n",
        " }\n",
        "\n",
        "def choose(options):\n",
        "  choice = dict()\n",
        "  for k,v in options.items():\n",
        "    choice[k] = random.choice(v)\n",
        "  return choice\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYFUSi1-4nzj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YFiismva8BL"
      },
      "source": [
        "results = list()\n",
        "from PPG import UtilitiesDataXY\n",
        "while True:\n",
        "  full_trainer = FullTrainer.NoHrPceLstmFullTrainer(dfs_train, args[\"device\"])\n",
        "  choice = choose(options)\n",
        "  try:\n",
        "    out = full_trainer.train(**choice)\n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    results.append([out[\"args\"], out[\"metric\"]])\n",
        "  except RuntimeError as e:\n",
        "    if isinstance(e, KeyboardInterrupt):\n",
        "      raise e\n",
        "    else:\n",
        "      print(\"####\")\n",
        "      print(f\"Failed: {choice}\")\n",
        "      print(\"###\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNTrC3_M2D-Z"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chhDawFV_14T"
      },
      "source": [
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0,\n",
        "  'lr': 0.001,\n",
        "  'nattrs': 5,\n",
        "  'bvp_count': 16,\n",
        "  'dropout_rate': 0.25,\n",
        "  'lstm_input': 128,\n",
        "  'lstm_size': 64,\n",
        "  'ts_h_size': 64}\n",
        "\n",
        "\n",
        "dresults = list()\n",
        "from PPG import UtilitiesDataXY\n",
        "ts_sub = 3\n",
        "for val_sub in [i for i in range(15) if i != ts_sub]:\n",
        "  full_trainer = FullTrainer.NoHrPceLstmFullTrainer(dfs_train, args[\"device\"])\n",
        "  try:\n",
        "    fchoice[\"ts_sub\"] = ts_sub\n",
        "    fchoice[\"val_sub\"] = val_sub\n",
        "    out = full_trainer.train(**fchoice)\n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    dresults.append([out])\n",
        "  except RuntimeError as e:\n",
        "    if isinstance(e, KeyboardInterrupt):\n",
        "      raise e\n",
        "    else:\n",
        "      print(\"####\")\n",
        "      print(f\"Failed: {choice}\")\n",
        "      print(\"###\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxjMx66OD9T9"
      },
      "source": [
        "y = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFOG4ar9WYpt"
      },
      "source": [
        "full_trainer = FullTrainer.AttentionFullTrainer(dfs_train, args[\"device\"], 0, 1)\n",
        "\n",
        "full_trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYVLTnMGXYGp"
      },
      "source": [
        "from PPG import UtilitiesDataXY \n",
        "\n",
        "\n",
        "transformers = PPG.AttentionDefaults.get_preprocessing_transformer()\n",
        "make_loaders = UtilitiesDataXY.DataLoaderFactory(transformers, dfs_train).make_loaders\n",
        "\n",
        "loader_tr, loader_val, loader_ts = make_loaders(ts_sub=0, val_sub=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Vr-YDyoGfH"
      },
      "source": [
        "from PPG.Models import SnippetConvolutionalTransformer\n",
        "\n",
        "net = SnippetConvolutionalTransformer().to(args[\"device\"])\n",
        "\n",
        "# x,y = next(iter(loader_tr))\n",
        "\n",
        "# p = net(x)\n",
        "\n",
        "criterion = nn.MSELoss().to(args[\"device\"])# nn.L1Loss().to(args[\"device\"]) #nn.CrossEntropyLoss().to(args[\"device\"])\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=args[\"lr\"],\n",
        "                             weight_decay=args[\"weight_decay\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ktvTpTaOcy"
      },
      "source": [
        "from PPG.TrainerXY import (EpochTrainerXY, MetricsComputerXY, TrainHelperXY)\n",
        "from preprocessing_utils import ZTransformer2\n",
        "\n",
        "epoch_trainer = EpochTrainerXY(net, optimizer, criterion, args[\"device\"])\n",
        "ztransformer = ZTransformer2(['heart_rate', 'wrist-ACC-0', 'wrist-ACC-1', 'wrist-ACC-2',\n",
        "              'wrist-BVP-0', 'wrist-EDA-0', 'wrist-TEMP-0', 'chest-ACC-0',\n",
        "              'chest-ACC-1', 'chest-ACC-2', 'chest-Resp-0'])\n",
        "metrics_comuter = MetricsComputerXY(ztransformer)\n",
        "\n",
        "train_helper = TrainHelperXY(epoch_trainer, loader_tr, loader_val, loader_ts, metrics_comuter.mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lyVMlfzkaFA"
      },
      "source": [
        "train_helper.train(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG0tSXLWPuCQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}