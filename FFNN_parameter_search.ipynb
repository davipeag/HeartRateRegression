{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "FFNN_parameter_search.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKtlPHl3Quos",
        "outputId": "8ec85b2e-3d07-4914-8fc0-cdf463319867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive, auth\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=bb31e9eaa869f47c1547e49fbc89fdc620dc76a36ef55057b2de0cc1dc9f1fa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Unix-like\n",
            "Mounted at /content/drive\n",
            "Cloning into 'HeartRateRegression'...\n",
            "Warning: Permanently added 'github.com,140.82.113.3' (RSA) to the list of known hosts.\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 1522 (delta 94), reused 93 (delta 41), pack-reused 1363\u001b[K\n",
            "Receiving objects: 100% (1522/1522), 103.46 MiB | 22.71 MiB/s, done.\n",
            "Resolving deltas: 100% (993/993), done.\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.112.4' to the list of known hosts.\n",
            "Already up to date.\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.114.3' to the list of known hosts.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS3l0K_iQupH",
        "outputId": "24e4d8d3-acd5-4524-fc92-88bb1556364c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = dict()\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# reset_seeds()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnWwUvdgQupH",
        "outputId": "d1498ee7-38e5-4e3c-96b7-48848050d88c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data_utils import (Pamap2Handler, FormatPamap)\n",
        "\n",
        "SUBJECTS = list(range(1,9))\n",
        "\n",
        "handler = Pamap2Handler(DATA_DIR)\n",
        "formatter = FormatPamap()\n",
        "dfs_train = [formatter.transform(handler.get_protocol_subject(i)) for i in SUBJECTS]\n",
        "[len(df)//200 for df in dfs_train]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1882, 2235, 1264, 1647, 1873, 1809, 1567, 2040]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Camj6ia2QupI",
        "outputId": "e3324e44-00e6-4be4-f15b-8ac4b360b922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "import preprocessing_utils\n",
        "from PPG import FullTrainer\n",
        "\n",
        "import RegressionHR\n",
        "importlib.reload(RegressionHR)\n",
        "from RegressionHR import Preprocessing\n",
        "from RegressionHR import FullTrainer\n",
        "from RegressionHR import PceLstmDefaults\n",
        "from RegressionHR import PceLstmModel\n",
        "from RegressionHR import TrainerJoint\n",
        "from RegressionHR import  UtilitiesData\n",
        "from RegressionHR import *\n",
        "\n",
        "import Models\n",
        "\n",
        "importlib.reload(Models.BaseModels)\n",
        "\n",
        "# importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "# importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "# importlib.reload(PPG.NoHrPceLstmModel)\n",
        "# importlib.reload(PPG.TrainerXY)\n",
        "# importlib.reload(PPG.TrainerIS)\n",
        "# importlib.reload(PPG.FullTrainer)\n",
        "# importlib.reload(PceLstmDefaults)\n",
        "# importlib.reload(preprocessing_utils)\n",
        "\n",
        "importlib.reload(RegressionHR.FullTrainer)\n",
        "importlib.reload(RegressionHR.PceLstmDefaults)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(preprocessing_utils)\n",
        "importlib.reload(RegressionHR.TrainerJoint)\n",
        "importlib.reload(RegressionHR.UtilitiesData)\n",
        "importlib.reload(RegressionHR.PceLstmModel)\n",
        "importlib.reload(preprocessing_utils)\n",
        "# import imp\n",
        "# for module in sys.modules.values():\n",
        "#     importlib.reload(module)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'preprocessing_utils' from '/tmp/HeartRateRegression/preprocessing_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK4MOabkQupI",
        "outputId": "6a29542e-5fa6-472e-9e4a-b795b5792b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random \n",
        "\n",
        "options = {\n",
        "  'ts_sub': [5],\n",
        "  'batch_size': [64],\n",
        "  'weight_decay': [0.0001, 0.00001, 0.0],\n",
        "  'lr': [0.001, 0.005, 0.0001, 0.0005],\n",
        "  'ts_per_sample':[30, 40, 50],\n",
        "  \"layer_sizes\": [(4,4,4), (8,8,8), (16, 16, 16), (32,32,32), (64,64,64)],\n",
        "  \"skip_mapping\": [((0,2),(0,3),(1,3)), ((0,2),(0,3)), ((1,3),(0,3)),  ((0,3),)],\n",
        "  \"dropout_rate\": [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "  }\n",
        "\n",
        "\n",
        "from  Optimization.Optimizers import RandomSearch\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "filename = \"pamap_ffnn_discriminator_results.pkl\"\n",
        "save_path = os.path.join(STORE_DIR, filename)\n",
        "\n",
        "try:\n",
        "  with open(save_path, \"rb\") as f:\n",
        "    results = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "  results = list()\n",
        "\n",
        "full_trainer = RegressionHR.FullTrainer.IteractiveFFNNFullTrainerJointValidation(dfs_train, args[\"device\"], nepoch =  500)\n",
        "\n",
        "searcher = RandomSearch(full_trainer, options)\n",
        "searcher.results = results\n",
        "while True:\n",
        "  searcher.fit(1)\n",
        "  with open(save_path, \"wb\") as f:\n",
        "    pickle.dump(searcher.results, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best val epoch: 1\n",
            "[1/500]: loss_train: 20.493 loss_val 21.462 loss_ts 21.557\n",
            "best val epoch: 2\n",
            "[2/500]: loss_train: 20.043 loss_val 21.197 loss_ts 21.197\n",
            "best val epoch: 3\n",
            "[3/500]: loss_train: 19.660 loss_val 21.032 loss_ts 20.896\n",
            "best val epoch: 4\n",
            "[4/500]: loss_train: 19.338 loss_val 20.909 loss_ts 20.608\n",
            "best val epoch: 5\n",
            "[5/500]: loss_train: 19.051 loss_val 20.848 loss_ts 20.189\n",
            "best val epoch: 6\n",
            "[6/500]: loss_train: 18.848 loss_val 20.802 loss_ts 19.989\n",
            "best val epoch: 7\n",
            "[7/500]: loss_train: 18.649 loss_val 20.623 loss_ts 19.954\n",
            "best val epoch: 8\n",
            "[8/500]: loss_train: 18.399 loss_val 20.289 loss_ts 20.132\n",
            "best val epoch: 9\n",
            "[9/500]: loss_train: 18.219 loss_val 20.015 loss_ts 20.368\n",
            "best val epoch: 10\n",
            "[10/500]: loss_train: 18.013 loss_val 19.810 loss_ts 20.384\n",
            "best val epoch: 11\n",
            "[11/500]: loss_train: 17.800 loss_val 19.617 loss_ts 20.287\n",
            "best val epoch: 12\n",
            "[12/500]: loss_train: 17.559 loss_val 19.369 loss_ts 20.233\n",
            "best val epoch: 13\n",
            "[13/500]: loss_train: 17.319 loss_val 19.126 loss_ts 20.263\n",
            "best val epoch: 14\n",
            "[14/500]: loss_train: 17.090 loss_val 18.859 loss_ts 20.554\n",
            "best val epoch: 15\n",
            "[15/500]: loss_train: 16.771 loss_val 18.604 loss_ts 20.550\n",
            "best val epoch: 16\n",
            "[16/500]: loss_train: 16.482 loss_val 18.389 loss_ts 20.463\n",
            "best val epoch: 17\n",
            "[17/500]: loss_train: 16.251 loss_val 18.213 loss_ts 20.746\n",
            "best val epoch: 18\n",
            "[18/500]: loss_train: 15.997 loss_val 17.982 loss_ts 20.488\n",
            "best val epoch: 19\n",
            "[19/500]: loss_train: 15.776 loss_val 17.559 loss_ts 21.033\n",
            "best val epoch: 21\n",
            "[21/500]: loss_train: 15.487 loss_val 17.217 loss_ts 21.635\n",
            "best val epoch: 22\n",
            "[22/500]: loss_train: 15.040 loss_val 16.930 loss_ts 20.709\n",
            "best val epoch: 23\n",
            "[23/500]: loss_train: 14.965 loss_val 16.701 loss_ts 21.896\n",
            "best val epoch: 25\n",
            "[25/500]: loss_train: 14.501 loss_val 16.489 loss_ts 21.181\n",
            "best val epoch: 26\n",
            "[26/500]: loss_train: 14.148 loss_val 16.001 loss_ts 23.162\n",
            "best val epoch: 27\n",
            "[27/500]: loss_train: 13.607 loss_val 15.703 loss_ts 22.500\n",
            "best val epoch: 33\n",
            "[33/500]: loss_train: 13.642 loss_val 15.454 loss_ts 25.487\n",
            "best val epoch: 35\n",
            "[35/500]: loss_train: 12.165 loss_val 15.435 loss_ts 17.259\n",
            "best val epoch: 36\n",
            "[36/500]: loss_train: 11.897 loss_val 15.289 loss_ts 22.149\n",
            "best val epoch: 40\n",
            "[40/500]: loss_train: 12.537 loss_val 14.694 loss_ts 26.136\n",
            "best val epoch: 41\n",
            "[41/500]: loss_train: 11.481 loss_val 14.642 loss_ts 17.388\n",
            "best val epoch: 42\n",
            "[42/500]: loss_train: 10.904 loss_val 14.237 loss_ts 17.664\n",
            "best val epoch: 44\n",
            "[44/500]: loss_train: 10.836 loss_val 13.960 loss_ts 22.346\n",
            "best val epoch: 45\n",
            "[45/500]: loss_train: 10.885 loss_val 13.904 loss_ts 21.489\n",
            "best val epoch: 48\n",
            "[48/500]: loss_train: 10.425 loss_val 13.540 loss_ts 21.944\n",
            "best val epoch: 49\n",
            "[49/500]: loss_train: 10.185 loss_val 13.356 loss_ts 22.546\n",
            "best val epoch: 50\n",
            "[50/500]: loss_train: 10.196 loss_val 13.078 loss_ts 26.529\n",
            "best val epoch: 51\n",
            "[51/500]: loss_train: 10.269 loss_val 12.784 loss_ts 24.015\n",
            "best val epoch: 58\n",
            "[58/500]: loss_train: 10.116 loss_val 11.948 loss_ts 27.545\n",
            "best val epoch: 59\n",
            "[59/500]: loss_train: 9.327 loss_val 11.894 loss_ts 22.632\n",
            "best val epoch: 60\n",
            "[60/500]: loss_train: 9.438 loss_val 11.804 loss_ts 24.214\n",
            "best val epoch: 61\n",
            "[61/500]: loss_train: 9.337 loss_val 11.683 loss_ts 24.082\n",
            "best val epoch: 63\n",
            "[63/500]: loss_train: 9.387 loss_val 11.571 loss_ts 22.560\n",
            "best val epoch: 64\n",
            "[64/500]: loss_train: 8.904 loss_val 10.740 loss_ts 23.952\n",
            "best val epoch: 67\n",
            "[67/500]: loss_train: 8.881 loss_val 10.422 loss_ts 22.717\n",
            "best val epoch: 70\n",
            "[70/500]: loss_train: 8.608 loss_val 10.383 loss_ts 25.143\n",
            "best val epoch: 72\n",
            "[72/500]: loss_train: 8.759 loss_val 10.356 loss_ts 22.939\n",
            "best val epoch: 73\n",
            "[73/500]: loss_train: 8.270 loss_val 9.675 loss_ts 16.785\n",
            "best val epoch: 74\n",
            "[74/500]: loss_train: 8.223 loss_val 9.601 loss_ts 21.692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKihB2HjQ6jO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}