{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "import torch\n",
    "\n",
    "args = {\n",
    "    'epoch_num': 100,     # Number of epochs.\n",
    "    'lr': 1.0e-3,           # Learning rate.\n",
    "    'weight_decay': 10e-4, # L2 penalty.\n",
    "    'momentum': 0.9,      # Momentum.\n",
    "    'batch_size': 2,     # Mini-batch size. 600\n",
    "    'batch_test': 2,     # size of test batch\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args['device'] = torch.device('cuda')\n",
    "else:\n",
    "    args['device'] = torch.device('cpu')\n",
    "\n",
    "print(args['device'])\n",
    "\n",
    "dataset_name = \"PAMAP2\"\n",
    "model_type = \"AttentionTransformer\"\n",
    "#\"OurConvLSTM\", \"AttentionTransformer\", \"DeepConvLSTM\", \"CnnIMU\"\n",
    "\n",
    "plot_subject = 2\n",
    "\n",
    "! pip install wget\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "ssh_config = \"\"\"\n",
    "Host github.com\n",
    "  IdentityFile ~/.ssh/github.pem\n",
    "  User davipeag\n",
    "  StrictHostKeyChecking no\n",
    "\"\"\"\n",
    "\n",
    "if os.name == 'nt':\n",
    "  base_path = \"\"\n",
    "  REPO_DIR = \".\"\n",
    "  print(\"Windows\")\n",
    "else:\n",
    "  print(\"Unix-like\")\n",
    "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
    "  DATA_PATH = \"/content/drive/My\\ Drive/deeplearning_project/normalized.zip\"\n",
    "  !mkdir ~/.ssh\n",
    "  !cp -u {GIT_PATH} ~/.ssh/\n",
    "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
    "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
    "  !chmod u=rw,g=,o= ~/.ssh/config\n",
    "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
    "  ! (cd {REPO_DIR} && git pull )\n",
    "  import sys\n",
    "  sys.path.append(REPO_DIR)\n",
    "\n",
    "\n",
    "def git_push():\n",
    "  if os.name == 'nt':\n",
    "    pass\n",
    "  else:\n",
    "    ! git config --global user.email \"daviaguiar@outlook.com\"\n",
    "    ! git config --global user.name \"Davi Pedrosa de Aguiar\"\n",
    "    print(\"going to push\")\n",
    "    ! (cd {REPO_DIR} && git pull && cd -)\n",
    "    ! (cd {REPO_DIR} && git add . && git commit -m \"from colab\" && git push)\n",
    "\n",
    "def git_pull():\n",
    "  if os.name == 'nt':\n",
    "    pass\n",
    "  else:\n",
    "    ! git config --global user.email \"daviaguiar@outlook.com\"\n",
    "    ! git config --global user.name \"Davi Pedrosa de Aguiar\"\n",
    "    print(\"going to push\")\n",
    "    ! (cd {REPO_DIR} && git pull && cd -)\n",
    "    \n",
    "  \n",
    "git_push()\n",
    "\n",
    "\n",
    "\n",
    "from data_utils import (\n",
    "    Pamap2Handler, cross_validation_split)\n",
    "\n",
    "from default_utils import DefaultPamapPreprocessing\n",
    "from preprocessing_utils import (OurConvLstmToAttentionFormat, OurConvLstmToCnnImuFormat)\n",
    "\n",
    "from models_utils import OurConvLstmDataset, make_loader, reset_seeds\n",
    "from models_utils import DatasetXY\n",
    "\n",
    "from default_utils import TrainOurConvLSTM, TrainXY\n",
    "from default_utils import make_our_conv_lstm, make_attention_transormer_model \n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "dataset_handler = Pamap2Handler(os.path.join(REPO_DIR, \"..\"))\n",
    "\n",
    "dfs = [dataset_handler.get_protocol_subject(s) for s in [1,2,3]]#,4,5,6,7,8]]\n",
    "df_full = pd.concat(dfs)\n",
    "\n",
    "#%%\n",
    "preprocessing_options = {\n",
    "    \"OurConvLSTM\": DefaultPamapPreprocessing(),\n",
    "    \"AttentionTransformer\": DefaultPamapPreprocessing(last_transformer=OurConvLstmToAttentionFormat()),\n",
    "    \"DeepConvLSTM\": DefaultPamapPreprocessing(last_transformer=OurConvLstmToCnnImuFormat()),\n",
    "    \"CnnIMU\": DefaultPamapPreprocessing(last_transformer=OurConvLstmToCnnImuFormat())\n",
    " }\n",
    "\n",
    "models = [\"AttentionTransformer\", \"OurConvLSTM\"]\n",
    "\n",
    "preprocessors =[preprocessing_options[model] for model in models]\n",
    "tdata = list()\n",
    "for preprocessor in preprocessors:\n",
    "    preprocessor.transformers.fit(df_full)\n",
    "    tdata.append(preprocessor.transformers.transform(dfs[plot_subject]))\n",
    "\n",
    "del dfs\n",
    "del df_full\n",
    "\n",
    "dataset_cls_options = {\n",
    "    \"OurConvLSTM\": OurConvLstmDataset,\n",
    "    \"AttentionTransformer\": DatasetXY,\n",
    "    \"DeepConvLSTM\": DatasetXY,\n",
    "    \"CnnIMU\": DatasetXY\n",
    " }\n",
    "\n",
    "\n",
    "datasets_cls = [dataset_cls_options[model_type] for model_type in models]\n",
    "\n",
    "loaders = [make_loader([xy], dataset_cls, batch_size = args[\"batch_size\"], shuffle=False)\n",
    "            for dataset_cls, xy in zip(datasets_cls, tdata)]\n",
    "\n",
    "\n",
    "#%%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default_utils import make_cnn_imu2\n",
    "from default_utils import make_deep_conv_lstm\n",
    "\n",
    "\n",
    "net_options = {\n",
    "    \"OurConvLSTM\": lambda : make_our_conv_lstm(40,1,False),\n",
    "    \"AttentionTransformer\": lambda: make_attention_transormer_model(args[\"device\"]),\n",
    "    \"DeepConvLSTM\": lambda : make_deep_conv_lstm(),\n",
    "    \"CnnIMU\": lambda : make_cnn_imu2()\n",
    "}\n",
    "\n",
    "nets = [net_options[model_type]().to(args[\"device\"]) for model_type in models]\n",
    "\n",
    "#net = net_options[model_type]().to(args[\"device\"])\n",
    "criterion = nn.L1Loss().to(args[\"device\"]) \n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "trainers = list()\n",
    "\n",
    "for preprocessor,net, model_type in zip(preprocessors,nets, models):\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args[\"lr\"],\n",
    "                             weight_decay=args[\"weight_decay\"])\n",
    "\n",
    "    basic_training_parameters = {\n",
    "        \"net\": net,\n",
    "        \"criterion\": criterion,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"loader_tr\": None,\n",
    "        \"loader_val\": None,\n",
    "        \"loader_ts\": None,\n",
    "        \"normdz\": preprocessor.normdz,\n",
    "        \"ztransformer\": preprocessor.ztransformer,\n",
    "        \"device\": args[\"device\"]\n",
    "    }\n",
    "\n",
    "\n",
    "    trainer_options = {\n",
    "        \"OurConvLSTM\": lambda : TrainOurConvLSTM(**basic_training_parameters),\n",
    "        \"AttentionTransformer\": lambda : TrainXY(\n",
    "            **basic_training_parameters,\n",
    "            get_last_y_from_x = lambda x: x[:,1, 0, -1].reshape(-1,1)\n",
    "        ),\n",
    "        \"CnnIMU\":lambda : TrainXY(\n",
    "            **basic_training_parameters,\n",
    "            get_last_y_from_x = lambda x: np.mean(x[:,0,200:300, 0], axis=1).reshape(-1,1)\n",
    "        ),\n",
    "        \"DeepConvLSTM\":lambda : TrainXY(\n",
    "            **basic_training_parameters,\n",
    "            get_last_y_from_x = lambda x: np.mean(x[:,0,200:300, 0], axis=1).reshape(-1,1)\n",
    "        ), \n",
    "\n",
    "    }\n",
    "\n",
    "    trainer = trainer_options[model_type]()\n",
    "    trainers.append(trainer)\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "for model_type, loader, trainer in zip(models, loaders, trainers):\n",
    "    state_dict_name = f\"trained_models/{model_type}ts_{plot_subject}_val_{4}.pkl\"\n",
    "    trainer.net.load_state_dict(torch.load(state_dict_name, map_location=args[\"device\"]))\n",
    "    y,p = reverse_transformed_prediction_labels()\n",
    "    plt.plot(p, label=model_type)\n",
    "plt.plot(y, label=\"actual\")\n",
    "plt.labels()\n",
    "plt.show()\n"
   ]
  }
 ]
}