{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "ppg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg4pPcCWcJR",
        "outputId": "09ba32c0-99c4-445f-decb-2a10907aa6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=e7e5f8cc3227cc9603369a52511b5ccc00e481cc4334620a90ec0f14bdd47095\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Unix-like\n",
            "Mounted at /content/drive\n",
            "Cloning into 'HeartRateRegression'...\n",
            "Warning: Permanently added 'github.com,140.82.114.3' (RSA) to the list of known hosts.\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 722 (delta 0), reused 0 (delta 0), pack-reused 719\u001b[K\n",
            "Receiving objects: 100% (722/722), 87.94 MiB | 36.47 MiB/s, done.\n",
            "Resolving deltas: 100% (456/456), done.\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.113.4' to the list of known hosts.\n",
            "Already up to date.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFiZv0xM1pa",
        "outputId": "a3254214-dc93-407f-c517-4349826560f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = {\n",
        "    'epoch_num': 250,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 0,     # Number of workers on data loader.\n",
        "    'batch_size': 128,     # Mini-batch size. 128\n",
        "    'batch_test': 248,     # size of test batch\n",
        "    'window': 15,\n",
        "    'initial_window':5,\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seeds()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V97F8pWmvK",
        "outputId": "cdcb20a8-e42a-4b87-9d94-7d715cdc098a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from data_utils import (PpgDaliaExtractor, FormatPPGDalia)\n",
        "\n",
        "extractor = PpgDaliaExtractor(DATA_DIR)\n",
        "ppg_dalia_formatter = FormatPPGDalia()\n",
        "dfs_train = [ppg_dalia_formatter.transform(extractor.extract_subject(i)) for i in range(1,16)]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDUK1vToJWo",
        "outputId": "1a78fad3-b06f-4c2e-f85d-0945af1f4527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "importlib.reload(PPG.TrainerXY)\n",
        "importlib.reload(PPG.FullTrainer)\n",
        "importlib.reload(PPG.TrainerIS)\n",
        "\n",
        "from PPG import FullTrainer"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 10 (delta 5), reused 10 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects:  10% (1/10)   \rUnpacking objects:  20% (2/10)   \rUnpacking objects:  30% (3/10)   \rUnpacking objects:  40% (4/10)   \rUnpacking objects:  50% (5/10)   \rUnpacking objects:  60% (6/10)   \rUnpacking objects:  70% (7/10)   \rUnpacking objects:  80% (8/10)   \rUnpacking objects:  90% (9/10)   \rUnpacking objects: 100% (10/10)   \rUnpacking objects: 100% (10/10), done.\n",
            "From github.com:davipeag/HeartRateRegression\n",
            "   896229a..e9f4bfe  master     -> origin/master\n",
            "Updating 896229a..e9f4bfe\n",
            "Fast-forward\n",
            " Ensembles.py               | 22 \u001b[32m++++++++++++++++\u001b[m\n",
            " Optimization/Optimizers.py | 34 \u001b[32m+++++++++++++++++++++++++\u001b[m\n",
            " PPG/FullTrainer.py         | 62 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " test.py                    |  5 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 4 files changed, 121 insertions(+), 2 deletions(-)\n",
            " create mode 100644 Ensembles.py\n",
            " create mode 100644 Optimization/Optimizers.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdPECC3jYpjp"
      },
      "source": [
        "import random \n",
        "options = {\n",
        "  'nfeatures': [4],\n",
        "  'conv_filters': [64, 128, 256],\n",
        "  'nconv_layers': [1, 2, 3, 4],\n",
        "  'conv_dropout': [0, 0.1, 0.25,],\n",
        "  'nenc_layers': [1, 2, 3, 4],\n",
        "  'ndec_layers': [2, 3, 4],\n",
        "  'nhead': [1, 2, 4],\n",
        "  'feedforward_expansion': [1, 2, 4],\n",
        "  'nlin_layers': [2,3,4],\n",
        "  'lin_size': [16, 32, 64],\n",
        "  'lin_dropout': [0, 0.25, 0.5],\n",
        "  'lr': [0.001, 0.0001],\n",
        "  'weight_decay': [0, 0.00001],\n",
        "  'batch_size': [128, 256],\n",
        "  'ts_sub': [0],\n",
        "  'val_sub': [4]\n",
        " }\n",
        "\n",
        "def choose(options):\n",
        "  choice = dict()\n",
        "  for k,v in options.items():\n",
        "    choice[k] = random.choice(v)\n",
        "  return choice\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHTAXY6cdDZ6",
        "outputId": "beca7028-05b5-4311-ed03-db19d8f6b633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from  Optimization.Optimizers import RandomSearch\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "filename = \"joint_attentiontion_full_trainer_results.pkl\"\n",
        "save_path = os.path.join(STORE_DIR, filename)\n",
        "\n",
        "try:\n",
        "  with open(save_path, \"rb\") as f:\n",
        "    results = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "  results = list()\n",
        " \n",
        "searcher = RandomSearch(FullTrainer.JointValAttentionFullTrainer(dfs_train, args[\"device\"]), options)\n",
        "searcher.results = results\n",
        "while True:\n",
        "  searcher.fit(1)\n",
        "  with open(save_path, \"wb\") as f:\n",
        "    pickle.dump(searcher.results, f)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####\n",
            "Failed: {'nfeatures': 4, 'conv_filters': 256, 'nconv_layers': 3, 'conv_dropout': 0.1, 'nenc_layers': 1, 'ndec_layers': 3, 'nhead': 2, 'feedforward_expansion': 4, 'nlin_layers': 2, 'lin_size': 16, 'lin_dropout': 0.25, 'lr': 0.001, 'weight_decay': 1e-05, 'batch_size': 128, 'ts_sub': 0, 'val_sub': 4}\n",
            "###\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 15.744 loss_val 16.101 loss_ts 10.411\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 15.822 loss_val 16.061 loss_ts 9.784\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 12.490 loss_val 12.773 loss_ts 10.827\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 10.196 loss_val 10.437 loss_ts 11.107\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 9.793 loss_val 9.899 loss_ts 9.380\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 9.559 loss_val 9.750 loss_ts 9.443\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 8.954 loss_val 9.063 loss_ts 8.883\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 8.874 loss_val 9.041 loss_ts 8.890\n",
            "Final: 8.890214920043945\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 10.978 loss_val 11.174 loss_ts 16.977\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.804 loss_val 9.038 loss_ts 13.429\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 8.056 loss_val 8.311 loss_ts 11.929\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 7.733 loss_val 8.016 loss_ts 11.609\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 7.134 loss_val 7.319 loss_ts 12.794\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 6.323 loss_val 6.611 loss_ts 10.789\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 6.334 loss_val 6.600 loss_ts 10.974\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 5.638 loss_val 5.928 loss_ts 9.820\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 5.527 loss_val 5.818 loss_ts 9.576\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 4.495 loss_val 4.891 loss_ts 8.603\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 3.974 loss_val 4.450 loss_ts 8.564\n",
            "Final: 8.564207077026367\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 16.983 loss_val 17.134 loss_ts 12.192\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 16.928 loss_val 16.938 loss_ts 11.772\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 16.567 loss_val 16.541 loss_ts 11.845\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 16.656 loss_val 16.538 loss_ts 10.339\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 16.175 loss_val 16.124 loss_ts 11.721\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 16.035 loss_val 15.997 loss_ts 11.986\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 15.818 loss_val 15.764 loss_ts 11.710\n",
            "Final: 11.710244178771973\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 12.985 loss_val 12.740 loss_ts 12.903\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.921 loss_val 8.899 loss_ts 12.560\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 7.734 loss_val 7.618 loss_ts 9.986\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 7.168 loss_val 7.147 loss_ts 10.260\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 6.912 loss_val 6.880 loss_ts 10.370\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 6.481 loss_val 6.507 loss_ts 10.355\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 6.054 loss_val 6.153 loss_ts 10.677\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 5.876 loss_val 5.979 loss_ts 10.148\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 5.617 loss_val 5.784 loss_ts 10.281\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 5.278 loss_val 5.565 loss_ts 8.916\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 5.089 loss_val 5.525 loss_ts 8.710\n",
            "best val epoch: 22\n",
            "[22/30]: loss_train: 4.859 loss_val 5.333 loss_ts 9.015\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 4.552 loss_val 5.269 loss_ts 8.242\n",
            "Final: 8.241843223571777\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 9.716 loss_val 10.110 loss_ts 13.451\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.053 loss_val 8.264 loss_ts 10.201\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 7.877 loss_val 7.933 loss_ts 12.544\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 7.030 loss_val 7.113 loss_ts 10.116\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.963 loss_val 6.055 loss_ts 7.487\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.300 loss_val 5.430 loss_ts 8.111\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 4.786 loss_val 4.949 loss_ts 6.960\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 4.521 loss_val 4.646 loss_ts 5.372\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 4.116 loss_val 4.403 loss_ts 6.403\n",
            "Final: 6.403109073638916\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 17.490 loss_val 17.876 loss_ts 10.741\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 16.849 loss_val 17.245 loss_ts 11.428\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 16.423 loss_val 16.816 loss_ts 10.662\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 15.608 loss_val 15.944 loss_ts 10.259\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 14.778 loss_val 15.075 loss_ts 10.132\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 13.961 loss_val 14.233 loss_ts 10.747\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 13.830 loss_val 14.132 loss_ts 10.712\n",
            "best val epoch: 29\n",
            "[29/30]: loss_train: 13.336 loss_val 13.622 loss_ts 10.405\n",
            "Final: 10.405375480651855\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 13.986 loss_val 14.281 loss_ts 10.360\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 12.841 loss_val 13.147 loss_ts 10.536\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 12.846 loss_val 13.071 loss_ts 10.154\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 11.404 loss_val 11.649 loss_ts 9.839\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 9.981 loss_val 10.282 loss_ts 9.195\n",
            "Final: 9.195068359375\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.234 loss_val 14.463 loss_ts 14.292\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 12.469 loss_val 12.803 loss_ts 13.174\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 9.434 loss_val 9.278 loss_ts 11.682\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 9.044 loss_val 8.944 loss_ts 11.018\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 7.892 loss_val 7.849 loss_ts 10.463\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 7.348 loss_val 7.328 loss_ts 10.927\n",
            "best val epoch: 23\n",
            "[23/30]: loss_train: 6.728 loss_val 6.792 loss_ts 10.421\n",
            "Final: 10.420950889587402\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 17.569 loss_val 17.264 loss_ts 18.694\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 16.871 loss_val 16.609 loss_ts 13.186\n",
            "Final: 13.186417579650879\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.825 loss_val 14.768 loss_ts 10.601\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 13.622 loss_val 13.664 loss_ts 10.651\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 11.297 loss_val 11.345 loss_ts 9.686\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 10.784 loss_val 10.875 loss_ts 8.991\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 9.717 loss_val 9.691 loss_ts 9.275\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 9.568 loss_val 9.656 loss_ts 9.186\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 8.591 loss_val 8.559 loss_ts 9.160\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 8.426 loss_val 8.469 loss_ts 9.276\n",
            "Final: 9.276348114013672\n",
            "####\n",
            "Failed: {'nfeatures': 4, 'conv_filters': 128, 'nconv_layers': 3, 'conv_dropout': 0.1, 'nenc_layers': 4, 'ndec_layers': 3, 'nhead': 1, 'feedforward_expansion': 4, 'nlin_layers': 4, 'lin_size': 64, 'lin_dropout': 0.5, 'lr': 0.001, 'weight_decay': 0, 'batch_size': 256, 'ts_sub': 0, 'val_sub': 4}\n",
            "###\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.268 loss_val 14.812 loss_ts 13.064\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 11.823 loss_val 12.037 loss_ts 11.426\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 8.826 loss_val 9.056 loss_ts 11.720\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 8.396 loss_val 8.588 loss_ts 12.236\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 7.920 loss_val 8.301 loss_ts 9.969\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 7.204 loss_val 7.515 loss_ts 13.296\n",
            "best val epoch: 24\n",
            "[24/30]: loss_train: 7.056 loss_val 7.507 loss_ts 10.265\n",
            "Final: 10.264643669128418\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 11.945 loss_val 11.934 loss_ts 15.533\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 11.100 loss_val 11.307 loss_ts 17.112\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 8.980 loss_val 9.171 loss_ts 13.541\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 7.945 loss_val 8.054 loss_ts 13.281\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 6.885 loss_val 6.946 loss_ts 11.905\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 6.730 loss_val 6.845 loss_ts 13.026\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 6.328 loss_val 6.452 loss_ts 12.004\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 5.775 loss_val 6.089 loss_ts 11.530\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 5.649 loss_val 5.804 loss_ts 11.128\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 5.189 loss_val 5.456 loss_ts 10.111\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 4.853 loss_val 5.165 loss_ts 8.242\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 4.485 loss_val 4.817 loss_ts 7.900\n",
            "Final: 7.899688243865967\n",
            "####\n",
            "Failed: {'nfeatures': 4, 'conv_filters': 256, 'nconv_layers': 2, 'conv_dropout': 0.25, 'nenc_layers': 4, 'ndec_layers': 3, 'nhead': 1, 'feedforward_expansion': 4, 'nlin_layers': 4, 'lin_size': 64, 'lin_dropout': 0.5, 'lr': 0.0001, 'weight_decay': 0, 'batch_size': 256, 'ts_sub': 0, 'val_sub': 4}\n",
            "###\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.384 loss_val 14.492 loss_ts 12.212\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 11.851 loss_val 11.795 loss_ts 9.487\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 9.721 loss_val 9.742 loss_ts 9.909\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 9.129 loss_val 9.144 loss_ts 9.907\n",
            "Final: 9.906913757324219\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 19.083 loss_val 19.747 loss_ts 11.544\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 18.874 loss_val 19.522 loss_ts 11.132\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 18.477 loss_val 19.121 loss_ts 11.371\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 18.033 loss_val 18.647 loss_ts 11.279\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 17.518 loss_val 18.123 loss_ts 11.467\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 17.483 loss_val 18.070 loss_ts 11.016\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 17.460 loss_val 18.043 loss_ts 11.761\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 17.023 loss_val 17.585 loss_ts 11.891\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 16.988 loss_val 17.531 loss_ts 11.016\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 16.657 loss_val 17.161 loss_ts 11.635\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 16.466 loss_val 16.989 loss_ts 11.068\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 16.099 loss_val 16.557 loss_ts 11.496\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 15.424 loss_val 15.901 loss_ts 10.401\n",
            "Final: 10.400750160217285\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 16.325 loss_val 16.843 loss_ts 10.306\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 15.815 loss_val 16.233 loss_ts 10.984\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 13.452 loss_val 13.757 loss_ts 10.678\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 13.406 loss_val 13.719 loss_ts 10.461\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 12.968 loss_val 13.276 loss_ts 10.273\n",
            "best val epoch: 22\n",
            "[22/30]: loss_train: 11.869 loss_val 12.095 loss_ts 9.749\n",
            "Final: 9.74850845336914\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 17.815 loss_val 17.598 loss_ts 13.569\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 17.453 loss_val 17.268 loss_ts 13.046\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 17.067 loss_val 16.898 loss_ts 13.621\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 16.960 loss_val 16.803 loss_ts 12.585\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 16.862 loss_val 16.729 loss_ts 13.908\n",
            "best val epoch: 28\n",
            "[28/30]: loss_train: 16.815 loss_val 16.684 loss_ts 12.926\n",
            "best val epoch: 29\n",
            "[29/30]: loss_train: 16.813 loss_val 16.677 loss_ts 13.524\n",
            "Final: 13.524179458618164\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.055 loss_val 14.108 loss_ts 10.306\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 13.937 loss_val 13.907 loss_ts 9.836\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 11.703 loss_val 11.735 loss_ts 9.803\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 11.560 loss_val 11.504 loss_ts 10.146\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 11.352 loss_val 11.331 loss_ts 9.373\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 11.246 loss_val 11.166 loss_ts 8.498\n",
            "best val epoch: 25\n",
            "[25/30]: loss_train: 10.975 loss_val 10.924 loss_ts 7.118\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 10.923 loss_val 10.829 loss_ts 8.222\n",
            "best val epoch: 27\n",
            "[27/30]: loss_train: 10.720 loss_val 10.660 loss_ts 8.612\n",
            "Final: 8.612241744995117\n",
            "####\n",
            "Failed: {'nfeatures': 4, 'conv_filters': 256, 'nconv_layers': 4, 'conv_dropout': 0.25, 'nenc_layers': 4, 'ndec_layers': 4, 'nhead': 4, 'feedforward_expansion': 2, 'nlin_layers': 3, 'lin_size': 64, 'lin_dropout': 0.25, 'lr': 0.0001, 'weight_decay': 0, 'batch_size': 256, 'ts_sub': 0, 'val_sub': 4}\n",
            "###\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.030 loss_val 14.127 loss_ts 12.662\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.979 loss_val 9.041 loss_ts 11.443\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 8.138 loss_val 8.183 loss_ts 12.000\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 7.278 loss_val 7.526 loss_ts 11.198\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 7.111 loss_val 7.275 loss_ts 9.996\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 6.848 loss_val 7.096 loss_ts 9.955\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 6.697 loss_val 6.971 loss_ts 10.055\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 6.551 loss_val 6.869 loss_ts 11.986\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 6.354 loss_val 6.683 loss_ts 8.602\n",
            "best val epoch: 24\n",
            "[24/30]: loss_train: 5.766 loss_val 6.125 loss_ts 8.965\n",
            "best val epoch: 25\n",
            "[25/30]: loss_train: 5.453 loss_val 5.789 loss_ts 9.693\n",
            "Final: 9.692835807800293\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.390 loss_val 14.353 loss_ts 14.055\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 14.082 loss_val 14.090 loss_ts 12.043\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 12.712 loss_val 12.713 loss_ts 10.804\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 12.544 loss_val 12.641 loss_ts 10.880\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 12.441 loss_val 12.568 loss_ts 10.294\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 10.536 loss_val 10.552 loss_ts 9.982\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 9.963 loss_val 9.793 loss_ts 9.891\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 9.739 loss_val 9.562 loss_ts 9.489\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 8.831 loss_val 8.646 loss_ts 9.372\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 8.475 loss_val 8.266 loss_ts 10.039\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 8.170 loss_val 8.043 loss_ts 9.588\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 7.647 loss_val 7.561 loss_ts 9.548\n",
            "best val epoch: 16\n",
            "[16/30]: loss_train: 7.583 loss_val 7.467 loss_ts 10.313\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 7.382 loss_val 7.354 loss_ts 9.645\n",
            "best val epoch: 22\n",
            "[22/30]: loss_train: 7.088 loss_val 7.136 loss_ts 9.541\n",
            "best val epoch: 24\n",
            "[24/30]: loss_train: 6.742 loss_val 6.763 loss_ts 9.522\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 6.303 loss_val 6.455 loss_ts 9.111\n",
            "Final: 9.111244201660156\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 14.668 loss_val 14.433 loss_ts 12.108\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 12.411 loss_val 12.352 loss_ts 11.582\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 11.596 loss_val 11.550 loss_ts 9.971\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 9.917 loss_val 9.876 loss_ts 9.663\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 9.193 loss_val 9.067 loss_ts 9.697\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 8.968 loss_val 8.827 loss_ts 9.763\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 8.558 loss_val 8.517 loss_ts 11.000\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 8.170 loss_val 8.132 loss_ts 10.667\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 8.066 loss_val 8.031 loss_ts 10.321\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 7.893 loss_val 7.854 loss_ts 10.475\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 7.612 loss_val 7.625 loss_ts 9.761\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 7.190 loss_val 7.202 loss_ts 10.422\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 7.139 loss_val 7.172 loss_ts 10.954\n",
            "best val epoch: 22\n",
            "[22/30]: loss_train: 7.086 loss_val 7.110 loss_ts 10.199\n",
            "best val epoch: 24\n",
            "[24/30]: loss_train: 6.980 loss_val 7.017 loss_ts 10.314\n",
            "best val epoch: 28\n",
            "[28/30]: loss_train: 6.835 loss_val 6.905 loss_ts 9.442\n",
            "best val epoch: 30\n",
            "[30/30]: loss_train: 6.613 loss_val 6.726 loss_ts 10.076\n",
            "Final: 10.076183319091797\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 18.404 loss_val 18.029 loss_ts 13.132\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 17.683 loss_val 17.357 loss_ts 14.487\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 17.682 loss_val 17.356 loss_ts 14.489\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 17.668 loss_val 17.344 loss_ts 14.528\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 17.634 loss_val 17.312 loss_ts 14.630\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 17.614 loss_val 17.294 loss_ts 14.693\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 17.586 loss_val 17.266 loss_ts 14.788\n",
            "best val epoch: 27\n",
            "[27/30]: loss_train: 17.583 loss_val 17.264 loss_ts 14.797\n",
            "Final: 14.797235488891602\n",
            "####\n",
            "Failed: {'nfeatures': 4, 'conv_filters': 256, 'nconv_layers': 3, 'conv_dropout': 0.25, 'nenc_layers': 3, 'ndec_layers': 3, 'nhead': 2, 'feedforward_expansion': 2, 'nlin_layers': 4, 'lin_size': 64, 'lin_dropout': 0.25, 'lr': 0.0001, 'weight_decay': 0, 'batch_size': 256, 'ts_sub': 0, 'val_sub': 4}\n",
            "###\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 13.723 loss_val 13.926 loss_ts 17.679\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.595 loss_val 8.559 loss_ts 11.932\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 7.995 loss_val 8.111 loss_ts 11.230\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 6.901 loss_val 7.082 loss_ts 11.970\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 6.217 loss_val 6.429 loss_ts 11.028\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.965 loss_val 6.122 loss_ts 11.499\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 5.832 loss_val 6.076 loss_ts 10.609\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 5.411 loss_val 5.754 loss_ts 10.814\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 5.174 loss_val 5.679 loss_ts 9.673\n",
            "best val epoch: 29\n",
            "[29/30]: loss_train: 5.030 loss_val 5.608 loss_ts 9.585\n",
            "Final: 9.584559440612793\n",
            "####\n",
            "Failed: {'nfeatures': 4, 'conv_filters': 256, 'nconv_layers': 4, 'conv_dropout': 0.1, 'nenc_layers': 2, 'ndec_layers': 4, 'nhead': 2, 'feedforward_expansion': 4, 'nlin_layers': 3, 'lin_size': 64, 'lin_dropout': 0.5, 'lr': 0.0001, 'weight_decay': 0, 'batch_size': 256, 'ts_sub': 0, 'val_sub': 4}\n",
            "###\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 16.144 loss_val 16.295 loss_ts 10.506\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 14.540 loss_val 14.781 loss_ts 9.216\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 14.115 loss_val 14.342 loss_ts 9.063\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 13.344 loss_val 13.585 loss_ts 9.156\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 12.926 loss_val 13.236 loss_ts 9.137\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 12.886 loss_val 13.233 loss_ts 8.864\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 12.442 loss_val 12.780 loss_ts 8.760\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 10.717 loss_val 11.084 loss_ts 8.486\n",
            "Final: 8.485993385314941\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 13.778 loss_val 14.331 loss_ts 17.682\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 8.675 loss_val 8.964 loss_ts 12.735\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 8.180 loss_val 8.580 loss_ts 12.919\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 7.214 loss_val 7.619 loss_ts 10.998\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 6.387 loss_val 6.935 loss_ts 11.272\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 6.224 loss_val 6.856 loss_ts 10.145\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.754 loss_val 6.406 loss_ts 9.846\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 5.447 loss_val 6.164 loss_ts 10.186\n",
            "best val epoch: 13\n",
            "[13/30]: loss_train: 5.143 loss_val 5.855 loss_ts 9.017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YFiismva8BL",
        "outputId": "0aace75c-de78-450c-ca46-e8435236087e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "from PPG.FullTrainer import JointValAttentionFullTrainer\n",
        "while True:\n",
        "  full_trainer = FullTrainer.JointValAttentionFullTrainer(dfs_train, args[\"device\"])\n",
        "  out = full_trainer.train(**choose(options))\n",
        "  print(out[\"args\"], out[\"metric\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best val epoch: 1\n",
            "[1/30]: loss_train: 15.961 loss_val 15.448 loss_ts 10.991\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 15.638 loss_val 15.230 loss_ts 10.613\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 14.188 loss_val 13.952 loss_ts 9.869\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 13.723 loss_val 13.501 loss_ts 9.882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5747caad479e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfull_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJointValAttentionFullTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mchoose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metric\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/HeartRateRegression/PPG/FullTrainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nfeatures, conv_filters, nconv_layers, conv_dropout, nenc_layers, ndec_layers, nhead, feedforward_expansion, nlin_layers, lin_size, lin_dropout, lr, weight_decay, batch_size, ts_sub, val_sub)\u001b[0m\n\u001b[1;32m    126\u001b[0m             epoch_trainer, loader_tr, loader_val, loader_ts, metrics_comuter.mae)\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         p = [metrics_comuter.inverse_transform_label(v)\n",
            "\u001b[0;32m/tmp/HeartRateRegression/PPG/TrainerXY.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epoch)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/HeartRateRegression/PPG/TrainerXY.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/HeartRateRegression/PPG/TrainerXY.py\u001b[0m in \u001b[0;36mapply_to_batches\u001b[0;34m(self, function, loader)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_to_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/HeartRateRegression/PPG/TrainerXY.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_to_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/HeartRateRegression/PPG/TrainerXY.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFOG4ar9WYpt"
      },
      "source": [
        "full_trainer = FullTrainer.AttentionFullTrainer(dfs_train, args[\"device\"], 0, 1)\n",
        "\n",
        "full_trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYVLTnMGXYGp"
      },
      "source": [
        "from PPG import UtilitiesDataXY \n",
        "\n",
        "\n",
        "transformers = PPG.AttentionDefaults.get_preprocessing_transformer()\n",
        "make_loaders = UtilitiesDataXY.DataLoaderFactory(transformers, dfs_train).make_loaders\n",
        "\n",
        "loader_tr, loader_val, loader_ts = make_loaders(ts_sub=0, val_sub=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Vr-YDyoGfH"
      },
      "source": [
        "from PPG.Models import SnippetConvolutionalTransformer\n",
        "\n",
        "net = SnippetConvolutionalTransformer().to(args[\"device\"])\n",
        "\n",
        "# x,y = next(iter(loader_tr))\n",
        "\n",
        "# p = net(x)\n",
        "\n",
        "criterion = nn.MSELoss().to(args[\"device\"])# nn.L1Loss().to(args[\"device\"]) #nn.CrossEntropyLoss().to(args[\"device\"])\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=args[\"lr\"],\n",
        "                             weight_decay=args[\"weight_decay\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ktvTpTaOcy"
      },
      "source": [
        "from PPG.TrainerXY import (EpochTrainerXY, MetricsComputerXY, TrainHelperXY)\n",
        "from preprocessing_utils import ZTransformer2\n",
        "\n",
        "epoch_trainer = EpochTrainerXY(net, optimizer, criterion, args[\"device\"])\n",
        "ztransformer = ZTransformer2(['heart_rate', 'wrist-ACC-0', 'wrist-ACC-1', 'wrist-ACC-2',\n",
        "              'wrist-BVP-0', 'wrist-EDA-0', 'wrist-TEMP-0', 'chest-ACC-0',\n",
        "              'chest-ACC-1', 'chest-ACC-2', 'chest-Resp-0'])\n",
        "metrics_comuter = MetricsComputerXY(ztransformer)\n",
        "\n",
        "train_helper = TrainHelperXY(epoch_trainer, loader_tr, loader_val, loader_ts, metrics_comuter.mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lyVMlfzkaFA"
      },
      "source": [
        "train_helper.train(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG0tSXLWPuCQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}