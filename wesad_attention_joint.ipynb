{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "ppg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg4pPcCWcJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0381212-8c96-4693-b6bb-622353367f02"
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=d1dc81cecdec71293b1dbc81155dbd90e97fb4f6afecd43e93ea8ddc89bda71d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Unix-like\n",
            "Mounted at /content/drive\n",
            "Cloning into 'HeartRateRegression'...\n",
            "Warning: Permanently added 'github.com,140.82.113.4' (RSA) to the list of known hosts.\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 1040 (delta 9), reused 17 (delta 7), pack-reused 1020\u001b[K\n",
            "Receiving objects: 100% (1040/1040), 88.32 MiB | 34.18 MiB/s, done.\n",
            "Resolving deltas: 100% (677/677), done.\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.112.4' to the list of known hosts.\n",
            "Already up to date.\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.114.3' to the list of known hosts.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFiZv0xM1pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b38805-89e9-40f9-9dd0-c4f8dc9681b1"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = {\n",
        "    'epoch_num': 250,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 0,     # Number of workers on data loader.\n",
        "    'batch_size': 128,     # Mini-batch size. 128\n",
        "    'batch_test': 248,     # size of test batch\n",
        "    'window': 15,\n",
        "    'initial_window':5,\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seeds()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WJogg0JO2PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188c3c37-97e4-4e5d-f00e-e9f927cadb69"
      },
      "source": [
        "!pip install heartpy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting heartpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/1c/8a00260626770b4ec5980942df2c3b0ba7f0f56d77ff9b7ac5f241d646b5/heartpy-1.2.6-py3-none-any.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 29.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 35.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 35.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 37.2MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 39.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 29.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 26.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 27.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 25.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 25.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 25.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133kB 25.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143kB 25.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 235kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 256kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 327kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 337kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 419kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 430kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 450kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 460kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 471kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 522kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 532kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 542kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 552kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 563kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 573kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 583kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 593kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 645kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 655kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 675kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 686kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 706kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 737kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 747kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 757kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 768kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 778kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 788kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 798kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 808kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 819kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 829kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 839kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 849kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 860kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 870kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 880kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 890kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 901kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 911kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 921kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 931kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 942kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 962kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 972kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 993kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0MB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 25.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from heartpy) (3.2.2)\n",
            "Requirement already satisfied: scipy; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from heartpy) (1.4.1)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from heartpy) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->heartpy) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->heartpy) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->heartpy) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->heartpy) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib; python_version >= \"3.6\"->heartpy) (1.15.0)\n",
            "Installing collected packages: heartpy\n",
            "Successfully installed heartpy-1.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V97F8pWmvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f6d976-cd35-4415-d443-a85f70f7622d"
      },
      "source": [
        "from data_utils import (FormatPPGDalia, WesadExtractor, PpgDaliaExtractor)\n",
        "\n",
        "\n",
        "SUBJECTS_WESAD = [2,3,4,5,6,7,8,9,10,11,13,14,15,16,17]\n",
        "SUBJECTS_DALIA = [1,2,3,4,5,6,7, 9, 10, 11, 12, 13, 14, 15]\n",
        "\n",
        "extractor = WesadExtractor(DATA_DIR)\n",
        "formatter = FormatPPGDalia(from_ecg = True)\n",
        "dfs_wesad = [formatter.transform(extractor.extract_subject(i)) for i in SUBJECTS_WESAD]\n",
        "\n",
        "dalia_extractor = PpgDaliaExtractor(DATA_DIR)\n",
        "dalia_formater =  FormatPPGDalia()\n",
        "dfs_dalia = [dalia_formater.transform(dalia_extractor.extract_subject(i)) for i in SUBJECTS_DALIA]\n",
        "\n",
        "dfs_train = dfs_wesad + dfs_dalia"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/ma/core.py:5216: RuntimeWarning: Mean of empty slice.\n",
            "  dtype=dtype, **kwargs)[()]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3584: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:232: UserWarning: \n",
            "The maximal number of iterations maxit (set to 20 by the program)\n",
            "allowed for finding a smoothing spline with fp=s has been reached: s\n",
            "too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlpdOPNJAFdH"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDUK1vToJWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b28ded9-3e64-4cb2-b11b-3d077a0d3bfc"
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "\n",
        "from PPG import FullTrainer\n",
        "\n",
        "importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "importlib.reload(PPG.NoHrPceLstmModel)\n",
        "importlib.reload(PPG.TrainerXY)\n",
        "importlib.reload(PPG.TrainerIS)\n",
        "importlib.reload(PPG.FullTrainer)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'PPG.FullTrainer' from '/tmp/HeartRateRegression/PPG/FullTrainer.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7zop0WGrHb",
        "outputId": "f07efd67-8181-42a7-db26-79c7217ed28f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "  # ensembler = SimpleEnsemble()\n",
        "\n",
        "def compute_ensemble(results):\n",
        "  ps = [v[\"predictions\"][1].reshape(-1).numpy() for v in results]\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  return np.mean(np.abs(a - y))\n",
        "\n",
        "\n",
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0,\n",
        "  'lr': 0.0001,\n",
        "  'lin_dropout': 0,\n",
        "  'lin_size': 16,\n",
        "  'nlin_layers': 2,\n",
        "  'feedforward_expansion': 1,\n",
        "  'nhead': 4,\n",
        "  'ndec_layers': 2,\n",
        "  'nenc_layers': 2,\n",
        "  'conv_dropout': 0,\n",
        "  'nconv_layers': 2,\n",
        "  'conv_filters': 128,\n",
        "  'nfeatures': 4\n",
        "}\n",
        "\n",
        "\n",
        "from PPG import UtilitiesDataXY\n",
        "from collections import defaultdict\n",
        "\n",
        "aresults = defaultdict(list)\n",
        "\n",
        "for i in range(7):\n",
        "  for ts_sub in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]:\n",
        "    filename = f\"wesad_attention_output_ts_{ts_sub}_{i}_from_ecg_joint_single_shot.pkl\"\n",
        "    save_path = os.path.join(STORE_DIR, filename)\n",
        "    try:\n",
        "      with open(save_path , \"rb\") as f:\n",
        "        out = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "      full_trainer = FullTrainer.JointValAttentionFullTrainer(dfs_train, args[\"device\"], nepoch=30)\n",
        "    else:\n",
        "      aresults[ts_sub].append(out)\n",
        "      print(out[\"args\"], out[\"metric\"])\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      fchoice[\"ts_sub\"] = ts_sub\n",
        "      out = full_trainer.train(**fchoice)\n",
        "      # full_trainer.dfs = dfs_wesad\n",
        "      # out = full_trainer.train(**fchoice)\n",
        "      print(out[\"args\"], out[\"metric\"])\n",
        "      aresults[ts_sub].append(out)\n",
        "      \n",
        "      \n",
        "      with open(save_path, \"wb\") as f:\n",
        "        pickle.dump(out, f)\n",
        "\n",
        "    except RuntimeError as e:\n",
        "      if isinstance(e, KeyboardInterrupt):\n",
        "        raise e\n",
        "      else:\n",
        "        print(\"####\")\n",
        "        print(f\"Failed: {fchoice}\")\n",
        "        print(\"###\")\n",
        "  print(f\"TS:{compute_ensemble(dresults)}\")\n",
        "  aresults[ts_sub].append(dresults)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 8.949734\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 7.867 loss_val 7.883 loss_ts 17.918\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.300 loss_val 7.322 loss_ts 17.148\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.439 loss_val 6.512 loss_ts 15.858\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.262 loss_val 6.317 loss_ts 15.493\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 6.194 loss_val 6.279 loss_ts 19.126\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 6.170 loss_val 6.263 loss_ts 20.043\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.576 loss_val 5.673 loss_ts 18.168\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 5.404 loss_val 5.544 loss_ts 15.709\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 5.361 loss_val 5.516 loss_ts 21.792\n",
            "best val epoch: 15\n",
            "[15/30]: loss_train: 5.075 loss_val 5.288 loss_ts 16.845\n",
            "best val epoch: 18\n",
            "[18/30]: loss_train: 5.041 loss_val 5.283 loss_ts 15.249\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 5.020 loss_val 5.270 loss_ts 17.171\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 4.814 loss_val 5.073 loss_ts 17.444\n",
            "best val epoch: 23\n",
            "[23/30]: loss_train: 4.603 loss_val 4.971 loss_ts 18.372\n",
            "best val epoch: 25\n",
            "[25/30]: loss_train: 4.543 loss_val 4.908 loss_ts 17.394\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 4.533 loss_val 4.907 loss_ts 14.977\n",
            "best val epoch: 28\n",
            "[28/30]: loss_train: 4.552 loss_val 4.875 loss_ts 18.225\n",
            "Final: 18.224918365478516\n",
            "{'val_sub': 4, 'ts_sub': 1, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 18.224918\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 9.267 loss_val 9.218 loss_ts 13.280\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.535 loss_val 7.565 loss_ts 13.959\n",
            "best val epoch: 3\n",
            "[3/30]: loss_train: 6.954 loss_val 6.997 loss_ts 11.955\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 6.105 loss_val 6.213 loss_ts 12.959\n",
            "best val epoch: 10\n",
            "[10/30]: loss_train: 5.841 loss_val 6.038 loss_ts 11.400\n",
            "best val epoch: 11\n",
            "[11/30]: loss_train: 5.514 loss_val 5.751 loss_ts 9.775\n",
            "best val epoch: 14\n",
            "[14/30]: loss_train: 5.441 loss_val 5.728 loss_ts 15.535\n",
            "best val epoch: 17\n",
            "[17/30]: loss_train: 5.370 loss_val 5.676 loss_ts 8.618\n",
            "best val epoch: 19\n",
            "[19/30]: loss_train: 5.305 loss_val 5.621 loss_ts 10.395\n",
            "best val epoch: 20\n",
            "[20/30]: loss_train: 5.220 loss_val 5.553 loss_ts 11.975\n",
            "best val epoch: 21\n",
            "[21/30]: loss_train: 5.176 loss_val 5.507 loss_ts 15.074\n",
            "best val epoch: 23\n",
            "[23/30]: loss_train: 5.094 loss_val 5.395 loss_ts 10.882\n",
            "best val epoch: 26\n",
            "[26/30]: loss_train: 4.885 loss_val 5.310 loss_ts 12.464\n",
            "Final: 12.463979721069336\n",
            "{'val_sub': 4, 'ts_sub': 2, 'batch_size': 64, 'weight_decay': 0, 'lr': 0.0001, 'lin_dropout': 0, 'lin_size': 16, 'nlin_layers': 2, 'feedforward_expansion': 1, 'nhead': 4, 'ndec_layers': 2, 'nenc_layers': 2, 'conv_dropout': 0, 'nconv_layers': 2, 'conv_filters': 128, 'nfeatures': 4} 12.46398\n",
            "best val epoch: 1\n",
            "[1/30]: loss_train: 8.099 loss_val 8.128 loss_ts 10.121\n",
            "best val epoch: 2\n",
            "[2/30]: loss_train: 7.130 loss_val 7.213 loss_ts 8.752\n",
            "best val epoch: 4\n",
            "[4/30]: loss_train: 6.617 loss_val 6.726 loss_ts 8.547\n",
            "best val epoch: 5\n",
            "[5/30]: loss_train: 6.358 loss_val 6.456 loss_ts 10.074\n",
            "best val epoch: 6\n",
            "[6/30]: loss_train: 6.302 loss_val 6.387 loss_ts 8.964\n",
            "best val epoch: 7\n",
            "[7/30]: loss_train: 6.186 loss_val 6.292 loss_ts 9.435\n",
            "best val epoch: 8\n",
            "[8/30]: loss_train: 5.809 loss_val 5.963 loss_ts 9.066\n",
            "best val epoch: 9\n",
            "[9/30]: loss_train: 5.725 loss_val 5.904 loss_ts 9.584\n",
            "best val epoch: 12\n",
            "[12/30]: loss_train: 5.405 loss_val 5.561 loss_ts 9.450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odb81F6V6OnM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}