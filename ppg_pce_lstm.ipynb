{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "ppg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg4pPcCWcJR",
        "outputId": "7f97809e-3055-4641-f02c-02a233dfec9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=601d26a0b772f87a5401500ba44caebecfbae8ebd8ce1067788fc5794d7e8b97\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Unix-like\n",
            "Mounted at /content/drive\n",
            "Cloning into 'HeartRateRegression'...\n",
            "Warning: Permanently added 'github.com,192.30.255.113' (RSA) to the list of known hosts.\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 1011 (delta 195), reused 151 (delta 78), pack-reused 719\u001b[K\n",
            "Receiving objects: 100% (1011/1011), 88.37 MiB | 31.56 MiB/s, done.\n",
            "Resolving deltas: 100% (651/651), done.\n",
            "Already up to date.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFiZv0xM1pa",
        "outputId": "e2160607-b2c2-4e36-8807-949d4d2b035d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = {\n",
        "    'epoch_num': 250,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 0,     # Number of workers on data loader.\n",
        "    'batch_size': 128,     # Mini-batch size. 128\n",
        "    'batch_test': 248,     # size of test batch\n",
        "    'window': 15,\n",
        "    'initial_window':5,\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seeds()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V97F8pWmvK",
        "outputId": "cd8602aa-ea31-4c8f-b329-b12dc4ecff4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data_utils import (PpgDaliaExtractor, FormatPPGDalia)\n",
        "\n",
        "extractor = PpgDaliaExtractor(DATA_DIR)\n",
        "ppg_dalia_formatter = FormatPPGDalia()\n",
        "dfs_train = [ppg_dalia_formatter.transform(extractor.extract_subject(i)) for i in range(1,16)]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDUK1vToJWo",
        "outputId": "90a8f550-e2b8-48b6-dbe5-2e71ec165d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "\n",
        "from PPG import FullTrainer\n",
        "\n",
        "importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "importlib.reload(PPG.NoHrPceLstmModel)\n",
        "importlib.reload(PPG.TrainerXY)\n",
        "importlib.reload(PPG.TrainerIS)\n",
        "importlib.reload(PPG.FullTrainer)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Permanently added the RSA host key for IP address '192.30.255.112' to the list of known hosts.\r\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'PPG.FullTrainer' from '/tmp/HeartRateRegression/PPG/FullTrainer.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7zop0WGrHb",
        "outputId": "da48a5d9-04a1-408b-f6f8-920dff90b23d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "# fchoice = {'val_sub': 4,\n",
        "#   'ts_sub': 0,\n",
        "#   'batch_size': 64,\n",
        "#   'weight_decay': 0,\n",
        "#   'lr': 0.001,\n",
        "#   'nattrs': 5,\n",
        "#   'bvp_count': 16,\n",
        "#   'dropout_rate': 0.25,\n",
        "#   'lstm_input': 128,\n",
        "#   'lstm_size': 64,\n",
        "#   'ts_h_size': 64\n",
        "#   }\n",
        "def compute_ensemble(results):\n",
        "  ps = np.stack([v[\"predictions\"][1].reshape(-1).numpy() for v in results])\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  return np.mean(np.abs(a - y)), np.mean(np.abs(ps - y))\n",
        "\n",
        "\n",
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0.0001,\n",
        "  'lr': 0.001,\n",
        "  'nattrs': 5,\n",
        "  'bvp_count': 12,\n",
        "  'dropout_rate': 0,\n",
        "  'lstm_input': 128,\n",
        "  'lstm_size': 32,\n",
        "  'ts_h_size': 32\n",
        "  }\n",
        "\n",
        "\n",
        "from PPG import UtilitiesDataXY\n",
        "from collections import defaultdict\n",
        "\n",
        "aresults = defaultdict(list)\n",
        "for i in range(7):\n",
        "  for ts_sub in [0,1,2,3, 4,5,6,7,8,9,10,11,12,13,14]:\n",
        "    filename = f\"dalia_ts_{ts_sub}_{i}_from_ecg_period2_.pkl\"\n",
        "    save_path = os.path.join(STORE_DIR, filename)\n",
        "    try:\n",
        "      with open(save_path , \"rb\") as f:\n",
        "        out = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "      full_trainer = FullTrainer.JointValNoHrPceLstmFullTrainer(dfs_train, args[\"device\"])\n",
        "      try:\n",
        "        fchoice[\"ts_sub\"] = ts_sub\n",
        "        out = full_trainer.train(**fchoice)\n",
        "        \n",
        "        with open(save_path, \"wb\") as f:\n",
        "          pickle.dump(out, f)\n",
        "\n",
        "      except RuntimeError as e:\n",
        "        if isinstance(e, KeyboardInterrupt):\n",
        "          raise e\n",
        "        else:\n",
        "          print(\"####\")\n",
        "          print(f\"Failed: {choice}\")\n",
        "          print(\"###\")\n",
        "    \n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    aresults[ts_sub].append(out)\n",
        "    print(f\"{ts_sub}-TS:{compute_ensemble(aresults[ts_sub])}\")\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 5.645121\n",
            "0-TS:(5.645121, 5.645121)\n",
            "{'val_sub': 4, 'ts_sub': 1, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.7695744\n",
            "1-TS:(3.7695744, 3.7695744)\n",
            "{'val_sub': 4, 'ts_sub': 2, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 2.5999687\n",
            "2-TS:(2.5999687, 2.5999687)\n",
            "{'val_sub': 4, 'ts_sub': 3, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 5.646535\n",
            "3-TS:(5.646535, 5.646535)\n",
            "{'val_sub': 4, 'ts_sub': 4, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 14.475673\n",
            "4-TS:(14.475673, 14.475673)\n",
            "{'val_sub': 4, 'ts_sub': 5, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.531871\n",
            "5-TS:(3.531871, 3.531871)\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 2.8642764\n",
            "6-TS:(2.8642764, 2.8642764)\n",
            "{'val_sub': 4, 'ts_sub': 7, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 6.94611\n",
            "7-TS:(6.94611, 6.94611)\n",
            "{'val_sub': 4, 'ts_sub': 8, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 8.126204\n",
            "8-TS:(8.126204, 8.126204)\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 2.7868276\n",
            "9-TS:(2.7868276, 2.7868276)\n",
            "{'val_sub': 4, 'ts_sub': 10, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 7.592152\n",
            "10-TS:(7.592152, 7.592152)\n",
            "{'val_sub': 4, 'ts_sub': 11, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 6.660283\n",
            "11-TS:(6.660283, 6.660283)\n",
            "{'val_sub': 4, 'ts_sub': 12, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.622669\n",
            "12-TS:(3.622669, 3.622669)\n",
            "{'val_sub': 4, 'ts_sub': 13, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 4.6309094\n",
            "13-TS:(4.6309094, 4.6309094)\n",
            "{'val_sub': 4, 'ts_sub': 14, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.7771509\n",
            "14-TS:(3.7771509, 3.7771509)\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 5.678279\n",
            "0-TS:(5.607268, 5.6617002)\n",
            "{'val_sub': 4, 'ts_sub': 1, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.420264\n",
            "1-TS:(3.3892453, 3.5949192)\n",
            "{'val_sub': 4, 'ts_sub': 2, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 2.6933603\n",
            "2-TS:(2.5353684, 2.6466644)\n",
            "{'val_sub': 4, 'ts_sub': 3, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 5.695152\n",
            "3-TS:(5.2341313, 5.6708436)\n",
            "{'val_sub': 4, 'ts_sub': 4, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 9.962615\n",
            "4-TS:(11.896001, 12.219143)\n",
            "{'val_sub': 4, 'ts_sub': 5, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 6.8443823\n",
            "5-TS:(4.9004307, 5.1881266)\n",
            "{'val_sub': 4, 'ts_sub': 6, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 2.599001\n",
            "6-TS:(2.6030009, 2.7316387)\n",
            "{'val_sub': 4, 'ts_sub': 7, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 6.6865897\n",
            "7-TS:(6.7054977, 6.8163495)\n",
            "{'val_sub': 4, 'ts_sub': 8, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 6.9268084\n",
            "8-TS:(7.2664566, 7.526506)\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.064951\n",
            "9-TS:(2.5373905, 2.9258895)\n",
            "{'val_sub': 4, 'ts_sub': 10, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 9.487566\n",
            "10-TS:(8.196672, 8.539858)\n",
            "{'val_sub': 4, 'ts_sub': 11, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 10.709357\n",
            "11-TS:(8.399096, 8.68482)\n",
            "{'val_sub': 4, 'ts_sub': 12, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.1246686\n",
            "12-TS:(3.2233856, 3.3736687)\n",
            "{'val_sub': 4, 'ts_sub': 13, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 4.0845695\n",
            "13-TS:(3.9821029, 4.3577394)\n",
            "{'val_sub': 4, 'ts_sub': 14, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.8525922\n",
            "14-TS:(3.704001, 3.8148718)\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 5.5010843\n",
            "0-TS:(5.5274825, 5.608162)\n",
            "{'val_sub': 4, 'ts_sub': 1, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'nattrs': 5, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.775381\n",
            "1-TS:(3.4078734, 3.6550734)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7RYiJL3nh-"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjYv8BlUKYnM"
      },
      "source": [
        "\n",
        "def compute_ensemble(results):\n",
        "  ps = [v[\"predictions\"][1].reshape(-1).numpy() for v in results]\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  np.mean(np.abs(a - y))\n",
        "\n",
        "compute_ensemble(dresults)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# p = p.reshape(-1)\n",
        "\n",
        "# plt.plot(y)\n",
        "# plt.plot(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdPECC3jYpjp"
      },
      "source": [
        "import random \n",
        "options = {\n",
        "  \"ts_h_size\": [64, 128],\n",
        "  \"lstm_size\": [64, 64, 128],\n",
        "  \"lstm_input\": [64, 128, 256],\n",
        "  \"dropout_rate\": [0.25],\n",
        "  \"bvp_count\": [8,16],\n",
        "  \"nattrs\": [5],\n",
        "  'lr': [0.001],\n",
        "  'weight_decay': [0, 0.0001],\n",
        "  'batch_size': [64, 128, 256],\n",
        "  'ts_sub': [0],\n",
        "  'val_sub': [4]\n",
        " }\n",
        "\n",
        "def choose(options):\n",
        "  choice = dict()\n",
        "  for k,v in options.items():\n",
        "    choice[k] = random.choice(v)\n",
        "  return choice\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYFUSi1-4nzj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YFiismva8BL"
      },
      "source": [
        "results = list()\n",
        "from PPG import UtilitiesDataXY\n",
        "while True:\n",
        "  full_trainer = FullTrainer.NoHrPceLstmFullTrainer(dfs_train, args[\"device\"])\n",
        "  choice = choose(options)\n",
        "  try:\n",
        "    out = full_trainer.train(**choice)\n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    results.append([out[\"args\"], out[\"metric\"]])\n",
        "  except RuntimeError as e:\n",
        "    if isinstance(e, KeyboardInterrupt):\n",
        "      raise e\n",
        "    else:\n",
        "      print(\"####\")\n",
        "      print(f\"Failed: {choice}\")\n",
        "      print(\"###\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNTrC3_M2D-Z"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chhDawFV_14T"
      },
      "source": [
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0,\n",
        "  'lr': 0.001,\n",
        "  'nattrs': 5,\n",
        "  'bvp_count': 16,\n",
        "  'dropout_rate': 0.25,\n",
        "  'lstm_input': 128,\n",
        "  'lstm_size': 64,\n",
        "  'ts_h_size': 64}\n",
        "\n",
        "\n",
        "dresults = list()\n",
        "from PPG import UtilitiesDataXY\n",
        "ts_sub = 3\n",
        "for val_sub in [i for i in range(15) if i != ts_sub]:\n",
        "  full_trainer = FullTrainer.NoHrPceLstmFullTrainer(dfs_train, args[\"device\"])\n",
        "  try:\n",
        "    fchoice[\"ts_sub\"] = ts_sub\n",
        "    fchoice[\"val_sub\"] = val_sub\n",
        "    out = full_trainer.train(**fchoice)\n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    dresults.append([out])\n",
        "  except RuntimeError as e:\n",
        "    if isinstance(e, KeyboardInterrupt):\n",
        "      raise e\n",
        "    else:\n",
        "      print(\"####\")\n",
        "      print(f\"Failed: {choice}\")\n",
        "      print(\"###\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxjMx66OD9T9"
      },
      "source": [
        "y = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFOG4ar9WYpt"
      },
      "source": [
        "full_trainer = FullTrainer.AttentionFullTrainer(dfs_train, args[\"device\"], 0, 1)\n",
        "\n",
        "full_trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYVLTnMGXYGp"
      },
      "source": [
        "from PPG import UtilitiesDataXY \n",
        "\n",
        "\n",
        "transformers = PPG.AttentionDefaults.get_preprocessing_transformer()\n",
        "make_loaders = UtilitiesDataXY.DataLoaderFactory(transformers, dfs_train).make_loaders\n",
        "\n",
        "loader_tr, loader_val, loader_ts = make_loaders(ts_sub=0, val_sub=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Vr-YDyoGfH"
      },
      "source": [
        "from PPG.Models import SnippetConvolutionalTransformer\n",
        "\n",
        "net = SnippetConvolutionalTransformer().to(args[\"device\"])\n",
        "\n",
        "# x,y = next(iter(loader_tr))\n",
        "\n",
        "# p = net(x)\n",
        "\n",
        "criterion = nn.MSELoss().to(args[\"device\"])# nn.L1Loss().to(args[\"device\"]) #nn.CrossEntropyLoss().to(args[\"device\"])\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=args[\"lr\"],\n",
        "                             weight_decay=args[\"weight_decay\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ktvTpTaOcy"
      },
      "source": [
        "from PPG.TrainerXY import (EpochTrainerXY, MetricsComputerXY, TrainHelperXY)\n",
        "from preprocessing_utils import ZTransformer2\n",
        "\n",
        "epoch_trainer = EpochTrainerXY(net, optimizer, criterion, args[\"device\"])\n",
        "ztransformer = ZTransformer2(['heart_rate', 'wrist-ACC-0', 'wrist-ACC-1', 'wrist-ACC-2',\n",
        "              'wrist-BVP-0', 'wrist-EDA-0', 'wrist-TEMP-0', 'chest-ACC-0',\n",
        "              'chest-ACC-1', 'chest-ACC-2', 'chest-Resp-0'])\n",
        "metrics_comuter = MetricsComputerXY(ztransformer)\n",
        "\n",
        "train_helper = TrainHelperXY(epoch_trainer, loader_tr, loader_val, loader_ts, metrics_comuter.mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lyVMlfzkaFA"
      },
      "source": [
        "train_helper.train(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG0tSXLWPuCQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}