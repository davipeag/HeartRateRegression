{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "ppg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg4pPcCWcJR",
        "outputId": "322e4857-c136-4152-97b1-09355a17aad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n",
            "Unix-like\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.ssh’: File exists\n",
            "fatal: destination path 'HeartRateRegression' already exists and is not an empty directory.\n",
            "Already up to date.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFiZv0xM1pa",
        "outputId": "3ecc2d56-d561-4ad3-9121-d19a67295adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = {\n",
        "    'epoch_num': 250,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 0,     # Number of workers on data loader.\n",
        "    'batch_size': 128,     # Mini-batch size. 128\n",
        "    'batch_test': 248,     # size of test batch\n",
        "    'window': 15,\n",
        "    'initial_window':5,\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seeds()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V97F8pWmvK",
        "outputId": "309ac6d5-83f4-4433-bf58-b67fd59c9997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data_utils import (FormatIeee,  IeeeExtractorTest)\n",
        "\n",
        "SUBJECTS = list(range(1,10))\n",
        "\n",
        "extractor = IeeeExtractorTest(DATA_DIR)\n",
        "formatter = FormatIeee()\n",
        "dfs_train = [formatter.transform(extractor.extract_subject(i)) for i in SUBJECTS]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDUK1vToJWo",
        "outputId": "9f79abf5-4c0d-4b15-e935-ee6bf450f777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "\n",
        "from PPG import FullTrainer\n",
        "\n",
        "importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "importlib.reload(PPG.NoHrPceLstmModel)\n",
        "importlib.reload(PPG.TrainerXY)\n",
        "importlib.reload(PPG.TrainerIS)\n",
        "importlib.reload(PPG.FullTrainer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'PPG.FullTrainer' from '/tmp/HeartRateRegression/PPG/FullTrainer.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7zop0WGrHb",
        "outputId": "ed08642a-824c-4a2c-df95-966a97ea7ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "# fchoice = {'val_sub': 4,\n",
        "#   'ts_sub': 0,\n",
        "#   'batch_size': 64,\n",
        "#   'weight_decay': 0,\n",
        "#   'lr': 0.001,\n",
        "#   'nattrs': 5,\n",
        "#   'bvp_count': 16,\n",
        "#   'dropout_rate': 0.25,\n",
        "#   'lstm_input': 128,\n",
        "#   'lstm_size': 64,\n",
        "#   'ts_h_size': 64\n",
        "#   }\n",
        "def compute_ensemble(results):\n",
        "  ps = [v[\"predictions\"][1].reshape(-1).numpy() for v in results]\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  return np.mean(np.abs(a - y))\n",
        "\n",
        "\n",
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0.0001,\n",
        "  'lr': 0.001,\n",
        "  'nattrs': 6,\n",
        "  'bvp_count': 12,\n",
        "  'dropout_rate': 0,\n",
        "  'lstm_input': 128,\n",
        "  'lstm_size': 32,\n",
        "  'ts_h_size': 32\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "from PPG import UtilitiesDataXY\n",
        "\n",
        "\n",
        "aresults = list()\n",
        "for ts_sub in [0,1,2,3, 4,5,6,7,8,9]:\n",
        "  dresults = list()\n",
        "  for i in range(7):\n",
        "    filename = f\"ieee_test_ts_{ts_sub}_{i}_pce_lstm_12\"\n",
        "    save_path = os.path.join(STORE_DIR, filename)\n",
        "    try:\n",
        "      with open(save_path , \"rb\") as f:\n",
        "        out = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "      full_trainer = FullTrainer.IeeeJointValNoHrPceLstmFullTrainer(dfs_train, args[\"device\"], nrun=400)\n",
        "    else:\n",
        "      dresults.append(out)\n",
        "      continue\n",
        "    # try:\n",
        "    fchoice[\"ts_sub\"] = ts_sub\n",
        "    out = full_trainer.train(**fchoice)\n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    dresults.append(out)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "      pickle.dump(out, f)\n",
        "    # except RuntimeError as e:\n",
        "    #   if isinstance(e, KeyboardInterrupt):\n",
        "    #     raise e\n",
        "    #   else:\n",
        "    #     print(\"####\")\n",
        "    #     print(f\"Failed: {choice}\")\n",
        "    #     print(\"###\")\n",
        "  print(f\"subject: {ts_sub}\")\n",
        "  print(f\"TS:{compute_ensemble(dresults)}\")\n",
        "  aresults.append(dresults)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subject: 0\n",
            "TS:34.24374771118164\n",
            "subject: 1\n",
            "TS:9.542508125305176\n",
            "subject: 2\n",
            "TS:5.941139221191406\n",
            "subject: 3\n",
            "TS:47.52583694458008\n",
            "subject: 4\n",
            "TS:7.277733325958252\n",
            "subject: 5\n",
            "TS:22.53272819519043\n",
            "subject: 6\n",
            "TS:17.044950485229492\n",
            "subject: 7\n",
            "TS:8.290112495422363\n",
            "subject: 8\n",
            "TS:3.54744029045105\n",
            "best val epoch: 1\n",
            "[1/300]: loss_train: 26.227 loss_val 26.563 loss_ts 41.060\n",
            "best val epoch: 2\n",
            "[2/300]: loss_train: 25.858 loss_val 26.543 loss_ts 38.840\n",
            "best val epoch: 3\n",
            "[3/300]: loss_train: 25.472 loss_val 26.473 loss_ts 36.613\n",
            "best val epoch: 4\n",
            "[4/300]: loss_train: 24.878 loss_val 26.083 loss_ts 33.969\n",
            "best val epoch: 5\n",
            "[5/300]: loss_train: 24.347 loss_val 25.573 loss_ts 31.821\n",
            "best val epoch: 10\n",
            "[10/300]: loss_train: 21.564 loss_val 25.430 loss_ts 12.124\n",
            "best val epoch: 13\n",
            "[13/300]: loss_train: 18.756 loss_val 25.014 loss_ts 7.865\n",
            "best val epoch: 14\n",
            "[14/300]: loss_train: 18.543 loss_val 24.692 loss_ts 10.599\n",
            "best val epoch: 15\n",
            "[15/300]: loss_train: 16.019 loss_val 23.789 loss_ts 18.372\n",
            "best val epoch: 17\n",
            "[17/300]: loss_train: 15.129 loss_val 22.053 loss_ts 13.243\n",
            "best val epoch: 18\n",
            "[18/300]: loss_train: 16.919 loss_val 22.028 loss_ts 16.793\n",
            "best val epoch: 19\n",
            "[19/300]: loss_train: 15.263 loss_val 20.859 loss_ts 10.972\n",
            "best val epoch: 24\n",
            "[24/300]: loss_train: 10.992 loss_val 19.541 loss_ts 13.588\n",
            "best val epoch: 25\n",
            "[25/300]: loss_train: 11.070 loss_val 18.434 loss_ts 9.920\n",
            "best val epoch: 26\n",
            "[26/300]: loss_train: 11.477 loss_val 17.825 loss_ts 15.484\n",
            "best val epoch: 28\n",
            "[28/300]: loss_train: 9.679 loss_val 17.557 loss_ts 10.281\n",
            "best val epoch: 29\n",
            "[29/300]: loss_train: 8.905 loss_val 16.878 loss_ts 9.602\n",
            "best val epoch: 34\n",
            "[34/300]: loss_train: 7.291 loss_val 14.988 loss_ts 12.573\n",
            "best val epoch: 35\n",
            "[35/300]: loss_train: 6.655 loss_val 13.696 loss_ts 13.680\n",
            "best val epoch: 37\n",
            "[37/300]: loss_train: 6.859 loss_val 12.383 loss_ts 13.629\n",
            "best val epoch: 38\n",
            "[38/300]: loss_train: 6.762 loss_val 11.524 loss_ts 11.892\n",
            "best val epoch: 41\n",
            "[41/300]: loss_train: 6.464 loss_val 11.331 loss_ts 12.437\n",
            "best val epoch: 42\n",
            "[42/300]: loss_train: 7.232 loss_val 10.759 loss_ts 10.793\n",
            "best val epoch: 43\n",
            "[43/300]: loss_train: 6.827 loss_val 10.646 loss_ts 11.205\n",
            "best val epoch: 47\n",
            "[47/300]: loss_train: 5.517 loss_val 10.011 loss_ts 8.553\n",
            "best val epoch: 48\n",
            "[48/300]: loss_train: 5.407 loss_val 9.954 loss_ts 14.531\n",
            "best val epoch: 51\n",
            "[51/300]: loss_train: 5.131 loss_val 9.219 loss_ts 13.698\n",
            "best val epoch: 52\n",
            "[52/300]: loss_train: 5.249 loss_val 8.840 loss_ts 16.839\n",
            "best val epoch: 53\n",
            "[53/300]: loss_train: 5.159 loss_val 8.729 loss_ts 13.127\n",
            "best val epoch: 67\n",
            "[67/300]: loss_train: 3.782 loss_val 8.126 loss_ts 9.991\n",
            "best val epoch: 68\n",
            "[68/300]: loss_train: 4.201 loss_val 7.687 loss_ts 8.715\n",
            "best val epoch: 72\n",
            "[72/300]: loss_train: 3.742 loss_val 7.429 loss_ts 12.342\n",
            "best val epoch: 85\n",
            "[85/300]: loss_train: 2.965 loss_val 7.129 loss_ts 12.319\n",
            "best val epoch: 96\n",
            "[96/300]: loss_train: 2.870 loss_val 6.878 loss_ts 13.988\n",
            "best val epoch: 100\n",
            "[100/300]: loss_train: 2.936 loss_val 6.471 loss_ts 12.203\n",
            "best val epoch: 121\n",
            "[121/300]: loss_train: 2.475 loss_val 6.389 loss_ts 10.460\n",
            "best val epoch: 124\n",
            "[124/300]: loss_train: 2.288 loss_val 5.557 loss_ts 10.401\n",
            "Final: 10.401459693908691\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 10.40146\n",
            "best val epoch: 1\n",
            "[1/300]: loss_train: 25.663 loss_val 28.983 loss_ts 43.783\n",
            "best val epoch: 2\n",
            "[2/300]: loss_train: 25.318 loss_val 28.848 loss_ts 42.461\n",
            "best val epoch: 3\n",
            "[3/300]: loss_train: 24.893 loss_val 28.644 loss_ts 40.385\n",
            "best val epoch: 4\n",
            "[4/300]: loss_train: 24.480 loss_val 28.308 loss_ts 39.824\n",
            "best val epoch: 5\n",
            "[5/300]: loss_train: 24.125 loss_val 28.121 loss_ts 38.394\n",
            "best val epoch: 7\n",
            "[7/300]: loss_train: 23.305 loss_val 27.790 loss_ts 33.309\n",
            "best val epoch: 8\n",
            "[8/300]: loss_train: 22.796 loss_val 27.351 loss_ts 36.426\n",
            "best val epoch: 9\n",
            "[9/300]: loss_train: 22.184 loss_val 27.044 loss_ts 34.502\n",
            "best val epoch: 10\n",
            "[10/300]: loss_train: 21.912 loss_val 27.043 loss_ts 26.577\n",
            "best val epoch: 11\n",
            "[11/300]: loss_train: 21.080 loss_val 26.439 loss_ts 30.086\n",
            "best val epoch: 12\n",
            "[12/300]: loss_train: 20.710 loss_val 26.319 loss_ts 34.853\n",
            "best val epoch: 13\n",
            "[13/300]: loss_train: 19.137 loss_val 25.200 loss_ts 21.021\n",
            "best val epoch: 14\n",
            "[14/300]: loss_train: 18.286 loss_val 23.962 loss_ts 6.913\n",
            "best val epoch: 15\n",
            "[15/300]: loss_train: 16.365 loss_val 23.264 loss_ts 6.857\n",
            "best val epoch: 16\n",
            "[16/300]: loss_train: 16.591 loss_val 21.368 loss_ts 9.731\n",
            "best val epoch: 18\n",
            "[18/300]: loss_train: 15.159 loss_val 19.809 loss_ts 11.570\n",
            "best val epoch: 21\n",
            "[21/300]: loss_train: 11.717 loss_val 17.351 loss_ts 6.975\n",
            "best val epoch: 23\n",
            "[23/300]: loss_train: 11.528 loss_val 16.247 loss_ts 25.179\n",
            "best val epoch: 27\n",
            "[27/300]: loss_train: 10.414 loss_val 15.992 loss_ts 10.635\n",
            "best val epoch: 28\n",
            "[28/300]: loss_train: 9.116 loss_val 14.143 loss_ts 6.405\n",
            "best val epoch: 30\n",
            "[30/300]: loss_train: 8.776 loss_val 14.139 loss_ts 8.111\n",
            "best val epoch: 31\n",
            "[31/300]: loss_train: 8.042 loss_val 13.205 loss_ts 6.732\n",
            "best val epoch: 32\n",
            "[32/300]: loss_train: 8.747 loss_val 12.565 loss_ts 5.351\n",
            "best val epoch: 35\n",
            "[35/300]: loss_train: 8.409 loss_val 11.889 loss_ts 7.717\n",
            "best val epoch: 38\n",
            "[38/300]: loss_train: 7.077 loss_val 11.117 loss_ts 10.997\n",
            "best val epoch: 39\n",
            "[39/300]: loss_train: 6.885 loss_val 9.908 loss_ts 13.971\n",
            "best val epoch: 43\n",
            "[43/300]: loss_train: 6.480 loss_val 8.261 loss_ts 8.217\n",
            "best val epoch: 44\n",
            "[44/300]: loss_train: 6.640 loss_val 7.777 loss_ts 8.176\n",
            "best val epoch: 60\n",
            "[60/300]: loss_train: 4.859 loss_val 7.076 loss_ts 10.127\n",
            "best val epoch: 72\n",
            "[72/300]: loss_train: 4.557 loss_val 7.015 loss_ts 13.671\n",
            "best val epoch: 73\n",
            "[73/300]: loss_train: 4.487 loss_val 6.820 loss_ts 14.338\n",
            "best val epoch: 74\n",
            "[74/300]: loss_train: 4.200 loss_val 6.479 loss_ts 14.534\n",
            "best val epoch: 97\n",
            "[97/300]: loss_train: 4.411 loss_val 6.258 loss_ts 15.530\n",
            "best val epoch: 100\n",
            "[100/300]: loss_train: 3.671 loss_val 6.140 loss_ts 11.097\n",
            "best val epoch: 104\n",
            "[104/300]: loss_train: 3.411 loss_val 5.733 loss_ts 7.260\n",
            "best val epoch: 108\n",
            "[108/300]: loss_train: 3.084 loss_val 5.530 loss_ts 11.791\n",
            "best val epoch: 134\n",
            "[134/300]: loss_train: 2.729 loss_val 5.238 loss_ts 5.570\n",
            "best val epoch: 154\n",
            "[154/300]: loss_train: 3.324 loss_val 4.618 loss_ts 9.758\n",
            "best val epoch: 254\n",
            "[254/300]: loss_train: 1.768 loss_val 4.573 loss_ts 4.194\n",
            "best val epoch: 287\n",
            "[287/300]: loss_train: 1.722 loss_val 4.123 loss_ts 3.334\n",
            "Final: 3.334181785583496\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 3.3341818\n",
            "best val epoch: 1\n",
            "[1/300]: loss_train: 27.952 loss_val 20.683 loss_ts 43.501\n",
            "best val epoch: 2\n",
            "[2/300]: loss_train: 27.810 loss_val 20.525 loss_ts 43.087\n",
            "best val epoch: 3\n",
            "[3/300]: loss_train: 27.649 loss_val 20.268 loss_ts 43.320\n",
            "best val epoch: 6\n",
            "[6/300]: loss_train: 27.259 loss_val 19.985 loss_ts 43.257\n",
            "best val epoch: 7\n",
            "[7/300]: loss_train: 26.984 loss_val 19.622 loss_ts 41.827\n",
            "best val epoch: 8\n",
            "[8/300]: loss_train: 26.715 loss_val 19.295 loss_ts 40.008\n",
            "best val epoch: 9\n",
            "[9/300]: loss_train: 26.333 loss_val 18.936 loss_ts 37.487\n",
            "best val epoch: 10\n",
            "[10/300]: loss_train: 25.800 loss_val 18.598 loss_ts 35.462\n",
            "best val epoch: 11\n",
            "[11/300]: loss_train: 25.277 loss_val 18.275 loss_ts 33.391\n",
            "best val epoch: 12\n",
            "[12/300]: loss_train: 24.758 loss_val 18.020 loss_ts 31.833\n",
            "best val epoch: 14\n",
            "[14/300]: loss_train: 23.707 loss_val 17.297 loss_ts 29.049\n",
            "best val epoch: 18\n",
            "[18/300]: loss_train: 20.225 loss_val 17.053 loss_ts 9.039\n",
            "best val epoch: 20\n",
            "[20/300]: loss_train: 19.548 loss_val 15.238 loss_ts 11.866\n",
            "best val epoch: 21\n",
            "[21/300]: loss_train: 19.372 loss_val 14.527 loss_ts 22.960\n",
            "best val epoch: 22\n",
            "[22/300]: loss_train: 16.376 loss_val 13.873 loss_ts 9.454\n",
            "best val epoch: 25\n",
            "[25/300]: loss_train: 12.285 loss_val 11.904 loss_ts 7.122\n",
            "best val epoch: 29\n",
            "[29/300]: loss_train: 11.206 loss_val 11.377 loss_ts 8.260\n",
            "best val epoch: 30\n",
            "[30/300]: loss_train: 10.552 loss_val 9.942 loss_ts 8.335\n",
            "best val epoch: 31\n",
            "[31/300]: loss_train: 9.473 loss_val 8.747 loss_ts 18.898\n",
            "best val epoch: 32\n",
            "[32/300]: loss_train: 9.064 loss_val 8.476 loss_ts 15.529\n",
            "best val epoch: 34\n",
            "[34/300]: loss_train: 8.971 loss_val 7.932 loss_ts 12.782\n",
            "best val epoch: 39\n",
            "[39/300]: loss_train: 7.864 loss_val 7.423 loss_ts 48.002\n",
            "best val epoch: 40\n",
            "[40/300]: loss_train: 7.576 loss_val 6.579 loss_ts 48.532\n",
            "best val epoch: 41\n",
            "[41/300]: loss_train: 6.813 loss_val 5.921 loss_ts 45.340\n",
            "best val epoch: 59\n",
            "[59/300]: loss_train: 4.797 loss_val 5.392 loss_ts 48.235\n",
            "best val epoch: 68\n",
            "[68/300]: loss_train: 4.766 loss_val 5.065 loss_ts 19.264\n",
            "best val epoch: 76\n",
            "[76/300]: loss_train: 4.151 loss_val 4.872 loss_ts 30.065\n",
            "best val epoch: 77\n",
            "[77/300]: loss_train: 3.879 loss_val 4.829 loss_ts 21.686\n",
            "best val epoch: 78\n",
            "[78/300]: loss_train: 3.877 loss_val 4.829 loss_ts 18.740\n",
            "best val epoch: 79\n",
            "[79/300]: loss_train: 4.040 loss_val 4.611 loss_ts 23.289\n",
            "best val epoch: 84\n",
            "[84/300]: loss_train: 3.514 loss_val 4.571 loss_ts 8.755\n",
            "best val epoch: 85\n",
            "[85/300]: loss_train: 3.510 loss_val 4.416 loss_ts 9.409\n",
            "best val epoch: 116\n",
            "[116/300]: loss_train: 2.858 loss_val 4.226 loss_ts 28.542\n",
            "Final: 28.542076110839844\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 28.542076\n",
            "best val epoch: 1\n",
            "[1/300]: loss_train: 26.064 loss_val 27.731 loss_ts 44.112\n",
            "best val epoch: 2\n",
            "[2/300]: loss_train: 25.966 loss_val 27.713 loss_ts 44.246\n",
            "best val epoch: 3\n",
            "[3/300]: loss_train: 25.922 loss_val 27.576 loss_ts 43.482\n",
            "best val epoch: 4\n",
            "[4/300]: loss_train: 25.858 loss_val 27.498 loss_ts 43.089\n",
            "best val epoch: 5\n",
            "[5/300]: loss_train: 25.704 loss_val 27.407 loss_ts 43.013\n",
            "best val epoch: 6\n",
            "[6/300]: loss_train: 25.493 loss_val 27.290 loss_ts 42.857\n",
            "best val epoch: 7\n",
            "[7/300]: loss_train: 25.268 loss_val 27.200 loss_ts 42.560\n",
            "best val epoch: 8\n",
            "[8/300]: loss_train: 25.126 loss_val 27.140 loss_ts 42.011\n",
            "best val epoch: 9\n",
            "[9/300]: loss_train: 24.986 loss_val 27.071 loss_ts 41.177\n",
            "best val epoch: 10\n",
            "[10/300]: loss_train: 24.704 loss_val 26.834 loss_ts 39.572\n",
            "best val epoch: 11\n",
            "[11/300]: loss_train: 24.304 loss_val 26.168 loss_ts 36.098\n",
            "best val epoch: 12\n",
            "[12/300]: loss_train: 24.055 loss_val 25.791 loss_ts 33.737\n",
            "best val epoch: 13\n",
            "[13/300]: loss_train: 23.608 loss_val 25.789 loss_ts 34.552\n",
            "best val epoch: 14\n",
            "[14/300]: loss_train: 23.277 loss_val 25.505 loss_ts 33.986\n",
            "best val epoch: 15\n",
            "[15/300]: loss_train: 23.205 loss_val 25.009 loss_ts 29.982\n",
            "best val epoch: 16\n",
            "[16/300]: loss_train: 22.543 loss_val 24.509 loss_ts 28.475\n",
            "best val epoch: 17\n",
            "[17/300]: loss_train: 22.286 loss_val 24.367 loss_ts 27.535\n",
            "best val epoch: 18\n",
            "[18/300]: loss_train: 21.498 loss_val 23.215 loss_ts 19.426\n",
            "best val epoch: 19\n",
            "[19/300]: loss_train: 21.433 loss_val 22.709 loss_ts 12.045\n",
            "best val epoch: 20\n",
            "[20/300]: loss_train: 20.182 loss_val 21.551 loss_ts 9.777\n",
            "best val epoch: 21\n",
            "[21/300]: loss_train: 20.153 loss_val 21.039 loss_ts 7.602\n",
            "best val epoch: 22\n",
            "[22/300]: loss_train: 18.526 loss_val 19.066 loss_ts 11.774\n",
            "best val epoch: 26\n",
            "[26/300]: loss_train: 16.086 loss_val 18.484 loss_ts 11.403\n",
            "best val epoch: 27\n",
            "[27/300]: loss_train: 15.381 loss_val 18.430 loss_ts 23.713\n",
            "best val epoch: 28\n",
            "[28/300]: loss_train: 13.605 loss_val 14.191 loss_ts 21.699\n",
            "best val epoch: 29\n",
            "[29/300]: loss_train: 13.080 loss_val 13.561 loss_ts 26.622\n",
            "best val epoch: 30\n",
            "[30/300]: loss_train: 11.464 loss_val 13.249 loss_ts 35.573\n",
            "best val epoch: 32\n",
            "[32/300]: loss_train: 11.072 loss_val 12.875 loss_ts 19.289\n",
            "best val epoch: 33\n",
            "[33/300]: loss_train: 10.222 loss_val 12.230 loss_ts 15.868\n",
            "best val epoch: 34\n",
            "[34/300]: loss_train: 9.538 loss_val 11.539 loss_ts 13.880\n",
            "best val epoch: 35\n",
            "[35/300]: loss_train: 9.527 loss_val 10.892 loss_ts 10.879\n",
            "best val epoch: 36\n",
            "[36/300]: loss_train: 8.067 loss_val 10.176 loss_ts 15.614\n",
            "best val epoch: 37\n",
            "[37/300]: loss_train: 8.013 loss_val 9.606 loss_ts 12.895\n",
            "best val epoch: 39\n",
            "[39/300]: loss_train: 7.475 loss_val 8.722 loss_ts 11.387\n",
            "best val epoch: 42\n",
            "[42/300]: loss_train: 5.980 loss_val 7.129 loss_ts 13.025\n",
            "best val epoch: 44\n",
            "[44/300]: loss_train: 5.675 loss_val 7.070 loss_ts 13.593\n",
            "best val epoch: 46\n",
            "[46/300]: loss_train: 6.670 loss_val 6.355 loss_ts 11.382\n",
            "best val epoch: 49\n",
            "[49/300]: loss_train: 5.635 loss_val 6.195 loss_ts 11.631\n",
            "best val epoch: 52\n",
            "[52/300]: loss_train: 5.204 loss_val 6.148 loss_ts 14.689\n",
            "best val epoch: 55\n",
            "[55/300]: loss_train: 5.246 loss_val 5.589 loss_ts 9.970\n",
            "best val epoch: 56\n",
            "[56/300]: loss_train: 4.723 loss_val 5.524 loss_ts 13.245\n",
            "best val epoch: 57\n",
            "[57/300]: loss_train: 4.348 loss_val 5.280 loss_ts 12.363\n",
            "best val epoch: 60\n",
            "[60/300]: loss_train: 4.280 loss_val 5.200 loss_ts 14.632\n",
            "best val epoch: 66\n",
            "[66/300]: loss_train: 3.743 loss_val 5.076 loss_ts 17.554\n",
            "best val epoch: 67\n",
            "[67/300]: loss_train: 3.891 loss_val 4.846 loss_ts 15.604\n",
            "best val epoch: 70\n",
            "[70/300]: loss_train: 4.340 loss_val 4.806 loss_ts 11.578\n",
            "best val epoch: 72\n",
            "[72/300]: loss_train: 3.456 loss_val 4.795 loss_ts 15.653\n",
            "best val epoch: 80\n",
            "[80/300]: loss_train: 2.942 loss_val 4.563 loss_ts 14.743\n",
            "best val epoch: 84\n",
            "[84/300]: loss_train: 3.181 loss_val 4.344 loss_ts 9.861\n",
            "best val epoch: 85\n",
            "[85/300]: loss_train: 2.930 loss_val 4.307 loss_ts 10.114\n",
            "best val epoch: 92\n",
            "[92/300]: loss_train: 2.984 loss_val 4.119 loss_ts 9.404\n",
            "best val epoch: 116\n",
            "[116/300]: loss_train: 2.413 loss_val 4.101 loss_ts 10.732\n",
            "best val epoch: 130\n",
            "[130/300]: loss_train: 2.422 loss_val 3.964 loss_ts 9.534\n",
            "best val epoch: 155\n",
            "[155/300]: loss_train: 2.032 loss_val 3.923 loss_ts 8.063\n",
            "best val epoch: 156\n",
            "[156/300]: loss_train: 1.889 loss_val 3.890 loss_ts 8.416\n",
            "best val epoch: 209\n",
            "[209/300]: loss_train: 2.119 loss_val 3.695 loss_ts 8.648\n",
            "best val epoch: 217\n",
            "[217/300]: loss_train: 1.542 loss_val 3.672 loss_ts 7.353\n",
            "Final: 7.35324239730835\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 7.3532424\n",
            "best val epoch: 1\n",
            "[1/300]: loss_train: 26.825 loss_val 24.174 loss_ts 43.313\n",
            "best val epoch: 2\n",
            "[2/300]: loss_train: 26.449 loss_val 24.012 loss_ts 42.188\n",
            "best val epoch: 3\n",
            "[3/300]: loss_train: 26.071 loss_val 23.838 loss_ts 39.701\n",
            "best val epoch: 4\n",
            "[4/300]: loss_train: 25.602 loss_val 23.751 loss_ts 37.661\n",
            "best val epoch: 6\n",
            "[6/300]: loss_train: 24.894 loss_val 23.705 loss_ts 35.313\n",
            "best val epoch: 7\n",
            "[7/300]: loss_train: 24.379 loss_val 23.166 loss_ts 28.953\n",
            "best val epoch: 8\n",
            "[8/300]: loss_train: 24.093 loss_val 23.058 loss_ts 23.048\n",
            "best val epoch: 9\n",
            "[9/300]: loss_train: 22.919 loss_val 22.641 loss_ts 17.524\n",
            "best val epoch: 10\n",
            "[10/300]: loss_train: 22.012 loss_val 22.507 loss_ts 13.683\n",
            "best val epoch: 11\n",
            "[11/300]: loss_train: 20.968 loss_val 22.274 loss_ts 10.752\n",
            "best val epoch: 13\n",
            "[13/300]: loss_train: 18.822 loss_val 21.953 loss_ts 9.627\n",
            "best val epoch: 15\n",
            "[15/300]: loss_train: 16.838 loss_val 21.111 loss_ts 11.341\n",
            "best val epoch: 17\n",
            "[17/300]: loss_train: 14.396 loss_val 18.760 loss_ts 16.198\n",
            "best val epoch: 19\n",
            "[19/300]: loss_train: 13.525 loss_val 17.990 loss_ts 13.626\n",
            "best val epoch: 20\n",
            "[20/300]: loss_train: 11.997 loss_val 16.587 loss_ts 16.182\n",
            "best val epoch: 23\n",
            "[23/300]: loss_train: 11.442 loss_val 15.760 loss_ts 13.432\n",
            "best val epoch: 24\n",
            "[24/300]: loss_train: 9.756 loss_val 14.788 loss_ts 12.289\n",
            "best val epoch: 26\n",
            "[26/300]: loss_train: 9.308 loss_val 14.107 loss_ts 11.352\n",
            "best val epoch: 30\n",
            "[30/300]: loss_train: 7.245 loss_val 13.367 loss_ts 6.237\n",
            "best val epoch: 31\n",
            "[31/300]: loss_train: 6.635 loss_val 13.261 loss_ts 8.835\n",
            "best val epoch: 33\n",
            "[33/300]: loss_train: 7.645 loss_val 12.945 loss_ts 37.748\n",
            "best val epoch: 34\n",
            "[34/300]: loss_train: 6.516 loss_val 11.480 loss_ts 9.703\n",
            "best val epoch: 35\n",
            "[35/300]: loss_train: 5.754 loss_val 10.865 loss_ts 10.138\n",
            "best val epoch: 37\n",
            "[37/300]: loss_train: 5.765 loss_val 10.723 loss_ts 12.746\n",
            "best val epoch: 38\n",
            "[38/300]: loss_train: 6.532 loss_val 10.138 loss_ts 9.063\n",
            "best val epoch: 39\n",
            "[39/300]: loss_train: 5.614 loss_val 9.743 loss_ts 9.782\n",
            "best val epoch: 42\n",
            "[42/300]: loss_train: 4.686 loss_val 9.578 loss_ts 45.862\n",
            "best val epoch: 46\n",
            "[46/300]: loss_train: 4.450 loss_val 8.707 loss_ts 9.581\n",
            "best val epoch: 57\n",
            "[57/300]: loss_train: 4.330 loss_val 8.323 loss_ts 6.020\n",
            "best val epoch: 61\n",
            "[61/300]: loss_train: 3.922 loss_val 7.896 loss_ts 11.687\n",
            "best val epoch: 62\n",
            "[62/300]: loss_train: 4.211 loss_val 7.748 loss_ts 10.883\n",
            "best val epoch: 76\n",
            "[76/300]: loss_train: 3.552 loss_val 7.515 loss_ts 32.866\n",
            "best val epoch: 85\n",
            "[85/300]: loss_train: 3.142 loss_val 7.279 loss_ts 35.165\n",
            "best val epoch: 89\n",
            "[89/300]: loss_train: 2.604 loss_val 7.116 loss_ts 13.517\n",
            "best val epoch: 93\n",
            "[93/300]: loss_train: 2.782 loss_val 7.060 loss_ts 8.407\n",
            "best val epoch: 100\n",
            "[100/300]: loss_train: 2.898 loss_val 6.984 loss_ts 5.509\n",
            "best val epoch: 105\n",
            "[105/300]: loss_train: 2.771 loss_val 6.960 loss_ts 14.967\n",
            "best val epoch: 141\n",
            "[141/300]: loss_train: 2.257 loss_val 6.914 loss_ts 11.671\n",
            "best val epoch: 146\n",
            "[146/300]: loss_train: 2.176 loss_val 6.817 loss_ts 24.974\n",
            "best val epoch: 150\n",
            "[150/300]: loss_train: 2.263 loss_val 6.491 loss_ts 12.540\n",
            "best val epoch: 178\n",
            "[178/300]: loss_train: 2.149 loss_val 6.390 loss_ts 10.929\n",
            "best val epoch: 203\n",
            "[203/300]: loss_train: 1.927 loss_val 6.312 loss_ts 10.831\n",
            "best val epoch: 207\n",
            "[207/300]: loss_train: 2.226 loss_val 6.301 loss_ts 10.775\n",
            "best val epoch: 229\n",
            "[229/300]: loss_train: 1.835 loss_val 6.272 loss_ts 10.155\n",
            "best val epoch: 240\n",
            "[240/300]: loss_train: 1.792 loss_val 6.015 loss_ts 7.763\n",
            "best val epoch: 275\n",
            "[275/300]: loss_train: 1.742 loss_val 5.816 loss_ts 7.233\n",
            "Final: 7.233096599578857\n",
            "{'val_sub': 4, 'ts_sub': 9, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 7.2330966\n",
            "best val epoch: 1\n",
            "[1/300]: loss_train: 26.955 loss_val 23.099 loss_ts 43.391\n",
            "best val epoch: 2\n",
            "[2/300]: loss_train: 26.901 loss_val 22.752 loss_ts 40.468\n",
            "best val epoch: 3\n",
            "[3/300]: loss_train: 26.506 loss_val 22.297 loss_ts 38.941\n",
            "best val epoch: 4\n",
            "[4/300]: loss_train: 26.027 loss_val 21.783 loss_ts 38.389\n",
            "best val epoch: 5\n",
            "[5/300]: loss_train: 25.663 loss_val 21.222 loss_ts 36.594\n",
            "best val epoch: 6\n",
            "[6/300]: loss_train: 25.202 loss_val 20.702 loss_ts 34.542\n",
            "best val epoch: 7\n",
            "[7/300]: loss_train: 24.736 loss_val 20.302 loss_ts 32.868\n",
            "best val epoch: 8\n",
            "[8/300]: loss_train: 24.331 loss_val 20.012 loss_ts 32.351\n",
            "best val epoch: 10\n",
            "[10/300]: loss_train: 23.621 loss_val 19.682 loss_ts 32.739\n",
            "best val epoch: 11\n",
            "[11/300]: loss_train: 23.587 loss_val 19.166 loss_ts 24.436\n",
            "best val epoch: 12\n",
            "[12/300]: loss_train: 23.063 loss_val 18.794 loss_ts 19.761\n",
            "best val epoch: 13\n",
            "[13/300]: loss_train: 21.696 loss_val 17.650 loss_ts 15.992\n",
            "best val epoch: 14\n",
            "[14/300]: loss_train: 20.851 loss_val 17.554 loss_ts 14.980\n",
            "best val epoch: 15\n",
            "[15/300]: loss_train: 19.278 loss_val 16.365 loss_ts 7.289\n",
            "best val epoch: 16\n",
            "[16/300]: loss_train: 17.967 loss_val 16.166 loss_ts 10.253\n",
            "best val epoch: 18\n",
            "[18/300]: loss_train: 16.343 loss_val 15.708 loss_ts 14.144\n",
            "best val epoch: 19\n",
            "[19/300]: loss_train: 14.655 loss_val 15.030 loss_ts 12.712\n",
            "best val epoch: 28\n",
            "[28/300]: loss_train: 9.275 loss_val 14.187 loss_ts 12.773\n",
            "best val epoch: 29\n",
            "[29/300]: loss_train: 8.877 loss_val 13.960 loss_ts 11.277\n",
            "best val epoch: 34\n",
            "[34/300]: loss_train: 9.862 loss_val 13.868 loss_ts 3.507\n",
            "best val epoch: 35\n",
            "[35/300]: loss_train: 8.625 loss_val 13.017 loss_ts 3.202\n",
            "best val epoch: 39\n",
            "[39/300]: loss_train: 6.532 loss_val 12.822 loss_ts 11.360\n",
            "best val epoch: 40\n",
            "[40/300]: loss_train: 6.307 loss_val 12.138 loss_ts 11.265\n",
            "best val epoch: 42\n",
            "[42/300]: loss_train: 6.511 loss_val 11.918 loss_ts 10.455\n",
            "best val epoch: 43\n",
            "[43/300]: loss_train: 6.762 loss_val 11.801 loss_ts 11.593\n",
            "best val epoch: 47\n",
            "[47/300]: loss_train: 6.191 loss_val 11.394 loss_ts 3.527\n",
            "best val epoch: 52\n",
            "[52/300]: loss_train: 5.757 loss_val 10.705 loss_ts 5.265\n",
            "best val epoch: 56\n",
            "[56/300]: loss_train: 5.072 loss_val 10.365 loss_ts 7.523\n",
            "best val epoch: 57\n",
            "[57/300]: loss_train: 5.105 loss_val 10.305 loss_ts 6.190\n",
            "best val epoch: 59\n",
            "[59/300]: loss_train: 5.080 loss_val 10.286 loss_ts 9.047\n",
            "best val epoch: 61\n",
            "[61/300]: loss_train: 4.489 loss_val 9.930 loss_ts 10.914\n",
            "best val epoch: 63\n",
            "[63/300]: loss_train: 4.122 loss_val 9.417 loss_ts 12.957\n",
            "best val epoch: 64\n",
            "[64/300]: loss_train: 4.245 loss_val 8.868 loss_ts 11.361\n",
            "best val epoch: 68\n",
            "[68/300]: loss_train: 4.183 loss_val 8.591 loss_ts 9.378\n",
            "best val epoch: 71\n",
            "[71/300]: loss_train: 4.295 loss_val 8.205 loss_ts 6.766\n",
            "best val epoch: 78\n",
            "[78/300]: loss_train: 3.621 loss_val 8.195 loss_ts 8.895\n",
            "best val epoch: 79\n",
            "[79/300]: loss_train: 4.265 loss_val 8.135 loss_ts 6.053\n",
            "best val epoch: 80\n",
            "[80/300]: loss_train: 4.046 loss_val 8.033 loss_ts 7.636\n",
            "best val epoch: 81\n",
            "[81/300]: loss_train: 3.952 loss_val 7.984 loss_ts 7.505\n",
            "best val epoch: 82\n",
            "[82/300]: loss_train: 3.523 loss_val 7.979 loss_ts 7.730\n",
            "best val epoch: 88\n",
            "[88/300]: loss_train: 4.008 loss_val 7.952 loss_ts 12.204\n",
            "best val epoch: 93\n",
            "[93/300]: loss_train: 3.447 loss_val 7.814 loss_ts 10.497\n",
            "best val epoch: 94\n",
            "[94/300]: loss_train: 3.637 loss_val 7.729 loss_ts 7.733\n",
            "best val epoch: 95\n",
            "[95/300]: loss_train: 3.384 loss_val 7.474 loss_ts 8.189\n",
            "best val epoch: 96\n",
            "[96/300]: loss_train: 3.054 loss_val 7.405 loss_ts 9.693\n",
            "best val epoch: 99\n",
            "[99/300]: loss_train: 3.486 loss_val 7.289 loss_ts 13.582\n",
            "best val epoch: 100\n",
            "[100/300]: loss_train: 3.848 loss_val 7.112 loss_ts 14.539\n",
            "best val epoch: 113\n",
            "[113/300]: loss_train: 3.354 loss_val 6.984 loss_ts 10.649\n",
            "best val epoch: 129\n",
            "[129/300]: loss_train: 2.846 loss_val 6.701 loss_ts 6.713\n",
            "best val epoch: 148\n",
            "[148/300]: loss_train: 3.004 loss_val 6.406 loss_ts 7.937\n",
            "best val epoch: 149\n",
            "[149/300]: loss_train: 2.639 loss_val 6.347 loss_ts 7.949\n",
            "best val epoch: 170\n",
            "[170/300]: loss_train: 3.090 loss_val 6.335 loss_ts 11.744\n",
            "best val epoch: 179\n",
            "[179/300]: loss_train: 2.243 loss_val 6.172 loss_ts 10.519\n",
            "best val epoch: 182\n",
            "[182/300]: loss_train: 2.679 loss_val 6.129 loss_ts 7.915\n",
            "best val epoch: 183\n",
            "[183/300]: loss_train: 2.314 loss_val 6.072 loss_ts 8.310\n",
            "best val epoch: 187\n",
            "[187/300]: loss_train: 2.294 loss_val 5.931 loss_ts 9.482\n",
            "best val epoch: 190\n",
            "[190/300]: loss_train: 2.342 loss_val 5.704 loss_ts 8.696\n",
            "best val epoch: 191\n",
            "[191/300]: loss_train: 2.243 loss_val 5.585 loss_ts 9.642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG0tSXLWPuCQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}