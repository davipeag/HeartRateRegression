{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "ppg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg4pPcCWcJR",
        "outputId": "322e4857-c136-4152-97b1-09355a17aad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "ssh_config = \"\"\"\n",
        "Host github.com\n",
        "  IdentityFile ~/.ssh/github.pem\n",
        "  User davipeag\n",
        "  StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "if os.name == 'nt':\n",
        "  base_path = \"\"\n",
        "  REPO_DIR = \".\"\n",
        "  STORE_DIR =\".\" \n",
        "  print(\"Windows\")\n",
        "else:\n",
        "  print(\"Unix-like\")\n",
        "  REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "  DATA_DIR = os.path.join(REPO_DIR, \"repo\")\n",
        "  STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "  !mkdir ~/.ssh\n",
        "  !cp -u {GIT_PATH} ~/.ssh/\n",
        "  !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "  !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "  !chmod u=rw,g=,o= ~/.ssh/config\n",
        "  ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "  import sys\n",
        "  sys.path.append(REPO_DIR)\n",
        "\n",
        "def git_pull():\n",
        "  ! (cd {REPO_DIR} && git pull )\n",
        "\n",
        "git_pull()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n",
            "Unix-like\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.ssh’: File exists\n",
            "fatal: destination path 'HeartRateRegression' already exists and is not an empty directory.\n",
            "Already up to date.\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFiZv0xM1pa",
        "outputId": "f975179e-fc5c-425a-fbb6-35975273af20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "args = {\n",
        "    'epoch_num': 250,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 0,     # Number of workers on data loader.\n",
        "    'batch_size': 128,     # Mini-batch size. 128\n",
        "    'batch_test': 248,     # size of test batch\n",
        "    'window': 15,\n",
        "    'initial_window':5,\n",
        "    'clip_norm': 6.0,     # Upper limit on gradient L2 norm ###\n",
        "}\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "SEED = 1234\n",
        "def reset_seeds():\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reset_seeds()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V97F8pWmvK",
        "outputId": "e86bd408-171b-40b6-aba4-691b05aef002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data_utils import (FormatIeee,  IeeeExtractorTest)\n",
        "\n",
        "SUBJECTS = list(range(1,10))\n",
        "\n",
        "extractor = IeeeExtractorTest(DATA_DIR)\n",
        "formatter = FormatIeee()\n",
        "dfs_train = [formatter.transform(extractor.extract_subject(i)) for i in SUBJECTS]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDUK1vToJWo",
        "outputId": "d5b40b51-dbd1-4830-c82b-e444b6393df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "git_pull()\n",
        "\n",
        "import importlib\n",
        "\n",
        "import PPG\n",
        "\n",
        "from PPG import FullTrainer\n",
        "\n",
        "importlib.reload(PPG.AttentionDefaults)\n",
        "importlib.reload(PPG)\n",
        "importlib.reload(PPG.UtilitiesDataXY)\n",
        "importlib.reload(PPG.Models)\n",
        "importlib.reload(PPG.NoHrPceLstmModel)\n",
        "importlib.reload(PPG.TrainerXY)\n",
        "importlib.reload(PPG.TrainerIS)\n",
        "importlib.reload(PPG.FullTrainer)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From github.com:davipeag/HeartRateRegression\n",
            "   bff372c..cb9d324  master     -> origin/master\n",
            "Updating bff372c..cb9d324\n",
            "Fast-forward\n",
            " ieee_test_pce_lstm.ipynb | 610 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 571 insertions(+), 39 deletions(-)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'PPG.FullTrainer' from '/tmp/HeartRateRegression/PPG/FullTrainer.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7zop0WGrHb",
        "outputId": "24a1b365-1d04-4617-f781-63fb5532921e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "# fchoice = {'val_sub': 4,\n",
        "#   'ts_sub': 0,\n",
        "#   'batch_size': 64,\n",
        "#   'weight_decay': 0,\n",
        "#   'lr': 0.001,\n",
        "#   'nattrs': 5,\n",
        "#   'bvp_count': 16,\n",
        "#   'dropout_rate': 0.25,\n",
        "#   'lstm_input': 128,\n",
        "#   'lstm_size': 64,\n",
        "#   'ts_h_size': 64\n",
        "#   }\n",
        "def compute_ensemble(results):\n",
        "  ps = [v[\"predictions\"][1].reshape(-1).numpy() for v in results]\n",
        "  ys = [v[\"predictions\"][0].reshape(-1).numpy() for v in results]\n",
        "\n",
        "  for i in range(1, len(ys)-1):\n",
        "    assert np.all(ys[i] == ys[i-1])\n",
        "\n",
        "  s = ps[0]\n",
        "  for p in ps[1:]:\n",
        "    s = s + p\n",
        "\n",
        "  a = s/len(ps)\n",
        "  y = ys[0]\n",
        "\n",
        "  plt.plot(a)\n",
        "  plt.plot(y)\n",
        "\n",
        "  return np.mean(np.abs(a - y))\n",
        "\n",
        "\n",
        "fchoice = {'val_sub': 4,\n",
        "  'ts_sub': 0,\n",
        "  'batch_size': 64,\n",
        "  'weight_decay': 0.0001,\n",
        "  'lr': 0.001,\n",
        "  'nattrs': 6,\n",
        "  'bvp_count': 12,\n",
        "  'dropout_rate': 0,\n",
        "  'lstm_input': 128,\n",
        "  'lstm_size': 32,\n",
        "  'ts_h_size': 32\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "from PPG import UtilitiesDataXY\n",
        "\n",
        "\n",
        "aresults = list()\n",
        "for ts_sub in [0]:#[0,1,2,3, 4,5,6,7,8,9]:\n",
        "  dresults = list()\n",
        "  for i in range(7):\n",
        "    filename = f\"ieee_test_ts_{ts_sub}_{i}_pce_lstm_12\"\n",
        "    save_path = os.path.join(STORE_DIR, filename)\n",
        "    try:\n",
        "      raise FileNotFoundError\n",
        "      with open(save_path , \"rb\") as f:\n",
        "        out = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "      full_trainer = FullTrainer.IeeeJointValNoHrPceLstmFullTrainer(dfs_train, args[\"device\"], nrun=400)\n",
        "    else:\n",
        "      dresults.append(out)\n",
        "      continue\n",
        "    # try:\n",
        "    fchoice[\"ts_sub\"] = ts_sub\n",
        "    out = full_trainer.train(**fchoice)\n",
        "    print(out[\"args\"], out[\"metric\"])\n",
        "    dresults.append(out)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "      pickle.dump(out, f)\n",
        "    # except RuntimeError as e:\n",
        "    #   if isinstance(e, KeyboardInterrupt):\n",
        "    #     raise e\n",
        "    #   else:\n",
        "    #     print(\"####\")\n",
        "    #     print(f\"Failed: {choice}\")\n",
        "    #     print(\"###\")\n",
        "  print(f\"subject: {ts_sub}\")\n",
        "  print(f\"TS:{compute_ensemble(dresults)}\")\n",
        "  aresults.append(dresults)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best val epoch: 1\n",
            "[1/400]: loss_train: 22.687 loss_val 20.342 loss_ts 59.720\n",
            "best val epoch: 15\n",
            "[15/400]: loss_train: 22.687 loss_val 20.335 loss_ts 60.920\n",
            "best val epoch: 16\n",
            "[16/400]: loss_train: 22.667 loss_val 20.318 loss_ts 60.982\n",
            "best val epoch: 17\n",
            "[17/400]: loss_train: 22.637 loss_val 20.296 loss_ts 61.015\n",
            "best val epoch: 18\n",
            "[18/400]: loss_train: 22.605 loss_val 20.264 loss_ts 61.191\n",
            "best val epoch: 19\n",
            "[19/400]: loss_train: 22.563 loss_val 20.206 loss_ts 61.597\n",
            "best val epoch: 20\n",
            "[20/400]: loss_train: 22.502 loss_val 20.119 loss_ts 61.978\n",
            "best val epoch: 21\n",
            "[21/400]: loss_train: 22.410 loss_val 20.025 loss_ts 62.180\n",
            "best val epoch: 22\n",
            "[22/400]: loss_train: 22.266 loss_val 19.917 loss_ts 62.001\n",
            "best val epoch: 24\n",
            "[24/400]: loss_train: 22.139 loss_val 19.906 loss_ts 61.486\n",
            "best val epoch: 25\n",
            "[25/400]: loss_train: 22.055 loss_val 19.747 loss_ts 62.116\n",
            "best val epoch: 26\n",
            "[26/400]: loss_train: 21.995 loss_val 19.658 loss_ts 62.521\n",
            "best val epoch: 27\n",
            "[27/400]: loss_train: 21.935 loss_val 19.574 loss_ts 62.803\n",
            "best val epoch: 28\n",
            "[28/400]: loss_train: 21.906 loss_val 19.521 loss_ts 63.194\n",
            "best val epoch: 29\n",
            "[29/400]: loss_train: 21.794 loss_val 19.510 loss_ts 62.954\n",
            "best val epoch: 34\n",
            "[34/400]: loss_train: 21.122 loss_val 19.388 loss_ts 61.986\n",
            "best val epoch: 35\n",
            "[35/400]: loss_train: 20.952 loss_val 19.226 loss_ts 62.882\n",
            "best val epoch: 42\n",
            "[42/400]: loss_train: 19.461 loss_val 19.005 loss_ts 62.684\n",
            "best val epoch: 43\n",
            "[43/400]: loss_train: 19.087 loss_val 18.735 loss_ts 60.345\n",
            "best val epoch: 50\n",
            "[50/400]: loss_train: 17.464 loss_val 18.133 loss_ts 56.902\n",
            "best val epoch: 51\n",
            "[51/400]: loss_train: 16.905 loss_val 18.065 loss_ts 56.379\n",
            "best val epoch: 54\n",
            "[54/400]: loss_train: 16.363 loss_val 16.692 loss_ts 61.965\n",
            "best val epoch: 59\n",
            "[59/400]: loss_train: 15.230 loss_val 16.624 loss_ts 68.275\n",
            "best val epoch: 62\n",
            "[62/400]: loss_train: 14.235 loss_val 15.923 loss_ts 68.246\n",
            "best val epoch: 66\n",
            "[66/400]: loss_train: 11.335 loss_val 12.665 loss_ts 55.346\n",
            "best val epoch: 70\n",
            "[70/400]: loss_train: 14.020 loss_val 12.555 loss_ts 58.605\n",
            "best val epoch: 75\n",
            "[75/400]: loss_train: 12.012 loss_val 11.790 loss_ts 70.059\n",
            "best val epoch: 84\n",
            "[84/400]: loss_train: 10.599 loss_val 11.317 loss_ts 57.780\n",
            "best val epoch: 85\n",
            "[85/400]: loss_train: 11.504 loss_val 11.226 loss_ts 64.345\n",
            "best val epoch: 86\n",
            "[86/400]: loss_train: 11.841 loss_val 11.056 loss_ts 66.322\n",
            "best val epoch: 87\n",
            "[87/400]: loss_train: 11.295 loss_val 10.477 loss_ts 66.262\n",
            "best val epoch: 88\n",
            "[88/400]: loss_train: 10.224 loss_val 9.737 loss_ts 66.103\n",
            "best val epoch: 89\n",
            "[89/400]: loss_train: 9.337 loss_val 9.118 loss_ts 64.505\n",
            "best val epoch: 90\n",
            "[90/400]: loss_train: 8.779 loss_val 8.623 loss_ts 60.116\n",
            "best val epoch: 103\n",
            "[103/400]: loss_train: 7.435 loss_val 8.504 loss_ts 54.634\n",
            "best val epoch: 106\n",
            "[106/400]: loss_train: 7.821 loss_val 8.446 loss_ts 55.921\n",
            "best val epoch: 107\n",
            "[107/400]: loss_train: 7.969 loss_val 8.421 loss_ts 56.298\n",
            "best val epoch: 128\n",
            "[128/400]: loss_train: 6.809 loss_val 7.858 loss_ts 58.264\n",
            "best val epoch: 146\n",
            "[146/400]: loss_train: 6.708 loss_val 7.432 loss_ts 60.002\n",
            "best val epoch: 147\n",
            "[147/400]: loss_train: 6.535 loss_val 7.148 loss_ts 52.759\n",
            "best val epoch: 165\n",
            "[165/400]: loss_train: 5.404 loss_val 6.380 loss_ts 51.535\n",
            "best val epoch: 166\n",
            "[166/400]: loss_train: 5.730 loss_val 6.333 loss_ts 55.880\n",
            "best val epoch: 178\n",
            "[178/400]: loss_train: 5.497 loss_val 6.278 loss_ts 51.169\n",
            "best val epoch: 191\n",
            "[191/400]: loss_train: 4.661 loss_val 6.277 loss_ts 51.727\n",
            "best val epoch: 192\n",
            "[192/400]: loss_train: 4.624 loss_val 6.095 loss_ts 53.233\n",
            "best val epoch: 193\n",
            "[193/400]: loss_train: 4.699 loss_val 5.946 loss_ts 56.739\n",
            "best val epoch: 197\n",
            "[197/400]: loss_train: 4.563 loss_val 5.944 loss_ts 47.039\n",
            "best val epoch: 238\n",
            "[238/400]: loss_train: 4.497 loss_val 5.393 loss_ts 67.084\n",
            "best val epoch: 239\n",
            "[239/400]: loss_train: 4.504 loss_val 5.166 loss_ts 65.429\n",
            "best val epoch: 275\n",
            "[275/400]: loss_train: 4.430 loss_val 5.004 loss_ts 66.377\n",
            "best val epoch: 278\n",
            "[278/400]: loss_train: 4.213 loss_val 4.959 loss_ts 62.480\n",
            "best val epoch: 302\n",
            "[302/400]: loss_train: 4.380 loss_val 4.799 loss_ts 54.120\n",
            "best val epoch: 303\n",
            "[303/400]: loss_train: 4.022 loss_val 4.713 loss_ts 58.366\n",
            "best val epoch: 316\n",
            "[316/400]: loss_train: 3.299 loss_val 4.648 loss_ts 58.855\n",
            "best val epoch: 347\n",
            "[347/400]: loss_train: 3.212 loss_val 4.482 loss_ts 54.118\n",
            "Final: 54.1181640625\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 54.118164\n",
            "best val epoch: 1\n",
            "[1/400]: loss_train: 22.701 loss_val 19.738 loss_ts 61.650\n",
            "best val epoch: 13\n",
            "[13/400]: loss_train: 22.381 loss_val 19.722 loss_ts 60.844\n",
            "best val epoch: 18\n",
            "[18/400]: loss_train: 22.394 loss_val 19.664 loss_ts 62.209\n",
            "best val epoch: 19\n",
            "[19/400]: loss_train: 22.283 loss_val 19.650 loss_ts 60.866\n",
            "best val epoch: 33\n",
            "[33/400]: loss_train: 22.039 loss_val 19.633 loss_ts 60.561\n",
            "best val epoch: 35\n",
            "[35/400]: loss_train: 22.197 loss_val 19.624 loss_ts 61.804\n",
            "best val epoch: 36\n",
            "[36/400]: loss_train: 22.062 loss_val 19.548 loss_ts 61.632\n",
            "best val epoch: 37\n",
            "[37/400]: loss_train: 21.912 loss_val 19.479 loss_ts 61.145\n",
            "best val epoch: 45\n",
            "[45/400]: loss_train: 21.541 loss_val 19.338 loss_ts 59.620\n",
            "best val epoch: 46\n",
            "[46/400]: loss_train: 21.393 loss_val 19.223 loss_ts 60.935\n",
            "best val epoch: 49\n",
            "[49/400]: loss_train: 21.343 loss_val 19.176 loss_ts 62.661\n",
            "best val epoch: 50\n",
            "[50/400]: loss_train: 21.384 loss_val 19.166 loss_ts 63.318\n",
            "best val epoch: 51\n",
            "[51/400]: loss_train: 21.218 loss_val 18.992 loss_ts 63.000\n",
            "best val epoch: 52\n",
            "[52/400]: loss_train: 21.026 loss_val 18.881 loss_ts 61.533\n",
            "best val epoch: 59\n",
            "[59/400]: loss_train: 20.247 loss_val 18.560 loss_ts 58.400\n",
            "best val epoch: 60\n",
            "[60/400]: loss_train: 20.258 loss_val 18.354 loss_ts 60.534\n",
            "best val epoch: 62\n",
            "[62/400]: loss_train: 20.268 loss_val 18.272 loss_ts 62.229\n",
            "best val epoch: 63\n",
            "[63/400]: loss_train: 19.911 loss_val 18.151 loss_ts 60.965\n",
            "best val epoch: 64\n",
            "[64/400]: loss_train: 19.606 loss_val 17.994 loss_ts 60.467\n",
            "best val epoch: 76\n",
            "[76/400]: loss_train: 18.928 loss_val 17.948 loss_ts 63.964\n",
            "best val epoch: 81\n",
            "[81/400]: loss_train: 16.329 loss_val 17.259 loss_ts 56.336\n",
            "best val epoch: 82\n",
            "[82/400]: loss_train: 15.878 loss_val 16.542 loss_ts 57.656\n",
            "best val epoch: 83\n",
            "[83/400]: loss_train: 15.289 loss_val 16.192 loss_ts 58.235\n",
            "best val epoch: 87\n",
            "[87/400]: loss_train: 13.293 loss_val 15.888 loss_ts 53.199\n",
            "best val epoch: 91\n",
            "[91/400]: loss_train: 13.965 loss_val 14.811 loss_ts 56.335\n",
            "best val epoch: 93\n",
            "[93/400]: loss_train: 14.719 loss_val 14.646 loss_ts 60.709\n",
            "best val epoch: 94\n",
            "[94/400]: loss_train: 14.260 loss_val 14.051 loss_ts 62.509\n",
            "best val epoch: 95\n",
            "[95/400]: loss_train: 12.996 loss_val 13.332 loss_ts 61.214\n",
            "best val epoch: 96\n",
            "[96/400]: loss_train: 12.155 loss_val 13.330 loss_ts 58.712\n",
            "best val epoch: 97\n",
            "[97/400]: loss_train: 11.934 loss_val 13.097 loss_ts 58.502\n",
            "best val epoch: 98\n",
            "[98/400]: loss_train: 12.203 loss_val 12.493 loss_ts 60.348\n",
            "best val epoch: 108\n",
            "[108/400]: loss_train: 10.033 loss_val 12.419 loss_ts 51.386\n",
            "best val epoch: 109\n",
            "[109/400]: loss_train: 10.772 loss_val 11.935 loss_ts 56.672\n",
            "best val epoch: 117\n",
            "[117/400]: loss_train: 9.856 loss_val 11.875 loss_ts 53.724\n",
            "best val epoch: 118\n",
            "[118/400]: loss_train: 9.142 loss_val 11.471 loss_ts 52.882\n",
            "best val epoch: 124\n",
            "[124/400]: loss_train: 7.489 loss_val 11.027 loss_ts 48.609\n",
            "best val epoch: 125\n",
            "[125/400]: loss_train: 7.578 loss_val 9.517 loss_ts 54.810\n",
            "best val epoch: 126\n",
            "[126/400]: loss_train: 8.674 loss_val 9.054 loss_ts 60.346\n",
            "best val epoch: 128\n",
            "[128/400]: loss_train: 8.053 loss_val 8.636 loss_ts 59.607\n",
            "best val epoch: 152\n",
            "[152/400]: loss_train: 5.672 loss_val 8.097 loss_ts 53.782\n",
            "best val epoch: 153\n",
            "[153/400]: loss_train: 6.065 loss_val 8.083 loss_ts 61.544\n",
            "best val epoch: 198\n",
            "[198/400]: loss_train: 5.411 loss_val 7.948 loss_ts 49.714\n",
            "best val epoch: 208\n",
            "[208/400]: loss_train: 5.434 loss_val 7.945 loss_ts 57.749\n",
            "best val epoch: 209\n",
            "[209/400]: loss_train: 4.733 loss_val 7.197 loss_ts 56.486\n",
            "best val epoch: 210\n",
            "[210/400]: loss_train: 4.590 loss_val 6.936 loss_ts 56.520\n",
            "best val epoch: 229\n",
            "[229/400]: loss_train: 3.737 loss_val 6.814 loss_ts 53.210\n",
            "best val epoch: 230\n",
            "[230/400]: loss_train: 3.738 loss_val 6.631 loss_ts 50.600\n",
            "best val epoch: 241\n",
            "[241/400]: loss_train: 4.352 loss_val 6.553 loss_ts 58.160\n",
            "best val epoch: 242\n",
            "[242/400]: loss_train: 4.223 loss_val 6.513 loss_ts 54.188\n",
            "best val epoch: 243\n",
            "[243/400]: loss_train: 3.956 loss_val 6.408 loss_ts 48.105\n",
            "best val epoch: 244\n",
            "[244/400]: loss_train: 3.809 loss_val 6.336 loss_ts 44.010\n",
            "best val epoch: 245\n",
            "[245/400]: loss_train: 3.692 loss_val 6.270 loss_ts 41.504\n",
            "best val epoch: 246\n",
            "[246/400]: loss_train: 3.635 loss_val 6.253 loss_ts 41.444\n",
            "best val epoch: 247\n",
            "[247/400]: loss_train: 3.580 loss_val 6.240 loss_ts 44.104\n",
            "best val epoch: 248\n",
            "[248/400]: loss_train: 3.507 loss_val 6.235 loss_ts 46.811\n",
            "best val epoch: 249\n",
            "[249/400]: loss_train: 3.345 loss_val 6.156 loss_ts 41.163\n",
            "Final: 41.16349792480469\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 41.163498\n",
            "best val epoch: 1\n",
            "[1/400]: loss_train: 21.924 loss_val 24.013 loss_ts 60.889\n",
            "best val epoch: 2\n",
            "[2/400]: loss_train: 21.921 loss_val 23.901 loss_ts 61.452\n",
            "best val epoch: 3\n",
            "[3/400]: loss_train: 21.912 loss_val 23.853 loss_ts 61.556\n",
            "best val epoch: 4\n",
            "[4/400]: loss_train: 21.913 loss_val 23.831 loss_ts 61.907\n",
            "best val epoch: 5\n",
            "[5/400]: loss_train: 21.899 loss_val 23.814 loss_ts 62.058\n",
            "best val epoch: 6\n",
            "[6/400]: loss_train: 21.879 loss_val 23.791 loss_ts 62.205\n",
            "best val epoch: 9\n",
            "[9/400]: loss_train: 21.840 loss_val 23.760 loss_ts 62.287\n",
            "best val epoch: 20\n",
            "[20/400]: loss_train: 21.653 loss_val 23.691 loss_ts 59.937\n",
            "best val epoch: 21\n",
            "[21/400]: loss_train: 21.598 loss_val 23.594 loss_ts 60.074\n",
            "best val epoch: 22\n",
            "[22/400]: loss_train: 21.502 loss_val 23.517 loss_ts 60.028\n",
            "best val epoch: 23\n",
            "[23/400]: loss_train: 21.355 loss_val 23.418 loss_ts 60.078\n",
            "best val epoch: 24\n",
            "[24/400]: loss_train: 21.141 loss_val 23.304 loss_ts 60.245\n",
            "best val epoch: 25\n",
            "[25/400]: loss_train: 20.838 loss_val 23.178 loss_ts 60.446\n",
            "best val epoch: 26\n",
            "[26/400]: loss_train: 20.435 loss_val 22.961 loss_ts 61.466\n",
            "best val epoch: 33\n",
            "[33/400]: loss_train: 19.154 loss_val 22.581 loss_ts 61.843\n",
            "best val epoch: 54\n",
            "[54/400]: loss_train: 16.748 loss_val 22.274 loss_ts 43.860\n",
            "best val epoch: 59\n",
            "[59/400]: loss_train: 15.784 loss_val 21.034 loss_ts 38.054\n",
            "best val epoch: 60\n",
            "[60/400]: loss_train: 16.789 loss_val 20.523 loss_ts 34.189\n",
            "best val epoch: 61\n",
            "[61/400]: loss_train: 16.931 loss_val 20.166 loss_ts 32.140\n",
            "best val epoch: 62\n",
            "[62/400]: loss_train: 15.561 loss_val 19.626 loss_ts 33.494\n",
            "best val epoch: 70\n",
            "[70/400]: loss_train: 14.902 loss_val 19.481 loss_ts 57.171\n",
            "best val epoch: 71\n",
            "[71/400]: loss_train: 12.842 loss_val 18.501 loss_ts 43.049\n",
            "best val epoch: 72\n",
            "[72/400]: loss_train: 12.859 loss_val 18.094 loss_ts 30.247\n",
            "best val epoch: 73\n",
            "[73/400]: loss_train: 13.084 loss_val 17.215 loss_ts 26.325\n",
            "best val epoch: 74\n",
            "[74/400]: loss_train: 12.042 loss_val 16.698 loss_ts 29.472\n",
            "best val epoch: 83\n",
            "[83/400]: loss_train: 10.359 loss_val 16.583 loss_ts 31.056\n",
            "best val epoch: 99\n",
            "[99/400]: loss_train: 9.759 loss_val 16.447 loss_ts 38.219\n",
            "best val epoch: 101\n",
            "[101/400]: loss_train: 9.295 loss_val 16.338 loss_ts 32.613\n",
            "best val epoch: 131\n",
            "[131/400]: loss_train: 7.108 loss_val 16.139 loss_ts 40.690\n",
            "best val epoch: 141\n",
            "[141/400]: loss_train: 7.111 loss_val 16.120 loss_ts 40.134\n",
            "best val epoch: 142\n",
            "[142/400]: loss_train: 7.250 loss_val 15.978 loss_ts 35.507\n",
            "best val epoch: 143\n",
            "[143/400]: loss_train: 7.462 loss_val 15.856 loss_ts 32.885\n",
            "best val epoch: 144\n",
            "[144/400]: loss_train: 7.416 loss_val 15.786 loss_ts 31.819\n",
            "best val epoch: 145\n",
            "[145/400]: loss_train: 7.105 loss_val 15.763 loss_ts 33.278\n",
            "best val epoch: 187\n",
            "[187/400]: loss_train: 5.857 loss_val 15.518 loss_ts 32.148\n",
            "best val epoch: 188\n",
            "[188/400]: loss_train: 5.988 loss_val 15.505 loss_ts 26.662\n",
            "best val epoch: 189\n",
            "[189/400]: loss_train: 6.350 loss_val 15.404 loss_ts 32.590\n",
            "best val epoch: 194\n",
            "[194/400]: loss_train: 6.377 loss_val 15.343 loss_ts 43.585\n",
            "best val epoch: 195\n",
            "[195/400]: loss_train: 5.906 loss_val 15.042 loss_ts 40.966\n",
            "best val epoch: 196\n",
            "[196/400]: loss_train: 5.634 loss_val 14.879 loss_ts 37.864\n",
            "best val epoch: 197\n",
            "[197/400]: loss_train: 5.515 loss_val 14.734 loss_ts 35.768\n",
            "best val epoch: 198\n",
            "[198/400]: loss_train: 5.542 loss_val 14.608 loss_ts 36.772\n",
            "best val epoch: 213\n",
            "[213/400]: loss_train: 6.449 loss_val 14.518 loss_ts 21.084\n",
            "best val epoch: 214\n",
            "[214/400]: loss_train: 6.407 loss_val 14.310 loss_ts 20.596\n",
            "best val epoch: 215\n",
            "[215/400]: loss_train: 6.167 loss_val 14.183 loss_ts 18.455\n",
            "best val epoch: 216\n",
            "[216/400]: loss_train: 5.715 loss_val 14.148 loss_ts 15.741\n",
            "best val epoch: 233\n",
            "[233/400]: loss_train: 4.995 loss_val 13.894 loss_ts 32.572\n",
            "best val epoch: 245\n",
            "[245/400]: loss_train: 4.951 loss_val 13.685 loss_ts 21.325\n",
            "best val epoch: 255\n",
            "[255/400]: loss_train: 4.306 loss_val 13.599 loss_ts 26.419\n",
            "best val epoch: 256\n",
            "[256/400]: loss_train: 4.155 loss_val 13.446 loss_ts 29.228\n",
            "best val epoch: 272\n",
            "[272/400]: loss_train: 4.290 loss_val 13.277 loss_ts 45.954\n",
            "best val epoch: 273\n",
            "[273/400]: loss_train: 4.284 loss_val 13.244 loss_ts 42.975\n",
            "best val epoch: 301\n",
            "[301/400]: loss_train: 5.655 loss_val 13.194 loss_ts 14.358\n",
            "best val epoch: 302\n",
            "[302/400]: loss_train: 5.251 loss_val 12.699 loss_ts 14.729\n",
            "best val epoch: 303\n",
            "[303/400]: loss_train: 5.093 loss_val 12.505 loss_ts 31.835\n",
            "best val epoch: 327\n",
            "[327/400]: loss_train: 4.385 loss_val 12.462 loss_ts 63.238\n",
            "best val epoch: 330\n",
            "[330/400]: loss_train: 4.563 loss_val 12.359 loss_ts 64.754\n",
            "best val epoch: 331\n",
            "[331/400]: loss_train: 4.371 loss_val 11.820 loss_ts 65.533\n",
            "best val epoch: 332\n",
            "[332/400]: loss_train: 4.270 loss_val 11.449 loss_ts 67.881\n",
            "best val epoch: 333\n",
            "[333/400]: loss_train: 4.294 loss_val 11.184 loss_ts 69.901\n",
            "best val epoch: 334\n",
            "[334/400]: loss_train: 4.198 loss_val 10.599 loss_ts 69.455\n",
            "best val epoch: 335\n",
            "[335/400]: loss_train: 4.096 loss_val 10.433 loss_ts 67.848\n",
            "best val epoch: 394\n",
            "[394/400]: loss_train: 6.832 loss_val 10.074 loss_ts 35.337\n",
            "best val epoch: 395\n",
            "[395/400]: loss_train: 6.822 loss_val 9.068 loss_ts 29.875\n",
            "best val epoch: 396\n",
            "[396/400]: loss_train: 6.602 loss_val 7.451 loss_ts 37.154\n",
            "Final: 37.153507232666016\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 37.153507\n",
            "best val epoch: 1\n",
            "[1/400]: loss_train: 23.431 loss_val 17.619 loss_ts 61.079\n",
            "best val epoch: 2\n",
            "[2/400]: loss_train: 23.430 loss_val 17.497 loss_ts 61.571\n",
            "best val epoch: 9\n",
            "[9/400]: loss_train: 23.036 loss_val 17.378 loss_ts 60.959\n",
            "best val epoch: 10\n",
            "[10/400]: loss_train: 22.987 loss_val 17.293 loss_ts 61.077\n",
            "best val epoch: 11\n",
            "[11/400]: loss_train: 22.927 loss_val 17.232 loss_ts 61.114\n",
            "best val epoch: 12\n",
            "[12/400]: loss_train: 22.860 loss_val 17.180 loss_ts 61.102\n",
            "best val epoch: 13\n",
            "[13/400]: loss_train: 22.940 loss_val 17.129 loss_ts 61.701\n",
            "best val epoch: 14\n",
            "[14/400]: loss_train: 22.925 loss_val 17.109 loss_ts 61.721\n",
            "best val epoch: 15\n",
            "[15/400]: loss_train: 22.878 loss_val 17.081 loss_ts 61.646\n",
            "best val epoch: 16\n",
            "[16/400]: loss_train: 22.811 loss_val 17.044 loss_ts 61.626\n",
            "best val epoch: 21\n",
            "[21/400]: loss_train: 22.290 loss_val 16.979 loss_ts 60.694\n",
            "best val epoch: 37\n",
            "[37/400]: loss_train: 22.258 loss_val 16.948 loss_ts 61.076\n",
            "best val epoch: 40\n",
            "[40/400]: loss_train: 22.032 loss_val 16.910 loss_ts 60.784\n",
            "best val epoch: 41\n",
            "[41/400]: loss_train: 21.804 loss_val 16.822 loss_ts 59.975\n",
            "best val epoch: 42\n",
            "[42/400]: loss_train: 21.652 loss_val 16.811 loss_ts 58.861\n",
            "best val epoch: 48\n",
            "[48/400]: loss_train: 21.018 loss_val 16.405 loss_ts 59.115\n",
            "best val epoch: 53\n",
            "[53/400]: loss_train: 21.052 loss_val 15.962 loss_ts 60.990\n",
            "best val epoch: 62\n",
            "[62/400]: loss_train: 19.302 loss_val 15.536 loss_ts 58.614\n",
            "best val epoch: 63\n",
            "[63/400]: loss_train: 19.181 loss_val 14.963 loss_ts 60.875\n",
            "best val epoch: 64\n",
            "[64/400]: loss_train: 18.902 loss_val 14.745 loss_ts 61.343\n",
            "best val epoch: 69\n",
            "[69/400]: loss_train: 14.784 loss_val 14.381 loss_ts 50.977\n",
            "best val epoch: 73\n",
            "[73/400]: loss_train: 16.352 loss_val 13.921 loss_ts 60.483\n",
            "best val epoch: 74\n",
            "[74/400]: loss_train: 15.766 loss_val 13.026 loss_ts 46.634\n",
            "best val epoch: 75\n",
            "[75/400]: loss_train: 14.342 loss_val 12.482 loss_ts 43.160\n",
            "best val epoch: 76\n",
            "[76/400]: loss_train: 12.519 loss_val 12.039 loss_ts 45.153\n",
            "best val epoch: 95\n",
            "[95/400]: loss_train: 12.240 loss_val 11.867 loss_ts 38.571\n",
            "best val epoch: 97\n",
            "[97/400]: loss_train: 10.518 loss_val 10.801 loss_ts 56.132\n",
            "best val epoch: 112\n",
            "[112/400]: loss_train: 10.653 loss_val 10.417 loss_ts 42.007\n",
            "best val epoch: 113\n",
            "[113/400]: loss_train: 10.676 loss_val 10.241 loss_ts 42.868\n",
            "best val epoch: 114\n",
            "[114/400]: loss_train: 10.449 loss_val 9.878 loss_ts 42.745\n",
            "best val epoch: 115\n",
            "[115/400]: loss_train: 10.167 loss_val 9.625 loss_ts 41.697\n",
            "best val epoch: 134\n",
            "[134/400]: loss_train: 7.574 loss_val 9.118 loss_ts 42.702\n",
            "best val epoch: 156\n",
            "[156/400]: loss_train: 7.884 loss_val 9.008 loss_ts 44.349\n",
            "best val epoch: 157\n",
            "[157/400]: loss_train: 7.454 loss_val 8.757 loss_ts 45.146\n",
            "best val epoch: 158\n",
            "[158/400]: loss_train: 6.865 loss_val 8.407 loss_ts 45.142\n",
            "best val epoch: 159\n",
            "[159/400]: loss_train: 6.354 loss_val 8.095 loss_ts 44.576\n",
            "best val epoch: 160\n",
            "[160/400]: loss_train: 6.238 loss_val 8.069 loss_ts 43.711\n",
            "best val epoch: 180\n",
            "[180/400]: loss_train: 5.858 loss_val 7.744 loss_ts 25.325\n",
            "best val epoch: 181\n",
            "[181/400]: loss_train: 6.235 loss_val 6.906 loss_ts 31.102\n",
            "best val epoch: 192\n",
            "[192/400]: loss_train: 5.982 loss_val 6.743 loss_ts 28.349\n",
            "best val epoch: 194\n",
            "[194/400]: loss_train: 5.971 loss_val 6.732 loss_ts 26.006\n",
            "best val epoch: 195\n",
            "[195/400]: loss_train: 5.826 loss_val 6.627 loss_ts 26.601\n",
            "best val epoch: 196\n",
            "[196/400]: loss_train: 5.687 loss_val 6.561 loss_ts 35.690\n",
            "best val epoch: 197\n",
            "[197/400]: loss_train: 5.533 loss_val 6.517 loss_ts 37.017\n",
            "best val epoch: 205\n",
            "[205/400]: loss_train: 5.636 loss_val 6.326 loss_ts 45.832\n",
            "best val epoch: 212\n",
            "[212/400]: loss_train: 5.288 loss_val 6.228 loss_ts 44.713\n",
            "best val epoch: 215\n",
            "[215/400]: loss_train: 5.318 loss_val 6.181 loss_ts 45.212\n",
            "best val epoch: 227\n",
            "[227/400]: loss_train: 5.094 loss_val 5.841 loss_ts 50.126\n",
            "best val epoch: 228\n",
            "[228/400]: loss_train: 5.071 loss_val 5.513 loss_ts 50.894\n",
            "best val epoch: 266\n",
            "[266/400]: loss_train: 4.623 loss_val 5.363 loss_ts 51.917\n",
            "best val epoch: 353\n",
            "[353/400]: loss_train: 4.266 loss_val 5.305 loss_ts 51.613\n",
            "best val epoch: 359\n",
            "[359/400]: loss_train: 4.196 loss_val 5.215 loss_ts 53.636\n",
            "best val epoch: 360\n",
            "[360/400]: loss_train: 4.160 loss_val 5.147 loss_ts 52.885\n",
            "best val epoch: 361\n",
            "[361/400]: loss_train: 4.124 loss_val 5.091 loss_ts 50.496\n",
            "Final: 50.496089935302734\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 50.49609\n",
            "best val epoch: 2\n",
            "[2/400]: loss_train: 21.429 loss_val 24.646 loss_ts 59.916\n",
            "best val epoch: 3\n",
            "[3/400]: loss_train: 21.325 loss_val 24.638 loss_ts 59.902\n",
            "best val epoch: 18\n",
            "[18/400]: loss_train: 20.314 loss_val 24.630 loss_ts 59.474\n",
            "best val epoch: 19\n",
            "[19/400]: loss_train: 20.330 loss_val 24.405 loss_ts 59.053\n",
            "best val epoch: 20\n",
            "[20/400]: loss_train: 20.508 loss_val 24.066 loss_ts 58.143\n",
            "best val epoch: 21\n",
            "[21/400]: loss_train: 20.677 loss_val 23.905 loss_ts 57.639\n",
            "best val epoch: 28\n",
            "[28/400]: loss_train: 19.529 loss_val 23.743 loss_ts 58.393\n",
            "best val epoch: 29\n",
            "[29/400]: loss_train: 19.786 loss_val 23.484 loss_ts 57.238\n",
            "best val epoch: 30\n",
            "[30/400]: loss_train: 20.000 loss_val 23.357 loss_ts 56.284\n",
            "best val epoch: 41\n",
            "[41/400]: loss_train: 18.723 loss_val 23.240 loss_ts 64.285\n",
            "best val epoch: 42\n",
            "[42/400]: loss_train: 18.345 loss_val 22.457 loss_ts 63.661\n",
            "best val epoch: 43\n",
            "[43/400]: loss_train: 18.295 loss_val 22.156 loss_ts 62.626\n",
            "best val epoch: 44\n",
            "[44/400]: loss_train: 18.240 loss_val 21.967 loss_ts 61.371\n",
            "best val epoch: 45\n",
            "[45/400]: loss_train: 18.100 loss_val 21.768 loss_ts 60.278\n",
            "best val epoch: 51\n",
            "[51/400]: loss_train: 17.483 loss_val 21.620 loss_ts 56.558\n",
            "best val epoch: 52\n",
            "[52/400]: loss_train: 16.797 loss_val 21.254 loss_ts 58.751\n",
            "best val epoch: 53\n",
            "[53/400]: loss_train: 16.673 loss_val 20.504 loss_ts 56.299\n",
            "best val epoch: 56\n",
            "[56/400]: loss_train: 17.154 loss_val 20.457 loss_ts 61.692\n",
            "best val epoch: 61\n",
            "[61/400]: loss_train: 17.036 loss_val 20.096 loss_ts 50.031\n",
            "best val epoch: 65\n",
            "[65/400]: loss_train: 16.573 loss_val 19.950 loss_ts 48.188\n",
            "best val epoch: 66\n",
            "[66/400]: loss_train: 15.937 loss_val 19.609 loss_ts 50.050\n",
            "best val epoch: 67\n",
            "[67/400]: loss_train: 15.377 loss_val 19.575 loss_ts 53.331\n",
            "best val epoch: 71\n",
            "[71/400]: loss_train: 15.066 loss_val 19.097 loss_ts 60.082\n",
            "best val epoch: 72\n",
            "[72/400]: loss_train: 14.935 loss_val 15.357 loss_ts 31.713\n",
            "best val epoch: 81\n",
            "[81/400]: loss_train: 12.230 loss_val 14.711 loss_ts 37.875\n",
            "best val epoch: 82\n",
            "[82/400]: loss_train: 12.486 loss_val 14.603 loss_ts 34.212\n",
            "best val epoch: 89\n",
            "[89/400]: loss_train: 10.155 loss_val 12.820 loss_ts 42.605\n",
            "best val epoch: 92\n",
            "[92/400]: loss_train: 10.105 loss_val 12.736 loss_ts 62.690\n",
            "best val epoch: 105\n",
            "[105/400]: loss_train: 10.784 loss_val 12.632 loss_ts 49.031\n",
            "best val epoch: 106\n",
            "[106/400]: loss_train: 10.192 loss_val 12.228 loss_ts 38.063\n",
            "best val epoch: 107\n",
            "[107/400]: loss_train: 9.922 loss_val 12.214 loss_ts 30.905\n",
            "best val epoch: 109\n",
            "[109/400]: loss_train: 9.524 loss_val 11.903 loss_ts 26.378\n",
            "best val epoch: 110\n",
            "[110/400]: loss_train: 9.030 loss_val 11.370 loss_ts 29.873\n",
            "best val epoch: 111\n",
            "[111/400]: loss_train: 9.211 loss_val 11.125 loss_ts 40.046\n",
            "best val epoch: 116\n",
            "[116/400]: loss_train: 8.464 loss_val 10.643 loss_ts 51.284\n",
            "best val epoch: 117\n",
            "[117/400]: loss_train: 8.044 loss_val 10.009 loss_ts 49.497\n",
            "best val epoch: 118\n",
            "[118/400]: loss_train: 7.737 loss_val 9.810 loss_ts 33.454\n",
            "best val epoch: 123\n",
            "[123/400]: loss_train: 7.571 loss_val 9.519 loss_ts 23.631\n",
            "best val epoch: 124\n",
            "[124/400]: loss_train: 6.802 loss_val 8.834 loss_ts 25.078\n",
            "best val epoch: 125\n",
            "[125/400]: loss_train: 6.768 loss_val 8.392 loss_ts 56.819\n",
            "best val epoch: 126\n",
            "[126/400]: loss_train: 7.439 loss_val 8.379 loss_ts 64.636\n",
            "best val epoch: 132\n",
            "[132/400]: loss_train: 6.358 loss_val 7.722 loss_ts 17.469\n",
            "best val epoch: 153\n",
            "[153/400]: loss_train: 5.792 loss_val 7.330 loss_ts 55.301\n",
            "best val epoch: 157\n",
            "[157/400]: loss_train: 5.702 loss_val 7.316 loss_ts 62.783\n",
            "best val epoch: 171\n",
            "[171/400]: loss_train: 5.039 loss_val 7.240 loss_ts 59.799\n",
            "best val epoch: 173\n",
            "[173/400]: loss_train: 5.067 loss_val 7.139 loss_ts 54.950\n",
            "best val epoch: 197\n",
            "[197/400]: loss_train: 4.517 loss_val 7.042 loss_ts 60.136\n",
            "best val epoch: 198\n",
            "[198/400]: loss_train: 4.862 loss_val 6.371 loss_ts 54.256\n",
            "best val epoch: 273\n",
            "[273/400]: loss_train: 3.692 loss_val 6.228 loss_ts 57.959\n",
            "best val epoch: 281\n",
            "[281/400]: loss_train: 3.698 loss_val 6.201 loss_ts 26.304\n",
            "best val epoch: 282\n",
            "[282/400]: loss_train: 3.511 loss_val 6.061 loss_ts 25.418\n",
            "best val epoch: 283\n",
            "[283/400]: loss_train: 3.390 loss_val 6.060 loss_ts 26.779\n",
            "best val epoch: 298\n",
            "[298/400]: loss_train: 3.309 loss_val 6.004 loss_ts 24.382\n",
            "best val epoch: 299\n",
            "[299/400]: loss_train: 3.390 loss_val 6.002 loss_ts 22.446\n",
            "best val epoch: 301\n",
            "[301/400]: loss_train: 3.620 loss_val 5.996 loss_ts 21.458\n",
            "best val epoch: 302\n",
            "[302/400]: loss_train: 3.533 loss_val 5.882 loss_ts 22.636\n",
            "best val epoch: 303\n",
            "[303/400]: loss_train: 3.516 loss_val 5.859 loss_ts 23.793\n",
            "best val epoch: 304\n",
            "[304/400]: loss_train: 3.500 loss_val 5.758 loss_ts 24.421\n",
            "best val epoch: 346\n",
            "[346/400]: loss_train: 3.748 loss_val 5.726 loss_ts 13.224\n",
            "Final: 13.224272727966309\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 13.224273\n",
            "best val epoch: 1\n",
            "[1/400]: loss_train: 22.374 loss_val 21.732 loss_ts 60.066\n",
            "best val epoch: 2\n",
            "[2/400]: loss_train: 22.280 loss_val 21.667 loss_ts 59.911\n",
            "best val epoch: 3\n",
            "[3/400]: loss_train: 22.184 loss_val 21.634 loss_ts 60.724\n",
            "best val epoch: 4\n",
            "[4/400]: loss_train: 22.159 loss_val 21.630 loss_ts 61.289\n",
            "best val epoch: 5\n",
            "[5/400]: loss_train: 22.112 loss_val 21.605 loss_ts 61.423\n",
            "best val epoch: 9\n",
            "[9/400]: loss_train: 21.982 loss_val 21.583 loss_ts 62.042\n",
            "best val epoch: 10\n",
            "[10/400]: loss_train: 21.929 loss_val 21.557 loss_ts 62.076\n",
            "best val epoch: 13\n",
            "[13/400]: loss_train: 21.814 loss_val 21.468 loss_ts 62.218\n",
            "best val epoch: 14\n",
            "[14/400]: loss_train: 21.758 loss_val 21.397 loss_ts 61.836\n",
            "best val epoch: 15\n",
            "[15/400]: loss_train: 21.727 loss_val 21.340 loss_ts 61.029\n",
            "best val epoch: 16\n",
            "[16/400]: loss_train: 21.763 loss_val 21.297 loss_ts 60.362\n",
            "best val epoch: 17\n",
            "[17/400]: loss_train: 21.625 loss_val 21.206 loss_ts 60.542\n",
            "best val epoch: 18\n",
            "[18/400]: loss_train: 21.461 loss_val 21.083 loss_ts 60.787\n",
            "best val epoch: 19\n",
            "[19/400]: loss_train: 21.335 loss_val 20.918 loss_ts 60.236\n",
            "best val epoch: 20\n",
            "[20/400]: loss_train: 21.286 loss_val 20.770 loss_ts 59.580\n",
            "best val epoch: 21\n",
            "[21/400]: loss_train: 21.022 loss_val 20.605 loss_ts 60.145\n",
            "best val epoch: 23\n",
            "[23/400]: loss_train: 20.688 loss_val 20.580 loss_ts 61.292\n",
            "best val epoch: 24\n",
            "[24/400]: loss_train: 20.557 loss_val 20.520 loss_ts 61.448\n",
            "best val epoch: 28\n",
            "[28/400]: loss_train: 20.485 loss_val 20.351 loss_ts 60.326\n",
            "best val epoch: 30\n",
            "[30/400]: loss_train: 20.606 loss_val 20.284 loss_ts 59.201\n",
            "best val epoch: 31\n",
            "[31/400]: loss_train: 20.405 loss_val 20.178 loss_ts 59.874\n",
            "best val epoch: 32\n",
            "[32/400]: loss_train: 20.141 loss_val 19.985 loss_ts 60.227\n",
            "best val epoch: 33\n",
            "[33/400]: loss_train: 19.824 loss_val 19.736 loss_ts 60.667\n",
            "best val epoch: 34\n",
            "[34/400]: loss_train: 19.348 loss_val 19.213 loss_ts 60.461\n",
            "best val epoch: 35\n",
            "[35/400]: loss_train: 19.496 loss_val 18.309 loss_ts 57.119\n",
            "best val epoch: 36\n",
            "[36/400]: loss_train: 18.975 loss_val 18.076 loss_ts 57.170\n",
            "best val epoch: 41\n",
            "[41/400]: loss_train: 16.918 loss_val 17.601 loss_ts 58.690\n",
            "best val epoch: 42\n",
            "[42/400]: loss_train: 16.194 loss_val 17.075 loss_ts 58.648\n",
            "best val epoch: 43\n",
            "[43/400]: loss_train: 15.644 loss_val 16.901 loss_ts 59.468\n",
            "best val epoch: 46\n",
            "[46/400]: loss_train: 15.077 loss_val 16.502 loss_ts 61.457\n",
            "best val epoch: 47\n",
            "[47/400]: loss_train: 13.987 loss_val 15.230 loss_ts 55.969\n",
            "best val epoch: 54\n",
            "[54/400]: loss_train: 12.223 loss_val 13.576 loss_ts 52.052\n",
            "best val epoch: 55\n",
            "[55/400]: loss_train: 13.656 loss_val 13.028 loss_ts 40.876\n",
            "best val epoch: 59\n",
            "[59/400]: loss_train: 11.151 loss_val 12.784 loss_ts 55.623\n",
            "best val epoch: 60\n",
            "[60/400]: loss_train: 10.058 loss_val 10.474 loss_ts 44.046\n",
            "best val epoch: 85\n",
            "[85/400]: loss_train: 7.275 loss_val 9.772 loss_ts 57.249\n",
            "best val epoch: 93\n",
            "[93/400]: loss_train: 6.765 loss_val 9.095 loss_ts 41.365\n",
            "best val epoch: 94\n",
            "[94/400]: loss_train: 6.433 loss_val 8.302 loss_ts 44.345\n",
            "best val epoch: 95\n",
            "[95/400]: loss_train: 6.415 loss_val 7.996 loss_ts 45.346\n",
            "best val epoch: 99\n",
            "[99/400]: loss_train: 6.119 loss_val 7.810 loss_ts 43.129\n",
            "best val epoch: 100\n",
            "[100/400]: loss_train: 6.105 loss_val 7.641 loss_ts 45.600\n",
            "best val epoch: 105\n",
            "[105/400]: loss_train: 5.458 loss_val 7.515 loss_ts 52.061\n",
            "best val epoch: 145\n",
            "[145/400]: loss_train: 5.577 loss_val 7.173 loss_ts 52.983\n",
            "best val epoch: 155\n",
            "[155/400]: loss_train: 5.659 loss_val 7.077 loss_ts 54.341\n",
            "best val epoch: 156\n",
            "[156/400]: loss_train: 4.877 loss_val 6.368 loss_ts 50.084\n",
            "best val epoch: 161\n",
            "[161/400]: loss_train: 4.974 loss_val 6.325 loss_ts 52.167\n",
            "best val epoch: 162\n",
            "[162/400]: loss_train: 4.892 loss_val 6.218 loss_ts 52.139\n",
            "best val epoch: 163\n",
            "[163/400]: loss_train: 4.818 loss_val 6.164 loss_ts 50.480\n",
            "best val epoch: 169\n",
            "[169/400]: loss_train: 5.328 loss_val 6.145 loss_ts 42.932\n",
            "best val epoch: 177\n",
            "[177/400]: loss_train: 4.583 loss_val 6.136 loss_ts 52.461\n",
            "best val epoch: 178\n",
            "[178/400]: loss_train: 4.259 loss_val 6.113 loss_ts 48.052\n",
            "best val epoch: 220\n",
            "[220/400]: loss_train: 4.202 loss_val 5.953 loss_ts 50.241\n",
            "best val epoch: 223\n",
            "[223/400]: loss_train: 4.662 loss_val 5.889 loss_ts 18.186\n",
            "best val epoch: 224\n",
            "[224/400]: loss_train: 4.304 loss_val 5.719 loss_ts 18.884\n",
            "best val epoch: 243\n",
            "[243/400]: loss_train: 4.030 loss_val 5.680 loss_ts 19.460\n",
            "best val epoch: 251\n",
            "[251/400]: loss_train: 4.579 loss_val 5.657 loss_ts 50.344\n",
            "best val epoch: 252\n",
            "[252/400]: loss_train: 4.147 loss_val 5.464 loss_ts 41.378\n",
            "best val epoch: 257\n",
            "[257/400]: loss_train: 3.798 loss_val 5.464 loss_ts 37.844\n",
            "best val epoch: 262\n",
            "[262/400]: loss_train: 3.677 loss_val 5.223 loss_ts 35.948\n",
            "best val epoch: 263\n",
            "[263/400]: loss_train: 3.704 loss_val 4.988 loss_ts 14.953\n",
            "best val epoch: 360\n",
            "[360/400]: loss_train: 3.312 loss_val 4.955 loss_ts 16.204\n",
            "Final: 16.20400047302246\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 16.204\n",
            "best val epoch: 4\n",
            "[4/400]: loss_train: 23.148 loss_val 18.698 loss_ts 60.591\n",
            "best val epoch: 5\n",
            "[5/400]: loss_train: 23.150 loss_val 18.593 loss_ts 61.268\n",
            "best val epoch: 6\n",
            "[6/400]: loss_train: 23.154 loss_val 18.568 loss_ts 61.483\n",
            "best val epoch: 8\n",
            "[8/400]: loss_train: 23.167 loss_val 18.567 loss_ts 61.579\n",
            "best val epoch: 13\n",
            "[13/400]: loss_train: 23.084 loss_val 18.499 loss_ts 61.343\n",
            "best val epoch: 14\n",
            "[14/400]: loss_train: 23.130 loss_val 18.434 loss_ts 62.107\n",
            "best val epoch: 17\n",
            "[17/400]: loss_train: 23.168 loss_val 18.395 loss_ts 63.271\n",
            "best val epoch: 18\n",
            "[18/400]: loss_train: 22.943 loss_val 18.302 loss_ts 61.767\n",
            "best val epoch: 48\n",
            "[48/400]: loss_train: 22.384 loss_val 18.257 loss_ts 57.116\n",
            "best val epoch: 49\n",
            "[49/400]: loss_train: 22.253 loss_val 17.931 loss_ts 58.485\n",
            "best val epoch: 50\n",
            "[50/400]: loss_train: 22.247 loss_val 17.802 loss_ts 59.452\n",
            "best val epoch: 51\n",
            "[51/400]: loss_train: 22.107 loss_val 17.683 loss_ts 59.446\n",
            "best val epoch: 52\n",
            "[52/400]: loss_train: 21.953 loss_val 17.484 loss_ts 59.767\n",
            "best val epoch: 53\n",
            "[53/400]: loss_train: 21.767 loss_val 17.330 loss_ts 59.553\n",
            "best val epoch: 63\n",
            "[63/400]: loss_train: 21.007 loss_val 16.956 loss_ts 55.759\n",
            "best val epoch: 64\n",
            "[64/400]: loss_train: 20.933 loss_val 16.690 loss_ts 59.601\n",
            "best val epoch: 66\n",
            "[66/400]: loss_train: 20.604 loss_val 16.350 loss_ts 60.427\n",
            "best val epoch: 67\n",
            "[67/400]: loss_train: 20.271 loss_val 16.266 loss_ts 56.812\n",
            "best val epoch: 81\n",
            "[81/400]: loss_train: 18.759 loss_val 16.078 loss_ts 52.741\n",
            "best val epoch: 88\n",
            "[88/400]: loss_train: 18.231 loss_val 15.785 loss_ts 50.077\n",
            "best val epoch: 89\n",
            "[89/400]: loss_train: 18.292 loss_val 15.553 loss_ts 53.634\n",
            "best val epoch: 90\n",
            "[90/400]: loss_train: 18.498 loss_val 15.445 loss_ts 56.339\n",
            "best val epoch: 91\n",
            "[91/400]: loss_train: 17.777 loss_val 15.286 loss_ts 54.331\n",
            "best val epoch: 94\n",
            "[94/400]: loss_train: 15.693 loss_val 14.661 loss_ts 47.839\n",
            "best val epoch: 95\n",
            "[95/400]: loss_train: 14.749 loss_val 13.686 loss_ts 52.442\n",
            "best val epoch: 96\n",
            "[96/400]: loss_train: 14.568 loss_val 13.517 loss_ts 56.021\n",
            "best val epoch: 99\n",
            "[99/400]: loss_train: 12.090 loss_val 12.597 loss_ts 54.013\n",
            "best val epoch: 118\n",
            "[118/400]: loss_train: 11.322 loss_val 12.472 loss_ts 55.201\n",
            "best val epoch: 123\n",
            "[123/400]: loss_train: 10.419 loss_val 11.517 loss_ts 46.801\n",
            "best val epoch: 151\n",
            "[151/400]: loss_train: 9.306 loss_val 11.434 loss_ts 57.844\n",
            "best val epoch: 152\n",
            "[152/400]: loss_train: 9.250 loss_val 11.266 loss_ts 56.622\n",
            "best val epoch: 153\n",
            "[153/400]: loss_train: 9.109 loss_val 11.138 loss_ts 54.770\n",
            "best val epoch: 154\n",
            "[154/400]: loss_train: 8.985 loss_val 11.026 loss_ts 53.189\n",
            "best val epoch: 155\n",
            "[155/400]: loss_train: 8.893 loss_val 10.971 loss_ts 51.068\n",
            "best val epoch: 160\n",
            "[160/400]: loss_train: 8.606 loss_val 10.838 loss_ts 46.893\n",
            "best val epoch: 161\n",
            "[161/400]: loss_train: 8.346 loss_val 10.720 loss_ts 44.956\n",
            "best val epoch: 162\n",
            "[162/400]: loss_train: 8.194 loss_val 10.589 loss_ts 44.518\n",
            "best val epoch: 163\n",
            "[163/400]: loss_train: 8.051 loss_val 10.536 loss_ts 41.203\n",
            "best val epoch: 168\n",
            "[168/400]: loss_train: 7.600 loss_val 10.139 loss_ts 40.768\n",
            "best val epoch: 169\n",
            "[169/400]: loss_train: 7.635 loss_val 9.964 loss_ts 45.908\n",
            "best val epoch: 210\n",
            "[210/400]: loss_train: 6.905 loss_val 9.696 loss_ts 41.133\n",
            "best val epoch: 211\n",
            "[211/400]: loss_train: 6.823 loss_val 9.548 loss_ts 44.274\n",
            "best val epoch: 212\n",
            "[212/400]: loss_train: 7.032 loss_val 9.500 loss_ts 46.533\n",
            "best val epoch: 251\n",
            "[251/400]: loss_train: 7.418 loss_val 9.184 loss_ts 39.662\n",
            "best val epoch: 252\n",
            "[252/400]: loss_train: 6.840 loss_val 8.847 loss_ts 43.630\n",
            "best val epoch: 255\n",
            "[255/400]: loss_train: 6.172 loss_val 8.749 loss_ts 44.819\n",
            "best val epoch: 256\n",
            "[256/400]: loss_train: 6.024 loss_val 8.526 loss_ts 42.232\n",
            "best val epoch: 282\n",
            "[282/400]: loss_train: 5.314 loss_val 8.231 loss_ts 37.726\n",
            "best val epoch: 283\n",
            "[283/400]: loss_train: 5.354 loss_val 8.225 loss_ts 41.582\n",
            "best val epoch: 287\n",
            "[287/400]: loss_train: 5.804 loss_val 7.832 loss_ts 41.545\n",
            "best val epoch: 288\n",
            "[288/400]: loss_train: 5.563 loss_val 7.731 loss_ts 37.524\n",
            "best val epoch: 289\n",
            "[289/400]: loss_train: 5.335 loss_val 7.684 loss_ts 36.821\n",
            "best val epoch: 325\n",
            "[325/400]: loss_train: 4.640 loss_val 7.559 loss_ts 37.957\n",
            "best val epoch: 326\n",
            "[326/400]: loss_train: 4.528 loss_val 7.424 loss_ts 34.929\n",
            "best val epoch: 332\n",
            "[332/400]: loss_train: 4.670 loss_val 7.358 loss_ts 35.127\n",
            "best val epoch: 333\n",
            "[333/400]: loss_train: 4.503 loss_val 7.284 loss_ts 36.525\n",
            "best val epoch: 334\n",
            "[334/400]: loss_train: 4.481 loss_val 7.272 loss_ts 37.764\n",
            "Final: 37.76396179199219\n",
            "{'val_sub': 4, 'ts_sub': 0, 'batch_size': 64, 'weight_decay': 0.0001, 'lr': 0.001, 'ts_per_sample': 30, 'nattrs': 6, 'bvp_count': 12, 'dropout_rate': 0, 'lstm_input': 128, 'lstm_size': 32, 'ts_h_size': 32} 37.76396\n",
            "subject: 0\n",
            "TS:35.590824127197266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3yV1f3H3+dmLxLIArIISdgQRth7iYiKigO17lntUPtrq7W1tdbW1jpqW7UOlDpwFdyogLL3HiEbskkCmUD2Pb8/TgKBrJt7n5t7k5z368XrJs89z3NOyM33Oc93fL5CSolGo9Foui8mRy9Ao9FoNPZFG3qNRqPp5mhDr9FoNN0cbeg1Go2mm6MNvUaj0XRzXB29AICgoCA5YMAARy9Do9FouhR79uw5KaUMbm+cUxj6AQMGsHv3bkcvQ6PRaLoUQohMS8Zp141Go9F0c9o19EKIZUKIQiHE4SbHnhJCHBRC7BdCfCeE6N9wXAghXhJCpDW8P9aei9doNBpN+1iyo38buPSiY89KKUdJKUcDXwJPNBxfCMQ1/LsXeMWgdWo0Go3GSto19FLKjUDxRcfKm3zrAzTqKCwG/isV24EAIUQ/oxar0Wg0mo5jdTBWCPE0cCtQBsxuOBwGZDcZltNwLL+F8+9F7fqJjIy0dhkajUajaQerg7FSysellBHAe8BPrDj/NSllgpQyITi43ewgjUaj0ViJEVk37wFLGr7OBSKavBfecEyj0Wg0DsIqQy+EiGvy7WIgqeHrz4FbG7JvJgFlUspmbhuNxp6YzZKVe3MoPlPj6KVoNE5Buz56IcQKYBYQJITIAX4PXCaEGAyYgUzg/obhXwOXAWnAWeAOO6xZo2kVKSWPf3qYFTuzWDo+gmeWjHL0kjQah9OuoZdS3tjC4TdbGSuBB21dlEZjDVJKnvwikRU7s+jby5PPD+Tx+KKh+Hm6OXppGo1D0ZWxmm7Dsi3HeXvrce6eFs2rt4zjbE09n+7Pc/SyNBqHow29pltwKKeMZ1YfZf6wUB5fNJT4cH+G9evF+zuy0O0yNT0dbeg1XZ7T1XX8dMVegnw9+NuSUQghEEJw08RIjuaXsz+71NFL1Ggcijb0mi7P379NJqv4LP9YOobePu7nji8e3R9vdxc+2p3dxtkaTfdHG3pNlya7+Czv7chk6YRIJkT3ueA9P083psUGsTX9lINWp9E4B9rQa7o0L6xJwSQEP5sT1+L7CQN6k3nqLIUVVZ28Mo3GedCGXtNlST5Rwar9udw+ZQB9/T1bHDMuSu3y9xwv6cylaTROhTb0mi7L379LxtfdlftnxrQ6ZkRYL9xdTezO1IZe03PRhl7TJdmTWcKaxALumznwggDsxXi4uhAf7q8NvaZHow29psshpeTZb5MI8nXnjqnR7Y5PGNCHI7llVNbUd8LqNBrnQxt6TZdjU+pJtmcU85PZsfh4tN9SISGqN3VmyYEcnU+v6ZlY3XhEo+lMpJTszSphX1Yp7+/IIizAixsnWtawZlxUb0C5eyYNDLTnMjUap0Qbek2XYMexYpa+th2Avr08+cuSkXi4ulh0boC3O7Ehvuw+Xtz+YI2mG6INvaZLsCm1CBeTYOOvZhMW4NXh88cP6MPn+3Mpq6zF30urWWp6FtpHr+kSbE0/RXy4v1VGHuBHkyI5U1PPss3HDF6ZRuP8aEOvsZjKmnqyTp3t9HlPV9dxMKeMyTHW+9eH9/dnwfBQlm05RlllrYGr02icH23oNRbz+88PM+PZH7jkhQ38+4c06s2dI/+763gx9WbJ5IFBNl3nZ3PjqKiq07t6TY9DG3qNRZSdreWz/XlMiO6Dl7srz36bTGJeeafMvS39FO4upnPZM9Zyble/+RgpBRUGrU6jcX60oddYxKp9OVTXmXni8mE8c81IAI6fOtMpc29LP8XoyAC83C3LsmmLXy4YgoebC4v/tYWVe3MMWJ1G4/y0a+iFEMuEEIVCiMNNjj0rhEgSQhwUQqwSQgQ0ee8xIUSaECJZCLHAXgvXdB5SSlbszCY+3J8RYf5E9vEGIKvY/v76srO1HMkrY7JB+e+xIb58/bNpjAz355GPDvDi2hRDrqvRODOW7OjfBi696NgaYISUchSQAjwGIIQYBiwFhjec87IQwvZtmMah7M0qIbmgghsnqAIlHw9Xgnw9OiUwu+PYKcwSptgQiL2YkF6evH/3RK4dF86La1N5fWOGYdfWaJyRdg29lHIjUHzRse+klHUN324Hwhu+Xgx8IKWsllIeA9KACQauV+MA3t+Rja+HK1fE9z93LCrQm8xi+7tudhwrxsPVxOjIgPYHdwBXFxN/XTKKRaP68fTXR1m1T7txNN0XI3z0dwKrG74OA5r2bctpOKbpotTUmfn2yAkWjex3ga5MVB/vTtnR7zpezOiIAIurYDuCi0nwwvWjGdqvF8u3Zhp+fY3GWbDJ0AshHgfqgPesOPdeIcRuIcTuoqIiW5ahsSM7jp3idHUdlwwPveB4ZKA3+eVVVNfZTxHyTHUdR/LKGT+gT/uDrcTd1cT8YaEczCml7KzOr9d0T6w29EKI24HLgZullI0J1blARJNh4Q3HmiGlfE1KmSClTAgODrZ2GRo7syaxAC83F6bGXpjDHhXojZSQXVxpt7n3ZZVSb5aMj7afoQeYFhuEWcK2DN1bVtM9scrQCyEuBX4FXCmlbPr8/jmwVAjhIYSIBuKAnbYvU+MIpJSsTSxgelwQnm4Xuk4i+/gAkGVHP/3O48WYBIw12D9/MWMiA/Bxd2Fzmn6y1HRPLEmvXAFsAwYLIXKEEHcB/wL8gDVCiP1CiFcBpJRHgI+AROAb4EEppe720EU5kldOXlkV84aFNnsvKlClWGba0U+/61gxQ/v1ws/TviJkbi4mJg4MZEua3tFruiftqldKKW9s4fCbbYx/GnjalkVpnIO1RwsQAuYMCWn2XqCPOz7uLnYz9LX1ZvZll7B0vGWa87YyLTaI75MKySk5S3hv706ZU6PpLHRlrKZV1h4tYFxkb4J8PZq9J4Qgoo+33YqmDueWUVVrtmsgtinT4lQMYnPqyU6ZT6PpTLSh17RIXmklh3PLW3TbNBIV6E2mnWQQdjU0CRkfbZu+jaXEhfgS2suDzWna0Gu6H9rQa1pk3dECAOYNbcvQ+5BdUonZDiqWu4+XEBXoTYifp+HXbgkhBDPiglmfXKTTLDXdDm3oNS2y5mgh0UE+xAT7tDomso83NXVmTpRXGT7/kbxy4sPtm21zMXdOi+Z0dR3LtmgZY033Qht6TTMqqmrZln6S+cNCEUK0Os5emTclZ2rILa1kWP9ehl63PYb263WuOUl5ld7Va7oP2tBrmrEx5SS19bJNtw1AlJ1y6Y/mK5374Z1s6AF+Okc1J1m+5Xinz90RztcoajTtow29phlrEk/Q29ut3UKlsN5euLuYyCgy1tAnNhj6of0639CPCPNn3tAQ3th8jEI7uKRs5UheGY98tJ/Bv/2Grw/lO3o5mi6CNvSaC6itN/N9UiFzhoTi6tL2x8PFJIgO8iGt8LShaziSV05oL48W0zo7g18uGEJtvZk73t7F6eq6C96rN0uqah1TA/jZ/lwWvbSZbw6fwMfDhTc2aXlljWVoQ6+5gD2ZJZRX1TFvaPMiqZaIDfElvchYQ5+YV87w/v6GXrMjDO7rx79vHkvSiQoeeG/vOeG2wvIqFr20iete3dbprpNTp6v5w+dHGBsZwLZH5/LArFj2ZpWSfEK3RNS0jzb0mgvYnHoSF5M4V0DUHjHBPmQVnzVMxbKqtp60otMMc4DbpimzB4fw9FUj2JhSxLznN/DO9kyufXUbSScqOJRbxr7s0k5dz9NfHeV0dR3PLBmFv7cbS8aF4+5iYsXOrE5dh6Zrog295gI2p50kPtzfYn2ZmBBfzBKOnzQm8yaloIJ6s+z0jJuWWDohkrfvGI+vhxu/+/Qw5VW1vHf3RDzdTHy8u/MalWxJO8nKfbncPzOGQaF+APTxcWfBiL6s2pfrMFeSpuugDb3mHGWVtRzMKWVarGW7eYCYYF8Aw9w3iXmOy7hpiVmDQ/jqp9N4/dYEPntwKlNjg7hsRD++PJBHZU3nGNiX1qUSFuDFg7NjLzh+4/gIyiprWX1YB2U1baMNveYc2zNUf9aLtefbYmBDQZVRAdnE/HJ8PVyJcCJhMZNJMH9YKFGB6me9NiGciuo6vj1ywu5zpxedZsexYn40KaqZVPSkgYFEB/nw1pbjOt1S0yba0GvOsTXtJF5uLoyJtFxfxtvdlbAAL0N39EP7+WEytV6o5WgmRQcS3tuLj/dktz+4CeVVtVz36lZWdyAt8oOdWbiaBNeOC2/2nskkuHfGQA7mlGmNHk2baEOvOcfmtJNMiO6Du2vHPhYxBmXe1JslR/PLHR6IbQ+TSXDduAi2pJ1iW7rlGvZPf3mUXcdLeHeHZf1pq+vq+WRPDpcMDyXYr+VU02vGhhHay4OXf0i3eB2anoc29BoATpRVkV50pkP++UZig31JLzxjs7jZsZOnOVNTz4gwx6VWWsrd06OJDvLh4Q/3U3Kmpt3x65ML+XB3NkG+HmzPKLZIOO3bIwWUnK3lxgmta/J7uLpwz/SBbMs4xZ7Mkg79DJqegzb0GkBldkDH/PONxIT4UFlbT76NlaSHcssAGNXJYmbW4OPhyj9vHMOpM9X88pODbfrIUwsqePR/h4gL8eXlm8dSb5asSypod44Pd2UR0ceLqTFt/05unBBJb283/v1DWod/Dk3PQBt6DQAbUooI8nVnSF+/Dp/bmHlja0D2YE4ZXm4ubSpmOhMjwvx5dOFQ1h4t4KsW/O4nT1fz0Af7uOTFjZyuruO56+NJiOpN316efHekbUN/prqOHRnFXDayX7vxCh8PV+6ZMZDvkwrZqn31mhbQhr4HUFFVyw9JheSVVra486yrN7MhpYiZg0KsCoLGhjSkWDYY+sLyKlbuzeHfP6RRU2e2+DqHcsoY3r9Xu9ILzsQdUwYwMMiHVzekN/u/ffKLRL4+fIJ7Zwxk469mMyo84FwGz4aUojbz33ceK6bOLJkeG2zROu6cGk14by+e/CKRunrL/89tod4syS4+S1FFtc7ld3La7Rmr6fr8/dtklm9TAcBgPw+mxgQyc3Awi0b2x93VxL7sUsoqa1vsDWsJgT7u+Hu58ddvknh+TcoF+jCF5VU8uXhEu9eoqzdzJK+cpRMirFqDo2jMfHl05SG2pp865/pKLzrNlwfzuG9GDI8uHHLBOQuG9+Wd7ZlsSlVS0C2xOe0k7q4mEgZYlgHl6ebCbxcN5f539/L+ziwmDwwkMb+cBcP7NkvLNIqnvkzk7a3HAejl6cpH909mSF/nDqT3VNrdOgkhlgkhCoUQh5scu04IcUQIYRZCJFw0/jEhRJoQIlkIscAei9ZYztmaOlbuzWXOkBD+uHg4U2IC2ZR6koc/PMCTXxwB4PukQlxNgumDOu6fB9Wd6YnLh3FdQjjXJ0Tw2MIhfPnTadw1LZrl2zL53572q0jTi85QWVvPqHDnD8RezFVjwgj28+DVDeczX15Zn46Hq4m7p0c3Gz9xYB96ebq2Wei0Je0k4wf07pCRXjC8L5MHBvLEZ0eY/8JGfv7Bft7cbJ8mKhlFp3lneyYLhofyx8XDkRL+9b2OETgrluzo3wb+Bfy3ybHDwDXAf5oOFEIMA5YCw4H+wFohxCAppX6ucxBfHsynorqO+2fGMCG6D7dOHoDZLHn808N8uCub+2bE8P3RQsYP6EMvC2UPWmLJuHCWXJTrPaSvH0fyyvjNqkPER/gTG9K6/78xEDuyC2TcXIynmwt3To3mr98ksTGliAGBPqzal8utk6NaVOB0czFxeXx//rcnh8cvG0rgRWMKK6pIOlHBry4d3KF1CCH4yzUjeX1TBqPC/flodw4rdmZx/8wYXAyuS3juuxQ8XE08ddUIQvw8yS+r4tUN6TxSdJqBDTEbjfPQ7o5eSrkRKL7o2FEpZXILwxcDH0gpq6WUx4A0YIIhK9VYxfs7sogN8WV8ExeAySR4aF4cLibBb1YdIrmgwmq3TVu4upj4541jkRI+2Nl2cdGhnFJ83F2IDuqaRuKmiSrz5dZlO5n93HpchHLptMadU6OprjPzzvbmOfWNufnWpLoOCPLh6atHcsP4SO6YOoCckko2phZ1+DptsT+7lK8O5XP39IHnevreOTUadxcT/9mgpZOdEaOjXmFA07/onIZjzRBC3CuE2C2E2F1UZOwHUaNIzCtnf3YpN06IbNYSMLSXJ7dOjjpXUTnbDoYeVExgelwQqw+faDMF8WBuGcPD/A3feXYW/l5ufPvwDJ6/Pp7rEyJ44oph9PP3anV8bIgv84aG8N9tmc0CmZtTT+Lv5WazVPMlw/oS5OvO+zuMVbh87rtkAn3cL7iRBft5sHR8BCv35ZBXWmnofBrbcVh6g5TyNSllgpQyITjYsswCTcf4cFcW7q4mloxt8V7L/TNj8HF3ISrQ264pjQtH9iO3tJKDOWUtvl9bbyYxr5xRXdBt05QQP0+uGRvOX64ZyY8mRbU7/p7pAyk+U8P/9p6PYdTUmdmcdpIpMYE23/TcXU1clxDBuqMF5JcZY3yP5pezKfUkd08fiK/HhZ7fe2YMpM4s+cSCmIymczHa0OcCTdMmwhuOaRzAptSTzIgLIsDbvcX3A309eOnGMfzpqhFtNgG3lflDQ3E1Cb5uJfh4MKeU6jozI7tgINYWJkT3IT7cn5fWpfLR7mwO5ZRxzStbyC+r4rKR/QyZ48bxkUjgw10d0+VpjWWbj+Hl5sJNLVTrhvf2Zli/XmxN7165/Eknyrnm5S28sj7doipoZ8RoQ/85sFQI4SGEiAbigJ0Gz6GxgLKztWScPNOuQNncoaFMj7PvE5W/txtTY4NYfahl981bW47j5+FqlziBMyOE4A9XDqeXpxu/+uQgV/xrM3mlVfznlnFcEd/fkDkiA72ZPDCQVftyrVK4rK6r59N9uVRU1VJUUc1n+/O4dlw4/t4tB+6nxASyN7O0W+XVf7ovj71Zpfz1myQm/WUdv/z4AIdzW346dVYsSa9cAWwDBgshcoQQdwkhrhZC5ACTga+EEN8CSCmPAB8BicA3wIM648Yx7M9RHZBGRziHnMCikf3IKj7LkQa9+Uayi8/y9aF8bpoYaXGzk+7EmMjefPfwDD68dxK/unQw3zw0nQXD+xo6x1Wjw8g8dZb9VnTFevabZB76cD+XvriJP3x+hJp6M7dPHdDq+CmxQdTUm7uV7s62jFMkRPXm24dmcO24cL48mM/l/9zM82tSHL00i7Ek6+ZGKWU/KaWblDJcSvmmlHJVw9ceUspQKeWCJuOfllLGSCkHSylX23f5mtbYn1WKEDhNXvr8YaG4mESz1ndvbj6GSYg2jUd3RwjBxIGBPDAr9lwWi5FcOrIv7q4mPtuf1+7Yqtr6c9XM29JP8eaWYywYHoqHq4mvDuUzZ0jIOcmLlhg/oA+uJnFOO6mrU15Vy6GcUibHBDK4rx9PXz2S7b+Zy/xhobyxKYOyyvbF6ZwBXRnbTdmfXUJssK/T7JJ7+7jzo4mRLN+WybTYIBaO7Efp2Ro+3JXNlaP7t5mhorGNXp5uzB0SwpcH8/jtoqEtSkz89Zsk1h0tIL3oDD7uLiwZF853RwqI6uPNCzeMRiB4b0dmq5W8jfh6uBIfEcDWDsg3OzO7jhVjljA5JvDcMX8vNx6aF8eaxAI+3JXFvTNiHLhCy+g6oiIai5FSsj+71GncNo38ZtFQRkcE8H8fH+DNzce4+uWtVNbWc8/01vPNNcaweHQYJ0/XtNigJLe0klfWp+Pl7sqPZ8Ywc3AI727PJL+skueuj8fb3RUvdxfunj7wXJettpgSE8jBnFLKq7rGbrcttqWfwt3VxNiLYl3D+/szaWAflm/N7DRtIVvQhr4bklV8lpKztR3qFNUZeLi68PLNY/Fwc+GpLxPxcDWx7PYEhjp5o5HuwOwhwfTydG3RfbMxRdWx/P3aUfzfgsH888YxbHtsLl/9bDrjovp0eK4pMUGYpdoNd3W2ZZxibGRAi1IUd06NJre0km86oaWkrWhD3w1pDLo5244eoH+AFyvumcRbt4/n659NZ86Qtl0BGmPwcHVh0aj+rD6c38yvvDGliH7+nudUSAGCfD2svgGPiQzAw9XElrSu7b4pPVtDYn45U1rpBzB3aChRgd4ss5OekJFoQ98N2ZdVipebC4NCnVNOYHBfP2YPsU4SWWM9N02IpKrWzGf7z5e21NWrAq2Zg4INq6XwdHMhPiKAvVldO/Nme0Yx8iL/fFNcTILbpwxgb1Yp+5z8Z9WGvhuyP7uUkeH+XUrXXWN/Rob7MzLMn/d3ZJ3Lqd+fXUpFVR0zBhlbSzEyzJ+j+eVdwn/dGpvTivBycyG+jY5n1yVE4OfhajeVUKPQlqCbUW+WJOaXE+8kaZUa5+KmiZEknahgb5Zy721IKcLFJKxqIdkWI8P8qa4zk2ZA03hHUFNn5quD+cwdGoK7a+tm0tfDlaUTIlh9+IRTa/xoQ9/NyC4+S02dmbjQjrcE1HR/rozvj6+H6zmhs40pRYyOCMDfy9g03MYG74da0TdydjakFFFytpZrWtGJasqtkwcgpeT1TRm8tyOTG1/bTkpBRSes0nJ0Hn03o7Fva9PAmkbTiI+HK4tH9+f9nVnsyyrh2KkzPDR3kOHzRAf54O3uwpG8cq4z/Or2Z9W+HAJ93C2SB4no482lI/ry1pbj544t33qcp68eaccVdgxt6LsZ6Q2Pym1VL2p6Nr+6dAiBvh6kFlQQ4O3G4tHG6Oo0xcUkGN6/17mGMl2Jsspa1h4t5KYJkbhZGOd6ZP5gfNxduWZsOO/vzOKrQ/n8/orhbbp9OhNt6LsZaYWnCfbzMPxRXNN98Pdy45H5xu/iL2ZEmD8f7Mym3iw7pc/AD0mFJJ2oYERYL+IjAqzumPb1oXxq6swWuW0aiQ3x5dnr4gHVvvOLA3lsSi1i7lDnSB/Whr6bkVZ0mli9m9c4ASP6+1NZe5yMotN2jRmZzZK/f5fMy+vP9+wN7eXB97+YhY9Hx03cqn25xAT7WN3WcsagYHp7u/HZ/jynMfTO8VyhMQQpJWmFp4kJsV8TEY3GUhr7C9jTfZN16ix3vL2Ll9enc+OESHb/dh5/WzKKgvJq1iQWdPh6heVV7DpezJXxYVbXFbi5mLhsZD/WJBZwprrOqmsYjTb03Yii09VUVNXpHb3GKYgJ9sXTzWQXQ19Xb+aZ1UnMe34DO48V89RVI/jz1SMI8vXg2nHh9Pf3vKAwzFJUy0tYNMo2qejFo8OorK236mZjD7ShtyNSSr44kEfSifMa7HX1Zqrr7CPRfz7jRqdWahyPi0kwrF8vjuSWtz+4gyzbcoxXN6RzRXx/1v9yFrdMijq3AzeZBFeODmNj6klOna7u0HW/OpjPoFBfm/+GEqJ6ExXozX82ZlBv7njDF6PRht6OrE8u4qcr9nHpi5u4/509PLbyIBP+vI55z2/AbIdffnqDodeuG42zMCo8gEO5ZYZubvLLKnlxbSrzhobw3PXxhPZqruF/1Zj+1JslXx9quX1lSxSWV7Ers5hFI23PQjKZBL+4ZDBH88tZudfxPXS1obcTtfVmnvoqkYFBPvxsTixb0k7y2f48Ivp4k11cSWK+8buc9KIz+Hq40reFD75G4wimxQZRWVtvaMepp786Sr1Z8vsrhrc6ZkjfXgwO9eNTC5qtNGKU26aRK0b1Y3REAH//LpnKGsc22tOG3kAqqmpJK6xASsm72zPJKDrD44uG8sglg9n123ns/d18Xr91HAAbU4sMnz+t8DQxwT52bfSt0XSESTGBuJoEm1KN6Ti1PeMUXx7M54FZsUT08W5z7OIx/dmTWcJL61LJsECK4atDxrhtGhFC8PiioRSUV/P6pgxDrmkt2tAbQE7JWX736WEm/nkd857fyNRnvuf571KYFht0ruG1p5sLnm4uhPh5MrRfr3Ma4EaiDL0OxGqcB18PV8ZG9WaTQRubrw7m4+3uwn0z229Wc0NCBBOj+/D8mhTmPLeB3392uFWXaV5pJbuOF3PZyH6GrLOR8QP6MG9oCG9vPe5QgTdt6JsgpWTX8eIO/0IefH8fH+7OZuGIfjx99QiGh/nTy8uN310+rMXd9Yy4IPZklhiaenW6uo4T5VXEaOkDjZMxIy6Iw7nlHQ6MtsSu48WMi+rdYiOQiwn09eDD+yaz7bE53Do5iuXbMvnNqkMtBkc/aOhlvGRsuM1rvJjrEiIoPlPj0PaK7Rp6IcQyIUShEOJwk2N9hBBrhBCpDa+9G44LIcRLQog0IcRBIcRYey7eaD7anc11r27j1Q3p7Q9uoKiimgPZpfx8bhzPXR/PzROjeP3WBLY8OofBfVt+BJwxKJjaesn2DON+8Wsb0riGtDKnRuMoGvViWmpj2BHKKmtJLqggoYNdr/r5e/HklcP56ZxYPtiVzZ++Srzg/dp6Mx/symbWoOB23UHWMHNQMH4ernx5sHm8oFEu2t5YsqN/G7j0omOPAuuklHHAuobvARYCcQ3/7gVeMWaZ9qe8qpZnv00G4D8bMig5U2PReZvT1CPpDAvEjxpJGNAbTzeTYX7L4jM1PPVlIvHh/sw0WFdco7GVEWH+BHi7sTHFts/7nkzVCGR8dMdbZAqhsmBumhjJf7dlcvzkmXPvrTtaQGFFNTdPjLJpfa3h6ebC/OGhfHP4BDV1570FFVW13L18N6s7kBlkLe0aeinlRuDi5o+LgeUNXy8Hrmpy/L9SsR0IEEIY6/SyEy+tTeXUmRqeuy6e0zV1vGLhrn5jykn6+LgzvL/lbdc8XF2YNDDQMD/9U18mUlZZy1+vHaWbjWicjka9+02pRTbtYHceK8HNRTAmwvpeyA/Ni8PNRfCPdannjr23I4v+/p7Mboin2YMrRvWnvKruXKwi69RZlryylfUpRc1aO9oDa61CqJSy8TZ0AmgUdAgDspuMy2k41gwhxL1CiN1CiN1FRcYHJjtCetFp3t56nOvHRbBkXDjXjAnn7a3H220kYDZLNqWeZFpsUIfb4s2IC065WYcAACAASURBVCbj5BlybWxW8H1SAav25fLArBiG9NVNtjXOycxBwRRWWCdL0Mju48WMCPPHy719/3xrhPh5ctvkAXy6P5e0wgrWJhawKfUkSydE2lV4bWpsEAHebqzYmc0/16Vy5b83U1BezTt3TmDphEi7zduIzds/qW7RHb5NSylfk1ImSCkTgoMd6274bF8uZin5vwWDAXh4fhxSSpZvO97meUdPlHPydLVVbdhGR6r2ZIl51ufT55VW8ouPDjCkrx8Pzom1+joajb1ZPLo/Q/v14rGVhyiq6HhQtqq2noM5ZYwf0DH/fEvcNzMGbzcXlryyjbv/u5sBgd7caGdj6+5qYuGIvqw9WsBza1IYGebPpw9OZYrBnb1aw1pDX9Dokml4LWw4ngtENBkX3nDMqdmXXcqgUD+C/TwACO/tzcgwf/a2U+TR6HOcEdfxX1ZcQ3aMtZ1oauvN/HTFPmrqzLx881g8XK3f5Wg09sbD1YV/LB1NRXUdv/7fwQ67cA5kl1JTbzbE0Pfxcecnc+LwdDPxhyuG8d3DM8/97duTB2bF8vC8Qaz7xUzeuWsi0UGdV8FuraH/HLit4evbgM+aHL+1IftmElDWxMXjlJjNkgPZpYyJvLABcHyEKt1uK9VyY0oRQ/r6EWJFJaqfpxthAV4kn+i4oa+uq+fxVYfYk1nCX5aMYqDOndd0AQaF+vHYwiF8n1TIx3s6Jguwu2HTlRBlvX++KT+eFcOO38zj9qnRndYcJKKPNz+fF+eQWhdL0itXANuAwUKIHCHEXcAzwHwhRCowr+F7gK+BDCANeB14wC6rNpBjp85QXlXH6IgLDf3oiACqas0kt7LjrqypZ3dmMdOt2M03MrivX4d39JmnznDtK9v4aHcOP5kdy5XxxncH0mjsxW2TBzAuqjd/+yaJiirLg5B7MkuIDfGlt4+7HVfXfWlXlV9KeWMrb81tYawEHrR1UZ3J/qxSAEZfFMlvNPwHsssY3r95A4K9WSXU1kubfGxxob5sTj1Jbb253ZZlp6vr+M+GdF7flIG7i4n/3DKOBcON0eTQaDoLk0nwxOXDWPzvLfzrhzQeWzjUovMS88qZHBNo59V1X3p8Lt7+7FJ83F2aNdOO7ONNb2839me37KffnnEKF5Ow6VFycKgfNfVmMk+daXNcyZka5j+/gX9+n8a8oaGsfmiGNvKaLkt8RADXjgtn2eZjHDvZ9mcfVJ3IifIqhvXTWWXWog19dimjwgOapVYJIYiPCOBAdstNE7ZnnGJEmD9+VvalBOWzBEg+0bbg0vdJheSXVbHs9gT+ddNYwgK8rJ5To3EGfrVgMO4uJv72TVK7Y482KL0O1Ybeanq0oa+qredofvm5VMeLiQ8PIKWwgtMXadJU1tSzP7uUSQNtywCIDfHFJGg1DtDID8mFBPt5MGuQ/Qo6NJrOJKSXJ3dNi2b14RPtphg3vj+0n5b3sJYebeiP5JVRZ5bNArGNjI4MQEo4lHPhrr7RPz9poG0+Q083F6ICfUhpI/Omrt7MptSTzBoU3OGiLI3Gmblr2kD8PFz5x7qUNscl5pfTt5cngb72T4HsrvRoQ7+vIRA7phVDHx+uju/LLmFHxik+3ZeLlNIQ/3wjg0J9SSls3dDvzy6lrLKWWYP1bl7TvfD3duOOadF8e6SAI3mt95U9ml/OsA5IjGia027WTXdFSsn3SYWEBXi1mgffx8edyD7e/P3bZBqVTQ/llnEwp9Rm/3wjg0P9WJNYQFVtfYvSqz8kF+JiEkyzIY1To3FW7poWzVtbjvHSulT+c0tCs/erautJKzzN3KF6o2MLPXZH/8XBfLamn+KuadFtjrt1chSzBofwwg3x3D5lAG9uPsau4yU2++cbGdTXD7NUejstsT65iHFRvfH3sv2motE4G/5ebtwyKYo1iQUUllc1ez+t8DR1Zsmwfs1TnDWW0yMNfenZGv74xRHiw/25bcqANsfePX0gy24fz9Vjwvn9FcO4vWH8zA7IErfF4IbMmyO5zQNSheVVHMkrZ9ZgLT2s6b4sGReOWcLnB5rrtTcGYrXrxjZ6pKF/ZnUSJWdr+fM1IzukWCeE4PdXDGPjL2cbJkY0MNiXyD7efLg7u9l7a48qCSGdbaPpzsQE+xIf7s/Kvc1lsRLzy/F2dyHKDg1BehI9ztBX19Wzcm8uN4yPaLHitT2EEEQGGvehczEJbp8ygD2ZJezPLr3gvY/3ZBMX4qvTyjTdnqvHhJGYX36B9pOUkiN5ZQzp66czzmykxxn6w7nl1NSbrVKctBfXj4/Az8OVZZuPnTuWWlDBvqxSbhgf0WLfWY2mO3FFfH9cTYKV+3IoPlPDm5uPseDFjew6XmKIYmVPp8dl3TRKD4+NNEYFzwh8PVy5fnwEy7ce57HLhtDP34uP9+TgahJcNabFvi0aTbci0NeDmYOCeWdbJm9tPk5NvZn4iAD+cs1IrtZ/AzbT4wz9nswSIvq0nlLpKG6fMoC3thzjT18d5c9Xj2Tl3hzmDg0hSBeJaHoId0yNJrmggvnDQrlhfITumGYgPcrQSynZk1XCVCdUwYvo483P5sbx4tpUtqadpORsLTeMj2j/RI2mmzAtLojNv57j6GV0S3qUjz6npJKiimrGGdS8wGgemjeI9++ZiLe7K+G9vZhhUAqnRqPp2fSoHf3erAb/vJMaeoApMUGs+8VMquvMuLajUa/RaDSW0KMM/Z7MEnzcXc4VKTkrnm4uLcohaDQajTX0qC3jnswSRkcG6J2yRqPpUfQYi3emuo6kExWMc6K0So1Go+kMbDL0QoifCyEOCyGOCCEeajjWRwixRgiR2vDqFJb1UG4Z9WbJGG3oNRpND8NqQy+EGAHcA0wA4oHLhRCxwKPAOillHLCu4XuH0ygvEN+K9rxGo9F0V2zZ0Q8Fdkgpz0op64ANwDXAYmB5w5jlwFW2LdEYDmSXEtnHmz4+7o5eikaj0XQqthj6w8B0IUSgEMIbuAyIAEKllPkNY04AoS2dLIS4VwixWwixu6ioyIZlWMaB7FK9m9doND0Sqw29lPIo8FfgO+AbYD9Qf9EYCchWzn9NSpkgpUwIDrZvYVBheRV5ZVWt9obVaDSa7oxNwVgp5ZtSynFSyhlACZACFAgh+gE0vBbavkzbaPTPj47QXWo0Gk3Pw9asm5CG10iUf/594HPgtoYhtwGf2TKHERzIKcXVJKzSn9doNJqujq2Vsf8TQgQCtcCDUspSIcQzwEdCiLuATOB6WxdpK/uzSxnSz09Xm2o0mh6JTYZeSjm9hWOngLm2XNdIzGbJwewyrhzd39FL0Wg0GofQ7StjM06eoaK6TmfcaDSaHku3N/TbMk4B6IwbjUbTY+nWhl5KyTvbjjO0Xy/iQnwdvRyNRqNxCN3a0G9NP0VKwWnunDpAN9jWaDQ9lm5t6JdtPkagjztXxOtArEaj6bl0W0N//OQZvk8u5OZJUTqtUqPR9Gi6raF/c/MxXE2CH02KdPRSNBqNxqF0S0OfXXyWD3Zlce24CEL8PB29HI1Go3Eo3dLQv7A2BZMQ/HxunKOXotFoNA6n2xn65BMVrNqXy+1TBtDXX+/mNRqNptsZ+ufXJOPr7sr9M2McvRSNRqNxCrqVoS85U8Pao4XcNCmS3rqTlEaj0QDdzNCvSSyg3iy5fKTOm9doNJpGbJUpdipWH84nvLcXI8J6OXopGk3nkn8Q9r8PVWXg5gWX/gVcPRy9Ko2T0G0MfXlVLZvTTnLbZC13oOlhVJXB+9dDZQl49YGKPAgbC2N+5OiVaZyEbuO6+SGpkNp6yaUj+jp6KRpN57LuKThdAHd8DY8kQugI2PpPMJsdvTKNk9BtDP3qQycI8fNgbGRvRy9Fo+k8snfCrjdgwn0QNg6EgKk/h6IkSP3O0avTOAndwtBX1dazPqWQBcP7YjJpt42mh2A2w1ePQK/+MOfx88eHXw29wmHrS45bW09h15vwv7vhwIfKdeakdAtDn1V8lqpaMwkD9G5e04NIWQ0nDsHc34OH3/njLm4w+UHI3AK5ex23vu6MlLDmCXWjTf4GVt0LL4xQQXEnpFsY+tzSSgDCArwcvBKNppOQEjY+C70HwIglzd8ffRMgIG1tZ6+sZ/DNo7DlH5BwF/z6ONy1Fjx6wUe3QGWpo1fXDJsMvRDiYSHEESHEYSHECiGEpxAiWgixQwiRJoT4UAhh98ql/NIqAPppQ+94Co/CN4/Bmwvg1WlQcMTRK+qepH8Peftg2sPg0kLynFcABA9RPnyNsWRthx2vwoR7YdFz6v8/Yjxc9zaU5cCnD6gbsRNhtaEXQoQBPwMSpJQjABdgKfBX4AUpZSxQAtxlxELbIr+sEpOAUD+dN+xQCpPgrYWwexlIM5wuguVXKuOvMZZNz0GvMIi/sfUxEeMhZ5fOvjESs1ltZPz6wbw/qOB3I5ETYf5TkPwV7HvXUStsEVtdN66AlxDCFfAG8oE5wCcN7y8HrrJxjnbJK60ixM8TV5du4YnqmpRmwTtXg4s7PLAd7l4Dt38FJldYfgWUHHf0CrsPyd8o//vUn7ddFBUxEapK4VRq562tu3PoY8jbq+Ii7j7N35/0YwhLgPV/gdqqzl9fK1htGaWUucDfgSyUgS8D9gClUsq6hmE5QFhL5wsh7hVC7BZC7C4qKrJ2GYDa0fcP0EqVDqOuGt67HmrOwI9WQp9odTwoFm77AqrKYfOL9pv/xCHYvwLqa+03h7NQcwa+/iUED4WEO9seGz5BvWr3jTHUVsK6J6H/GBh1Q8tjhIC5T0B5Lux+s3PX1wa2uG56A4uBaKA/4ANcaun5UsrXpJQJUsqE4OBga5cBQH5ZlfbPO5KNz0LRUVjyBvQdceF7wYNg1PVw4AM4W2zsvFXlsPpR+M8M+PR+9Xp8i7FzOBsb/gplWXD58yq7pi0CY8EzAHK0oTeEAyuUAZ/3JJjaMJ0DZ8LAWbDx7+oz6gTY4uuYBxyTUhZJKWuBlcBUIKDBlQMQDuTauMY2kVKSV1pJf6097xhOHIbNL8CopTDokpbHTPox1FXC3v8aN6+U8P4NKig27g5Y8iZUn4a3L4Pk1cbN40zk7oFt/1bSBlFT2h9vMkHEBL2jNwJzvao27j8Wome0P37uE1BZDNtfsf/aLMAWQ58FTBJCeAslLjMXSAR+AK5tGHMb8JltS2yb4jM1VNeZ6eevd/SdTn0dfP4TtWu89C+tjwsdDgOmw87X1TlGkLUNsrbCpc+o3e3Ia+HBHdB3JHz2EzhdaMw8zsKJQ/DuEvDrD/P+aPl54RNUlawTpvx1KZK+guIMFRexREsrbBwMWgg7XlHuNgdji49+Byrouhc41HCt14BfA48IIdKAQMCujqr8MhXw0D56B7D5BZXid9mz4N2n7bGTfgzlOZD0hTFzb/2nEvAae+v5Y+7ecM0bUHMaPnvQ6VLcrKYwCf67GNy84bbPwSfQ8nMjGvz0Obvts7aegJSw5UXoHQ1Dr7D8vGkPqWrZve/Yb20WYlOaipTy91LKIVLKEVLKW6SU1VLKDCnlBCllrJTyOilltVGLbYm8hmKp/tpH37nk7oUNz8CIa2HENe2PH3Qp+EfAvvdsn7soBZK/hgn3KOPelJAhKsUt9TvY85btczma6tPw4c0gXFRguzHQbSlh40CYtJ/eFrK2KbfZlJ+AycXy8yInQcQk2PYvhycKdPl8xMYdvXbddCI1Z2HVfeATAov+btk5JhcYthiObVCyuraw7Z/g6qkKVlpiwj3KVbT2D13fhbP613AqHa5dBoFWtMf08FWFU3n7jV9bT2H7K+DVG+Jv6vi50x6Gsmw4vNL4dXWALm/o88oqcXcxEahbB3YOFSdg+eVwMhWueln9AVjK0CuhvgZSbFBVrCpXAlLxN4JPUMtjhIBFz6sb0ne/tX4uR3PoE9j/Lsz4P4iebv11+o6CE86pweL0lGZD0pfKRXjx06MlxF2iUmE3/d2hu/oub+jzS6vo6++pVSs7g+Ob4fU5qtL1hnchZnbHzg8fD7594ejn1q8hbQ3UV7eex9xI8CDlIz34IRzbaP18jqKqHFb/Sv2fzXzUtmv1HQkV+apSWdMxGnPhx99t3fkmE8z9HZxMURXjDqLLG/q8Ul0sZXcyt8Jbl8HbiwABd34LQy/v+HVMJnVe2lq127aGpK/BO+h8kLEtpv9CBdBW3a+eRLoS2/4NZ0/Bwr+1rGXTEfqNUq8nDti+rp5EbSXseRsGXwYBkdZfZ/BlKq/+h6fhzCmDFtcxuryhzy+ron9X8M+nfKs+NKfSu042iLkevn9aGfniY3DpX+Enu84bDmsYeiXUnoX0dR0/t64GUtfA4EstC4q5ecEN76jUwg9uUn+4XYEzJ1UAb+iVqiWgrfQdqV6dVELXaTn0scqamXi/bdcRAhb8RQXW1//ZmLV1kC5t6OvNkhPlVfRz5h19XQ189QvV0/OLn8M/x8Lrs20PSNqb6tNKu2bj35Tk7U93w6T7rfNTNiVqqkqLTLTCfZO5GarLYPAiy8/pOxKueU1lCX32k65xk930vLoZzjEovuDVW+1ITxwy5no9AXM9bHkJQkfCgGm2Xy90GIy/S7lvHFDA1qUNfVFFNfVm6bwZN/W1yljuegMm/wQe2KHu7CcOqa405npHr7BlaqtgxVLlk7/yXyro2pKAkzW4uKpH2dRvOx6cSvoaXL3UY3BHGHq5qlQ8/IkqS3dmKgrU5yX+JggebNx1dUC2YyR+qsTgZvzCsgIpS5jzO9X5a9V9nV5E1aUNfV5ZYw69k+7o972rdqFXvAQLnlY53pMfUH7X1O9gXQcqHDuL+lr4+DZl5K96BcbeYvwcgxeqJ5qsbZafI6XKnY+da91TxbSHlUzDD3+CRLsWa9vGnrdUsHnaw8Zet+8o5TasPm3sdbsjZrPaEAQNUu4zo/DspTZNxcdUd6pOpEsb+saGI05ZLFVbCRv+pqRim1ZvgnqES7hTVdtl73LM+lrj8EpI+UZVu8a3k9liLTGzwcWjY5o0+fuVoNTgy6ybUwi48iX1+1h5HxQlW3cde1JXrXqQxl2ilD+NpN8oQELBYWOv2x1J/hoKE2H6/3WsQMoSoqerNo+73rDOfWklXdrQj4/uzeu3JhDVxyC3gpHsehMq8pTLoKVHv/lPgae/Cro5E0dWqsdLa9PJLMHdRyn8JX9tuc886WtV4TnIYoHU5rh6wPXvqCDtZw86n+vsyCo4UwgT7zP+2n0bAug6INs2NWfg+6dUtlZLLRqNYM7vVNrsynshZ4995riILm3oQ/w8mT8sFC93g++6tlJdoToAxcxpPZDj4atUF49+7jxNOSpLVYu64VcZ55dsjcEL1c9t6c46+WtVTt4RnZeW8AtVTys5u2D7y7Zdy0ikVBWYQYMgZq7x1+/VH7wDe7afvrYKNjyrKqZLMpu/L6VqA3gyRVV825rW2hpunrB0BfiGwIobWl6LwXRpQ++0HPhASZTObidrYsK9ape64z+ds672SF6tKleH2b0p2PmdefLX7Y8tOa5cDkM6kG3TFiOWqMyd7/+k/NbOQPZO5Z6aeJ99brJCqF19fg/Npc8/AK/NUjGaLS/BS6Phw1sgc5sy8LWVqitU4qdKbz52nn3X4xsMN3+i/t464aleG3p7sP99lZYVPq7tcf5hyujs/a9zyMgmfqqEx8IT7D9Xr/7Qb7RlfvqkhpvBECv98xcjhJI2NrmqP25nYMer4OGvAsb2ImycatbuBLK5gGpEU2dXzcPz8yxbqHLib/4EHjoIU36mKqbfuhT+MQr+EqGauoy8Hqb81P5rAlW9fdcalYlnZ7ShN5rCJNVTcrSFAkiTHlCyugc/su+62qOyFNLWKeExe7ttGhl8mXKhlOe1PS75a6UX0megcXP79VUB8cP/c/yuvixXZQKNvUW59OxF+HiQ9Upa2pFkbIAPboZnY5X8sr2N/b53ofYM3LIK4uaDfzjMfxIeSYRFz6nP1uQH4MYPVKZZZ33+QaXQ2stF1ARt6I3mwPtqpzjyOsvG9x+tPmi26L8YQfJqMNfC8Ks7b84RSwDZ9k3ubLGSYDDKbdOUyT8Bk5vKfnIku94AZOtqnEYRPl695jgw0ytnN/z3SsjarprFZG1TBYX2KmQzm1WRUuQUVbTUFHcflXRw80cw/48qbtQJRtcRaENvJOZ6ZbRi5ysfnKUMvQIyt6jSd0dx8ENVPRnWjrvJSIJiVbrjgRWt/6GnfKN2oUa5bZriF6pSX/evgLIc469vCU31VHpH2Xcun0DoE+PYlN4Nf1WVuj/fryqWp/8f7HsHdr5mn/kyvoeSYyqluQejDb2RZPygVAItdds0MvQKkGbVrswRlOVAxnpVjdmZj62g5IaLklp3J+xZDr0HQL8x9pl/6s8BCdsclIFz8CMVuLdVT8VSIiaoJiSOkILI3asKBSf/BDz81LHZj6vA57qn7OPC2bVMieB1pDNUN0QbeiM5skoF1AYt6Nh5fUdCQBQcNajNXiObnlOCZGueUNkFrXHgA0BCvB0Dga0x/GpVPHVgRfP38vZB9naYcJ9SvrQHAREw5HL1RNPZeuH1tbD5eegXb4yeiiWEj4czRY5J6d3wN9VfuKmLymRSN7maCrXZMJKyXEhZrZ7aXD2MvXYXQxt6o5BSBTNjZnf8QyUEDLtSfdCNEjurPg0bn1N56ttehrcWKl/3xUipjGzU1I63qTMCrwDlfz/0cfMd3Y7XwM0Hxtxs3zXEL4WzJ9XvrzPZ/74yuLMf77wnKUf56fMPKqM7+UElBdCU6Jlqg2R0pWjKN+pJuaNP2N0Qqw29EGKwEGJ/k3/lQoiHhBB9hBBrhBCpDa8daEHUhSlMVG4ba/Nvh16pgqEp3xqznqNfqEyDG96BX2Uo//tnDzbXgc/ZBafSHPvHMPpmlfrWtDHD6UIlQjb6JlVBbE9i56liopaeKuxFXQ1sfFbFROIu6bx5Q4apm2dnG/o9bylBupYCzq7uSno66Utjn6oyflDpwoEGy0l0Qaw29FLKZCnlaCnlaGAccBZYBTwKrJNSxgHrGr7v/qStVa/WGvqwBNV9ySg//YH3lW87crLaQS3+NxRnXCikdrpIiTe5eau0SkcRO1cVUH33O9WEWUrY8g9VTGIPOYCLcXFTTc6TV3dePcO+d1Qv0dm/6dy4iIur0rjvTKncmrOqLeKwK9UTXEsMvRKqSuH4JmPmNNerPPmBMzs/7uSEGOW6mQukSykzgcXA8objy4FOKLN0AlLXQOgI6NXPuvNNJnWTyFhvuwZLaZb6kI+++fyHPHo6jL8HdrwC/54I714LL45QwbGpD50PjjkCIVT+sl9f+Ph2ePtyVS04YgkExXXOGuJvUKqRnaFsWZ6nqnIjJ9tH7qA9IiYoqezqis6ZL+lLqC6HMT9qfUzsXPWkYZT7Jn+/coMO7GC7y26KUYZ+KdD43Bsqpcxv+PoEEGrQHM5LdYXKC4618Y82Zrba1dha0HLgA/V6cXB1/pOq/2jvaHUzGHmd6hg169e2zWcE3n3gurehPB8Kj8AV/4Br3ui8+fuPhcC48/939sJcr8Ss6qqV1r8jdpsxc1XKaqoNTdo7wr53VLJBVBsBZzcvVcyU9KUxYnPpP6jX6Jm2X6sbYHN1gBDCHbgSeOzi96SUUgjRYh6XEOJe4F6AyEgb+jE6A8c2Kf+6rfoYA2cDQgmLWStD0BhcHTC9eZ9Ldx+Y3ezX5DyEJ8CPt4BPsDL8nYkQ6sb4/VNKZMpeOe2bX1DuicX/Nl6K2FIiJ4FvKBz51H4KjY2UHFdPl7Mfbz9zasgiJcNRcFhlItlCxnolQ9KRepZujBE7+oXAXillQcP3BUKIfgANr4UtnSSlfE1KmSClTAgO7uK/jLQ14O6r1BVtwSdQVcqmf2/9NU6lK1/88C7qMQse3PlGvpFR16tXe8lRHF6pGkSPWKLcao7C5KLyylPX2F/3Zv/7gFD1Eu0ROVm9Zu2wbc6as5C9Q/nnNYAxhv5GzrttAD4Hbmv4+jbAidv5GET69xA9Q2UP2ErMHBUoszbNMqPhkVX7JjtOQKRyL7RVqWstSV/DyntUJfCV/3R8gHDYYqirtK/7xmxWhj5mtqpXaA//cPDrr2onbCFrqwrkx+i/gUZsMvRCCB9gPrCyyeFngPlCiFRgXsP33ZfiY+rx1CjDGjNH+U+PWZl9kLFeGSwjBcB6EvFLoThdZf8YRdo61Z6x7yi46SPj+u/aQtRUVTFqz+DzsQ0qs6itIGxThIDIibZnBGWsBxf3808IGtsMvZTyjJQyUEpZ1uTYKSnlXCllnJRynpSy2PZlOjGN1XwDZxlzvfAJyg1kjfumvq4hpWyW43eMXZVhi8HV07ig7PEtSqkxaDD86H/Ni4UcRaP7JuW75rUVRrHvXVUJO7gDgnQRk9TNoSzX+nnT16snJ2e4oToJujLWVjJ+gF5hxqUBurqrQKo1hj5vn0pj024b6/HspQTGDn9iu/bK8c3w/vXKbXHLKsfFHlpj+FWqqK5poZpRVJaoor2R16mOSpYSMUG9Wuu+OV0EBYeM23h1E7Sht4VzRRmzjN1Bx8xRinvFGR07L+MHQOiUMlsZd1vzSt2OICVsfhGWX6lqA2793DmzP6JnwqCFsO5J4ztPHfpE1SVY6rZppO9IVcBnbUD22Ab1qjc7F6ANvS3kH1AGYeAsY68bM0e9dnRXn7Ee+o2yva9qTyd6pgqub3wWqso7dm5ZrtrFr/09DL0c7vnB+iI6eyOESvP0DoRP7lT6SEYgpcqdDx3Z8TRJFzclC5FtpaHP+EFJZvQfbd353RRt6G3BaP98I4Ex4B95vujDEqpPqyCW3snYjhAw7w9w9pTl/Tzr62DXm/DyJBVIX/gsXLfceXzyreETqHThT6XDR7cYY+yzd6pNUMLt1j3pRkxsqNzt4FqkVP756BkqBqE5M73SjAAADPRJREFUhzb0tpCxHkKGq27uRiIExM5RbiFLRZ4yt6iiLZ1SZgxh41Rgduu/2m51WFcDBz6Ef4+Hrx5RO9gHtsLEe7tOQDx6hkr5zFgPy6+wvQHOzv/Y1v82cpLKPMvd3bHzijOgPEf751tAG3prqTmjZA8GzrLP9WPmqMCqpWl+GetVtoitRVua88x5QsncLrsUTqZe+N7JVPjut/D8UFh1r/IrL30fbvuia6a2jr0FbnhPqbAuv8L6Oo7yfJWyOeZH1ve/jZio2nF25IkWzrs69VNtM7png8TOIP0HFWwaZCeJ2egZIEzqwxtpgfFO/0HlDXckw0HTNkGxcPuX8P4N8MY8ZbyESfU9zdqqjNGgS2HsbUr+wl7NUTqLIZepBtnvXQsf36Fy/jvaQ3XPWypJYcLd1q/Ds5f6LKeuUfpMlpKxXrk8u+KN1s508U+mA0lZrR5Po6ba5/pevZX7wJJmGBUnoOiofmS1B+EJcPdapX2z6w3Y8R84U6h8+A8nwtL31M2+qxv5RmJmw6LnIH0dfNNBsbu6atj9ltLXt9XYxl2ixO1Ksy0bX3NW/a3Eze86LrNORO/orcFsVg1CYueqLAF7ETMXNv4Nzha3nYPdGBTW/nn70Cca7tvo6FV0HuNuV66pbf9STyxx8y0779DH6iY4yYD+t4MWwJrfKR2phDvbH5/+vZJ06OG9YVujm2xDOpncParv5uDL7DvPoAXKR5y8uu1x6T+oFLnQkfZdj6bnMPcJCBqkAsyWVM5KCVv/qXoyGOEjDxqkpDxS11g2/ugXqgq3s3rvdjG0obeG5K9BuECcjbLE7dF/jPI5tqVHIqXa0UfP7D7uA43jcfWAy19UfQs2WCBXlbYWipJgyk+NcZ0IAXEL1Ge7tqrtsfW1ypU6eKF9n7C7MNoyWEPyaoiaovzo9qSxaXj6961nQRQlwekT2m2jMZ4BU2HMLSrF9MThtsdufUkpTw6/xrj54y6B2rMqdbgtjm9Sfx/abdMq2tB3lOJjKvA5eGHnzDdscdtNwxvdOgNndc56ND2L+X9UG5ovfq5iUy2RvVPVfEy63xip7kaip6uG4klftj3u6JcqvbWxolzTDG3oO8rBDwHRebuHsAS1U2rJfWOuV+lsUdOad5PSaIzAuw8s+LMqXtr9ZvP3q0/DqvugVziMu8PYud28YPjVqiCttabtdTXqRhA7T43XtEjXNvRnTiqFwKwdSrmxvs6+85nNsO891bmmswyryXS+G9DFzZxTv1M+1An3dM5aND2TUderGNC6PzavEl79a9WP4ZrX7CP3MOl+pbC5792W3z+wAk4XqFoGTat0bUN/fBO8vQiWXQKvzYKXRsO2l+3XHu3YBijLUn7LzmTYYlWctX/Fhcd3vqZ2+0M6oPet0XQUIeDyF1TQ8/W5Kl+9ogDWPgn734Vpjyh/vj3oFw+RU9Rn/eKm4fW1sOk51dg9dq595u8mdG1DHzVNScD+aCVc8wb4R8C3j6kqxvJ84+fb945K4RpyufHXbouoKcoHv/YP56WLT6apIG3CnTrTQGN/AmPgztVq1/7uNfDCMNj8vNqEzHrUvnNPvA9KMyHlmwuPH/xIHZ/5a10k1Q5CGt0b0woSEhLk7t0dFDBqjdS1qm2bd6Bq9hAYY8x1zxbDc0OUVvllzxpzzY5Qmg2vTIHQ4cpnuuYJpbXzSKLxomoaTWvUVsGWf0BNBYy9XclE2Jv6OvW07tUbbv9K3WzqauDliaob230be6yhF0LskVImtDeua+/oWyJuHtz2ufJnv3WZ5SXU7bF3eUMjhU522zQSEAGXPgNZ2+D12UoGdsGftZHXdC5unjDr13DJnzrHyIPS27n0mQbBtcshcyu8MVc93c7+TY818h2h++3oGyk4AssWqg4/d31rW877qXR4ZaoSGrv5I+PW2FGkhA1/VSqVCXeoBgsaTU8h5TulmV9XpZ7Yr3hJNXfpwVi6o7fJ0AshAoA3gBGABO4EkoEPgQHAceB6KWVJW9exi6EH1QDi3WtUiuItK61LvzKb1S7ixGF4cDv06m/8OjUajWVk7YDD/4PpvwC/UEevxuF0luvmH8A3UsohQDxwFHgUWCeljAPWNXzvGKKnw9WvKnfHR7cpv15HkBK2vKAq8xY8rY28RuNoIifCZX/TRr6DWG3ohRD+wAzgTQApZY2UshRYDCxvGLYcuMrWRdrEiCUqNSz1W1h5t+UdmyoKYMWNKnd4yOUdb3Ks0Wg0ToItMsXRQBHwlhAiHtgD/BwIlVI25jaeAFq89Qoh7gXuBYiMtHPxUcIdSjPj299AQSLM+70y3o1BHHM9lOUo3ZgTByFjg2pOLExwydMw6cc64KPRaLosVvvohRAJwHZgqpRyhxDiH0A58FMpZUCTcSVSyjYjoXbz0V9M8mqVlngyBVzcwSdYHa84oXpUNhI6UlW/jrsdguLsvy6NRqOxAkt99Lbs6HOAHCnljobvP0H54wuEEP2klPlCiH5AoQ1zGMvghRA7H46sVFk5Z04qvXf/MOgVBiFDIXgIeAW0fy2NRqPpIlht6KWUJ4QQ2UKIwVLKZGAukNjw7zbgmYbXNsTUHYCLq9Lu0Gg0mh6Cra0Efwq8J4RwBzKAO1AB3o+EEHcBmYC2qhqNRuNAbDL0Usr9QEv+Ia0wpNFoNE5C95NA0Gg0Gs0FaEOv0Wg03Rxt6DUajeb/2zu/ECuqOI5/vmgZGmRm2eYurZUUm2RKD0o9RP90RZSgB0XISOglyEIINyHoMYrKwKzoz0IsFpnVslBim8+aVuqmbhqKrmgalEG9KP16OOfidPded7u73Dkz/D4w7Jxz7i4fvsz53blnZu+UHC/0juM4JccLveM4TsnxQu84jlNykvg+eknnCPfcN8J04Ldx1GkG7twciuZcNF9w52ZRz/lmM7t+pF9OotCPBUl7RvNdDynhzs2haM5F8wV3bhZjdfalG8dxnJLjhd5xHKfklKHQv5u3QAO4c3MomnPRfMGdm8WYnAu/Ru84juNcnjKc0TuO4ziXwQu94zhOySl0oZe0WNKgpKOS1uftUwtJbZJ2Sjoo6SdJa2P/NEk7JB2JPy/7uMVmI2mCpB8k9cX2LEm7YtafxGcQJIOkqZK2Sjos6ZCkhQXI+Ll4TAxI2iLpqtRylvSBpLOSBjJ9NXNV4M3ovl/S/IScX4nHxn5Jn0vKPu60KzoPSlqUgm9mbJ0kkzQ9thvKuLCFXtIEYBPQCXQAKyV15GtVk4vAOjPrABYAT0fP9UC/mc0G+mM7JdYChzLtl4HXzew24HdgTS5W9dkIfG1mdwBzCe7JZixpJvAMcI+ZzQEmACtIL+duYHFVX71cO4HZcXsK2Nwkx2q6Ge68A5hjZncBPwNdAHEurgDujL/zVqwtzaSb4b5IagMeAU5kuhvL2MwKuQELge2ZdhfQlbfXKLy/BB4GBoGW2NcCDObtlnFsJUzgB4A+QIT/yptYK/u8N+Aa4Bjx5oJMf8oZzwROAtMIDwDqAxalmDPQDgyMlCvwDrCy1uvydq4aexToifv/qRvAdmBhCr6E53DPBY4D08eScWHP6Lk0USoMxb5kkdQOzAN2ATPM7HQcOgPMyEmrFm8AzwP/xPZ1wB9mdjG2U8t6FnAO+DAuN70naQoJZ2xmp4BXCWdrp4HzwF7SzrlCvVyLMiefBL6K+0k6S1oOnDKzfVVDDfkWudAXCklXA58Bz5rZn9kxC2/NSdznKmkpcNbM9ubt8j+YCMwHNpvZPOAvqpZpUsoYIK5rLye8Sd0ETKHGx/fUSS3XkZC0gbCc2pO3Sz0kTQZeAF4cr79Z5EJ/CmjLtFtjX3JIuoJQ5HvMbFvs/lVSSxxvAc7m5VfFvcAySceBjwnLNxuBqZIqzxhOLeshYMjMdsX2VkLhTzVjgIeAY2Z2zswuANsI2aecc4V6uSY9JyU9ASwFVsU3KEjT+VbCCcC+OA9bge8l3UiDvkUu9N8Bs+NdClcSLqj05uw0DEkC3gcOmdlrmaFeYHXcX01Yu88dM+sys1Yzaydk+q2ZrQJ2Ao/FlyXjC2BmZ4CTkm6PXQ8CB0k048gJYIGkyfEYqTgnm3OGern2Ao/HO0MWAOczSzy5ImkxYTlymZn9nRnqBVZImiRpFuEi5+48HCuY2QEzu8HM2uM8HALmx+O8sYzzuFAyjhcwlhCuoP8CbMjbp47jfYSPtvuBH+O2hLDu3Q8cAb4BpuXtWsP9fqAv7t9CmABHgU+BSXn7VbneDeyJOX8BXJt6xsBLwGFgAPgImJRazsAWwjWEC7HgrKmXK+Gi/aY4Hw8Q7ihKxfkoYW27Mgffzrx+Q3QeBDpT8K0aP86li7ENZexfgeA4jlNyirx04ziO44wCL/SO4zglxwu94zhOyfFC7ziOU3K80DuO45QcL/SO4zglxwu94zhOyfkXKBd/aUVlvt0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG0tSXLWPuCQ"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}