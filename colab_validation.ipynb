{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "colab_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkRS7VvwISGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42b0d518-912a-427e-efda-b68d6a77a590",
        "tags": []
      },
      "source": [
        "\n",
        "#%%\n",
        "import torch\n",
        "\n",
        "args = {\n",
        "    'epoch_num': 100,     # Number of epochs.\n",
        "    'lr': 1.0e-3,           # Learning rate.\n",
        "    'weight_decay': 10e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'batch_size': 5,     # Mini-batch size. 600\n",
        "    'batch_test': 5,     # size of test batch\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "dataset_name = \"PAMAP2\"\n",
        "model_type = \"OurConvLSTM\"\n",
        "#\"OurConvLSTM\", \"AttentionTransformer\", \"DeepConvLSTM\", \"CnnIMU\", FCNN\n",
        "\n",
        "val_sub = 4\n",
        "for ts_sub in [0,2,3,5,6,7]:##,1,3,5,0]:#2,6]:#[6,7,2,0,1,3,5]:\n",
        "\n",
        "\n",
        "  ! pip install wget\n",
        "  import os\n",
        "  import torch\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  from torch import nn\n",
        "\n",
        "\n",
        "  ssh_config = \"\"\"\n",
        "  Host github.com\n",
        "    IdentityFile ~/.ssh/github.pem\n",
        "    User davipeag\n",
        "    StrictHostKeyChecking no\n",
        "  \"\"\"\n",
        "\n",
        "  if os.name == 'nt':\n",
        "    base_path = \"\"\n",
        "    REPO_DIR = \".\"\n",
        "    STORE_DIR =\".\" \n",
        "    print(\"Windows\")\n",
        "  else:\n",
        "    print(\"Unix-like\")\n",
        "    REPO_DIR = \"/tmp/HeartRateRegression\"\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    GIT_PATH = \"/content/drive/My\\ Drive/deeplearning_project/github.pem\"\n",
        "    DATA_PATH = \"/content/drive/My\\ Drive/deeplearning_project/normalized.zip\"\n",
        "    STORE_DIR =\"/content/drive/My Drive/deeplearning_project/\" \n",
        "    !mkdir ~/.ssh\n",
        "    !cp -u {GIT_PATH} ~/.ssh/\n",
        "    !chmod u=rw,g=,o= ~/.ssh/github.pem\n",
        "    !echo \"{ssh_config}\" > ~/.ssh/config\n",
        "    !chmod u=rw,g=,o= ~/.ssh/config\n",
        "    ! (cd /tmp && git clone git@github.com:davipeag/HeartRateRegression.git)\n",
        "    ! (cd {REPO_DIR} && git pull )\n",
        "    import sys\n",
        "    sys.path.append(REPO_DIR)\n",
        "\n",
        "\n",
        "  def git_push():\n",
        "    if os.name == 'nt':\n",
        "      pass\n",
        "    else:\n",
        "      ! git config --global user.email \"daviaguiar@outlook.com\"\n",
        "      ! git config --global user.name \"Davi Pedrosa de Aguiar\"\n",
        "      print(\"going to push\")\n",
        "      ! (cd {REPO_DIR} && git pull && cd -)\n",
        "      ! (cd {REPO_DIR} && git add . && git commit -m \"from colab\" && git push)\n",
        "\n",
        "  def git_pull():\n",
        "    if os.name == 'nt':\n",
        "      pass\n",
        "    else:\n",
        "      ! git config --global user.email \"daviaguiar@outlook.com\"\n",
        "      ! git config --global user.name \"Davi Pedrosa de Aguiar\"\n",
        "      print(\"going to push\")\n",
        "      ! (cd {REPO_DIR} && git pull && cd -)\n",
        "      \n",
        "    \n",
        "  git_push()\n",
        "\n",
        "\n",
        "\n",
        "  from data_utils import (\n",
        "      Pamap2Handler, cross_validation_split)\n",
        "\n",
        "  from default_utils import DefaultPamapPreprocessing, FcPamapPreprocessing\n",
        "  from preprocessing_utils import (OurConvLstmToAttentionFormat, OurConvLstmToCnnImuFormat)\n",
        "\n",
        "  from models_utils import OurConvLstmDataset, make_loader, reset_seeds\n",
        "  from models_utils import DatasetXY\n",
        "\n",
        "  from default_utils import TrainOurConvLSTM, TrainXY\n",
        "  from default_utils import make_our_conv_lstm, make_attention_transormer_model, make_fcnn\n",
        "  from torch import nn\n",
        "\n",
        "  from options import (\n",
        "    preprocessing_options,\n",
        "    trainer_options,\n",
        "    dataset_cls_options,\n",
        "    net_options\n",
        "\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  reset_seeds()\n",
        "\n",
        "  is_size = 2 \n",
        "  recursive_size = 160\n",
        "  total_size = recursive_size + is_size\n",
        "\n",
        "  ##%%\n",
        "\n",
        "  dataset_handler = Pamap2Handler(os.path.join(REPO_DIR, \"..\"))\n",
        "\n",
        "  df_ts = dataset_handler.get_protocol_subject(ts_sub + 1)\n",
        "  \n",
        "  preprocessor =preprocessing_options[model_type]\n",
        "\n",
        "  xy_ts = [preprocessor.transformers_ts.transform(df_ts)]\n",
        "\n",
        "  dataset_cls = dataset_cls_options[model_type]\n",
        "\n",
        "  loader_ts = make_loader(\n",
        "    xy_ts, dataset_cls, batch_size=args[\"batch_test\"],\n",
        "    shuffle=False\n",
        "  )\n",
        "\n",
        "  ##%%\n",
        "  from default_utils import make_cnn_imu2\n",
        "  from default_utils import make_deep_conv_lstm\n",
        "\n",
        "\n",
        "  # net_options = {\n",
        "  #     \"OurConvLSTM\": lambda : make_our_conv_lstm(40,1),\n",
        "  #     \"AttentionTransformer\": lambda: make_attention_transormer_model(args[\"device\"]),\n",
        "  #     \"DeepConvLSTM\": lambda : make_deep_conv_lstm(recursive_size=recursive_size, total_size=total_size),\n",
        "  #     \"CnnIMU\": lambda : make_cnn_imu2(recursive_size=recursive_size, total_size=total_size),\n",
        "  #     \"FCNN\": lambda : make_fcnn()\n",
        "  # }\n",
        "\n",
        "  net = net_options[model_type](total_size, recursive_size).to(args[\"device\"])\n",
        "  criterion = nn.L1Loss().to(args[\"device\"]) \n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=args[\"lr\"],\n",
        "                              weight_decay=args[\"weight_decay\"])\n",
        "\n",
        "  ##%%\n",
        "\n",
        "\n",
        "  basic_training_parameters = {\n",
        "      \"net\": net,\n",
        "      \"criterion\": criterion,\n",
        "      \"optimizer\": optimizer,\n",
        "      \"loader_tr\": loader_ts,\n",
        "      \"loader_val\": loader_ts,\n",
        "      \"loader_ts\": loader_ts,\n",
        "      \"normdz\": preprocessor.normdz,\n",
        "      \"ztransformer\": preprocessor.ztransformer,\n",
        "      \"device\": args[\"device\"]\n",
        "  }\n",
        "\n",
        "  trainer = trainer_options[model_type](basic_training_parameters)\n",
        "\n",
        "  import os\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "  state_dict_name = f\"trained_models/{model_type}ts_{ts_sub}_val_{val_sub}.pkl\"\n",
        "  state_dict_path = os.path.join(STORE_DIR, state_dict_name)\n",
        "  trainer.net.load_state_dict(torch.load(state_dict_path, map_location=args[\"device\"]))\n",
        "  mae = trainer.compute_mean_MAE(loader_ts)\n",
        "\n",
        "  print(f\"{model_type}_ts_{ts_sub}_val_{val_sub}: {mae}\")\n",
        "\n",
        "  figures = list()\n",
        "  for idx in range(1):    \n",
        "    fig, ax = plt.subplots(figsize=(15,10))\n",
        "    figures.append((fig, ax))    \n",
        "    y,p = trainer.reverse_transformed_prediction_labels(loader_ts)\n",
        "    ax.plot(np.linspace(0, 3*(len(p[idx])-1), len(p[idx])), p[idx], label=model_type)\n",
        "    ax.plot(np.linspace(0, 3*(len(p[idx])-1), len(p[idx])), y[idx], 'k', label=\"actual\")\n",
        "    ax.set_ylabel(\"heart rate [beats per minute]\")\n",
        "    ax.set_xlabel(\"time[seconds]\")\n",
        "    ax.legend()\n",
        "    fig.show()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# %%\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "cpu\nRequirement already satisfied: wget in c:\\python37\\lib\\site-packages (3.2)\nWindows\n"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at ..\\caffe2\\serialize\\inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at ..\\caffe2\\serialize\\inline_container.cc:132)\n(no backtrace available)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-1212bb43d2d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    177\u001b[0m   \u001b[0mstate_dict_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"trained_models/{model_type}ts_{ts_sub}_val_{val_sub}.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[0mstate_dict_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTORE_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_dict_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m   \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m   \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mean_MAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at ..\\caffe2\\serialize\\inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at ..\\caffe2\\serialize\\inline_container.cc:132)\n(no backtrace available)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fiBFA9bINxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xi, yi, xr, yp, p = trainer.get_data_epoch(loader_ts)\n",
        "\n",
        "print(trainer.HR_MAE(yi, yp, p))\n",
        "# yr = trainer.inverse_transform_label(yi,yp)\n",
        "# pr = trainer.inverse_transform_label(yi,p)\n",
        "\n",
        "yi = yi.detach().cpu().numpy()\n",
        "yp = yp.detach().cpu().numpy()\n",
        "p = p.detach().cpu().numpy()\n",
        "\n",
        "yr = trainer.inverse_transform_label(yi,yp)\n",
        "pr = trainer.inverse_transform_label(yi,p)\n",
        "\n",
        "np.mean(np.abs(pr-yr))\n",
        "#trainer.HR_MAE(yi, yr, p)\n",
        "#pr.shape, yr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhvUq4S7TpHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(yr[0])\n",
        "plt.plot(pr[0])\n",
        "np.mean(np.abs(pr[0]-yr[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Llp40_diEhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}